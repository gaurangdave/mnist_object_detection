{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f4a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 12:01:43.930600: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761764504.020476   31081 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761764504.046764   31081 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1761764504.246152   31081 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761764504.246231   31081 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761764504.246232   31081 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761764504.246234   31081 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-29 12:01:44.269914: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1bf20",
   "metadata": {},
   "source": [
    "## Image Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6850df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## quick POC to try how image overlays would work. \n",
    "pixels = np.ones(shape=(10,10,1))\n",
    "canvas = np.zeros(shape=(100,100,1))\n",
    "temp = np.zeros(shape=(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93d99aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets see if we can render canvas as image\n",
    "## helper function to plot the mnist data instances\n",
    "def plot_canvas(canvas_data):\n",
    "    plt.imshow(canvas_data)  # Use 'gray' colormap to render grayscale\n",
    "    plt.axis(\"off\") # Remove axes for better visualization    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c62755d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAABP1JREFUeJzt17ERwlAMBcFvD61RAlVSgntDZJdC4rGD3VjBy260zcwsAFhr7VcPAOA+RAGAiAIAEQUAIgoARBQAiCgAEFEAII9/D5/768wdAJzs+Lx/3vgUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFADINjNz9QgA7sGnAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBAvuPuDgN/IHT5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## lets say we want to put the pixels on top, left corner of canvas so \n",
    "plot_canvas(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e13f0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAABRFJREFUeJzt17ENwkAQRcEDuQpycrpwsZRAQ1TBkb0UCwnZSDPxBj972tOccw4AGGOc9x4AwHGIAgARBQAiCgBEFACIKAAQUQAgogBAlq2Hr+f1lzu+sl5ue08A+BuP1/3jjU8BgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBk2Xq4Xm4/nAHAEfgUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQE5zzrn3CACOwacAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEDeuJMQloummXEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## lets overlay the pixels which should be a white blob on top left corner of canvas\n",
    "canvas[0:10,0:10] = pixels\n",
    "plot_canvas(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca241061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1 = [1,2,3,4]\n",
    "[a,b,c,d] = temp1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c3bf4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.randint(0, high=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b24b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gaurangdave/workspace/mnist_object_detection/notebooks'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "dir_path = os.getcwd()\n",
    "dir_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8999c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761764508.859051   31081 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6053 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:2e:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([20, 66, 50], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# The \"warehouse\" of scores\n",
    "params = tf.constant([[10, 20, 30, 40],\n",
    "                      [50, 60, 70, 80],\n",
    "                      [90, 11, 22, 33],\n",
    "                      [44, 55, 66, 77]])\n",
    "\n",
    "# The list of \"GPS coordinates\"\n",
    "indices = tf.constant([[0, 1],   # Get the score at (row=0, col=1)\n",
    "                       [3, 2],   # Get the score at (row=3, col=2)\n",
    "                       [1, 0]])  # Get the score at (row=1, col=0)\n",
    "\n",
    "\n",
    "tf.gather_nd(params=params, indices=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f0e1c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
       "array([[90, 11, 22, 33],\n",
       "       [10, 20, 30, 40]], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# The same \"warehouse\" of scores\n",
    "params = tf.constant([[10, 20, 30, 40],\n",
    "                      [50, 60, 70, 80],\n",
    "                      [90, 11, 22, 33],\n",
    "                      [44, 55, 66, 77]])\n",
    "\n",
    "# The list of row indices you want to select\n",
    "indices = tf.constant([[2],   # Get the entire row at index 2\n",
    "                       [0]])  # Get the entire row at index 0\n",
    "\n",
    "tf.gather_nd(params=params, indices=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "525b7739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[ 90,  11,  22,  33],\n",
       "       [110, 120, 130, 140],\n",
       "       [244, 255, 266, 277]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# A batch of 3 matrices, shape (3, 4, 4)\n",
    "params = tf.constant([\n",
    "  [[10, 20, 30, 40],   # Matrix 0\n",
    "   [50, 60, 70, 80],\n",
    "   [90, 11, 22, 33],\n",
    "   [44, 55, 66, 77]],\n",
    "\n",
    "  [[110, 120, 130, 140], # Matrix 1\n",
    "   [150, 160, 170, 180],\n",
    "   [190, 111, 122, 133],\n",
    "   [144, 155, 166, 177]],\n",
    "\n",
    "  [[210, 220, 230, 240], # Matrix 2\n",
    "   [250, 260, 270, 280],\n",
    "   [290, 211, 222, 233],\n",
    "   [244, 255, 266, 277]]\n",
    "])\n",
    "\n",
    "# The list of row indices to gather.\n",
    "# We want to get row 2 from Matrix 0, row 0 from Matrix 1, and row 3 from Matrix 2.\n",
    "indices = tf.constant([[2],   # Row index for Matrix 0\n",
    "                       [0],   # Row index for Matrix 1\n",
    "                       [3]])  # Row index for Matrix 2\n",
    "\n",
    "\n",
    "tf.gather_nd(params=params, indices=indices, batch_dims=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca584b",
   "metadata": {},
   "source": [
    "# TensorFlow Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d20abc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor = tf.constant([[0, 5, 0],\n",
    " [0, 8, 2],\n",
    " [0, 3, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "125b7a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[0, 5, 0],\n",
       "       [0, 8, 2],\n",
       "       [0, 3, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9480e7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=int32, numpy=\n",
       "array([[ 5],\n",
       "       [10],\n",
       "       [ 3]], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(my_tensor, keepdims=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d96bbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[ 0, 16,  2]], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(my_tensor, keepdims=True, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d1fcd",
   "metadata": {},
   "source": [
    "## Generation 1,28 and 28,1 tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62744412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=int32, numpy=\n",
       "array([[25,  0],\n",
       "       [10,  0],\n",
       "       [23,  0],\n",
       "       [12,  0],\n",
       "       [ 1,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_row_indices = tf.random.uniform(shape=(5,1),minval=0,maxval=28, dtype=tf.int32)\n",
    "row_zeros = tf.zeros(shape=(5,1), dtype=tf.int32)\n",
    "\n",
    "active_row_indices = tf.concat(values = [active_row_indices,row_zeros], axis=1)\n",
    "active_row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0896b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create tensors\n",
    "\n",
    "# A column tensor of shape (28, 1). Think of it as a vertical strip.\n",
    "# Each element represents the \"activity\" of a single row.\n",
    "active_rows = tf.zeros(shape=(28,1), dtype=tf.float32)\n",
    "\n",
    "# A row tensor of shape (1, 28). Think of it as a horizontal strip.\n",
    "# Each element represents the \"activity\" of a single column.\n",
    "active_cols = tf.zeros(shape=(1,28), dtype=tf.float32)\n",
    "\n",
    "\n",
    "## generate random indices to update\n",
    "\n",
    "# To update 5 specific rows in `active_rows`, we need 5 indices.\n",
    "# The shape is (5, 1) because `active_rows` is a 2D tensor, but since it only has\n",
    "# one column, TensorFlow lets us use a simpler index with just one coordinate (the row number).\n",
    "active_row_indices = tf.random.uniform(shape=(5,1), minval=0, maxval=28, dtype=tf.int32)\n",
    "\n",
    "\n",
    "# To update 5 specific columns in `active_cols`, we still need 5 indices.\n",
    "# We create a (5, 1) tensor of random column numbers first.\n",
    "active_col_indices_random = tf.random.uniform(shape=(5,1), minval=0, maxval=28, dtype=tf.int32)\n",
    "# We also need a (5, 1) tensor of row numbers. Since `active_cols` only has one row, this is always 0.\n",
    "column_zeros = tf.zeros(shape=(5,1), dtype=tf.int32)\n",
    "# We concatenate them to create the final indices.\n",
    "# The shape is (5, 2) because we are providing 5 full (row, column) coordinates\n",
    "# to precisely identify each element in the 2D `active_cols` tensor.\n",
    "active_col_indices = tf.concat(values=[column_zeros, active_col_indices_random], axis=1)\n",
    "\n",
    "\n",
    "## create update tensor\n",
    "\n",
    "# --- INTUITION FOR `row_updates` ---\n",
    "# We are updating 5 rows. Each `index` in `active_row_indices` points to a slice of\n",
    "# `active_rows`. The shape of this slice is (1,).\n",
    "# Therefore, our `updates` tensor must provide 5 \"packages\", where each package has a shape of (1,).\n",
    "# The final shape is (num_updates, slice_shape_part_1) -> (5, 1).\n",
    "row_updates = tf.ones(shape=(5,1), dtype=tf.float32)\n",
    "\n",
    "# --- INTUITION FOR `col_updates` ---\n",
    "# We are updating 5 columns. Each `(row, col)` coordinate in `active_col_indices` points\n",
    "# to a single SCALAR element within `active_cols`. The shape of this slice is ().\n",
    "# Therefore, our `updates` tensor must provide 5 \"packages\", where each package is a scalar.\n",
    "# A list of 5 scalars is a 1D tensor of shape [5].\n",
    "col_updates = tf.ones(shape=[5], dtype=tf.float32)\n",
    "\n",
    "\n",
    "# Perform the updates\n",
    "updated_active_rows = tf.tensor_scatter_nd_update(active_rows, active_row_indices, updates=row_updates)\n",
    "updated_active_cols = tf.tensor_scatter_nd_update(active_cols, active_col_indices, updates=col_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3cc635d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=3>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=21>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=15>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=21>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def get_min_max(active_rows, active_cols):\n",
    "    # find x_min, x_max\n",
    "    # step 1 find indices for active x\n",
    "    non_zero_active_cols = tf.where(active_cols != 0)\n",
    "    # get the first and last active x as x_min and x_max\n",
    "    x_min = tf.cast(tf.reduce_min(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "    x_max = tf.cast(tf.reduce_max(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "\n",
    "    ##\n",
    "    non_zero_active_rows = tf.where(active_rows != 0)\n",
    "    y_min = tf.cast(tf.reduce_min(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "    y_max = tf.cast(tf.reduce_max(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "\n",
    "x_min, x_max, y_min, y_max = get_min_max(\n",
    "    updated_active_rows, updated_active_cols)\n",
    "x_min, x_max, y_min, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db64817b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int64, numpy=3>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=21>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = tf.where(updated_active_cols != 0)\n",
    "tf.reduce_min(temp[:,1]),tf.reduce_max(temp[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d66ada50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int64, numpy=15>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=21>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = tf.where(updated_active_rows != 0)\n",
    "tf.reduce_min(temp[:,0]),tf.reduce_max(temp[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f23f5671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int64, numpy=\n",
       "array([[15,  0],\n",
       "       [17,  0],\n",
       "       [21,  0]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "774804fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  tf.Tensor(\n",
      "[[0. 2.]\n",
      " [0. 5.]\n",
      " [1. 5.]\n",
      " [2. 8.]], shape=(4, 2), dtype=float32)\n",
      "segment_ids:  tf.Tensor([0 0 1 2], shape=(4,), dtype=int32)\n",
      "Result:  tf.Tensor(\n",
      "[[0. 2.]\n",
      " [1. 5.]\n",
      " [2. 8.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# importing the library\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initializing the input tensor\n",
    "data = tf.constant([[0, 2],[0, 5], [1, 5], [2, 8]], dtype = tf.float32)\n",
    "segment_ids = tf.constant([0, 0, 1,2])\n",
    "\n",
    "# Printing the input tensor\n",
    "print('data: ', data)\n",
    "print('segment_ids: ', segment_ids)\n",
    "\n",
    "# Calculating result\n",
    "res = tf.math.segment_min(data, segment_ids)\n",
    "\n",
    "# Printing the result\n",
    "print('Result: ', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb39812a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error in map_fn:\n  Expected `fn` to return a:\n    RaggedTensorSpec(TensorShape([None, 2]), tf.float32, 1, tf.int64)\n  But it returned a:\n    TensorSpec(shape=(4, 2), dtype=tf.float32, name=None)\n    (value=tf.Tensor(\n[[1. 1.]\n [1. 1.]\n [1. 1.]\n [1. 1.]], shape=(4, 2), dtype=float32))\n  To fix, update the `fn_output_signature` (or `dtype`) argument to `map_fn`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m inputs = tf.constant([\u001b[32m1.0\u001b[39m, \u001b[32m2.0\u001b[39m, \u001b[32m3.0\u001b[39m, \u001b[32m4.0\u001b[39m])\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Map with ragged output\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m ragged_result = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprocess_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfn_output_signature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRaggedTensorSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(ragged_result)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Result will be a RaggedTensor with shapes: (4, 2), (7, 2), (10, 2), (13, 2)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/util/deprecation.py:660\u001b[39m, in \u001b[36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    652\u001b[39m           _PRINTED_WARNING[(func, arg_name)] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    653\u001b[39m         _log_deprecation(\n\u001b[32m    654\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is deprecated and \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    655\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mwill be removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    658\u001b[39m             \u001b[33m'\u001b[39m\u001b[33min a future version\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[32m    659\u001b[39m             (\u001b[33m'\u001b[39m\u001b[33mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m % date), instructions)\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/util/deprecation.py:588\u001b[39m, in \u001b[36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    580\u001b[39m         _PRINTED_WARNING[(func, arg_name)] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    581\u001b[39m       _log_deprecation(\n\u001b[32m    582\u001b[39m           \u001b[33m'\u001b[39m\u001b[33mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is deprecated and will \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    583\u001b[39m           \u001b[33m'\u001b[39m\u001b[33mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    586\u001b[39m           \u001b[33m'\u001b[39m\u001b[33min a future version\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m % date),\n\u001b[32m    587\u001b[39m           instructions)\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/ops/map_fn.py:637\u001b[39m, in \u001b[36mmap_fn_v2\u001b[39m\u001b[34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fn_output_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    636\u001b[39m   fn_output_signature = dtype\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m    \u001b[49m\u001b[43melems\u001b[49m\u001b[43m=\u001b[49m\u001b[43melems\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfn_output_signature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfn_output_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mback_prop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mback_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mswap_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mswap_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/util/deprecation.py:588\u001b[39m, in \u001b[36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    580\u001b[39m         _PRINTED_WARNING[(func, arg_name)] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    581\u001b[39m       _log_deprecation(\n\u001b[32m    582\u001b[39m           \u001b[33m'\u001b[39m\u001b[33mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is deprecated and will \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    583\u001b[39m           \u001b[33m'\u001b[39m\u001b[33mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    586\u001b[39m           \u001b[33m'\u001b[39m\u001b[33min a future version\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m % date),\n\u001b[32m    587\u001b[39m           instructions)\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/ops/map_fn.py:497\u001b[39m, in \u001b[36mmap_fn\u001b[39m\u001b[34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[39m\n\u001b[32m    492\u001b[39m   tas = [\n\u001b[32m    493\u001b[39m       ta.write(i, value) \u001b[38;5;28;01mfor\u001b[39;00m (ta, value) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tas, result_value_batchable)\n\u001b[32m    494\u001b[39m   ]\n\u001b[32m    495\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m (i + \u001b[32m1\u001b[39m, tas)\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m _, r_a = \u001b[43mwhile_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_batchable_ta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m    \u001b[49m\u001b[43mback_prop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mback_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43mswap_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mswap_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m result_batchable = [r.stack() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m r_a]\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# Update each output tensor w/ static shape info about the outer dimension.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/ops/while_loop.py:488\u001b[39m, in \u001b[36mwhile_loop\u001b[39m\u001b[34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[39m\n\u001b[32m    485\u001b[39m loop_var_structure = nest.map_structure(type_spec.type_spec_from_value,\n\u001b[32m    486\u001b[39m                                         \u001b[38;5;28mlist\u001b[39m(loop_vars))\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m cond(*loop_vars):\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m   loop_vars = \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    489\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m try_to_pack \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loop_vars, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    490\u001b[39m     packed = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/ops/while_loop.py:479\u001b[39m, in \u001b[36mwhile_loop.<locals>.<lambda>\u001b[39m\u001b[34m(i, lv)\u001b[39m\n\u001b[32m    476\u001b[39m     loop_vars = (counter, loop_vars)\n\u001b[32m    477\u001b[39m     cond = \u001b[38;5;28;01mlambda\u001b[39;00m i, lv: (  \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[32m    478\u001b[39m         math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     body = \u001b[38;5;28;01mlambda\u001b[39;00m i, lv: (i + \u001b[32m1\u001b[39m, \u001b[43morig_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    480\u001b[39m   try_to_pack = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m executing_eagerly:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/ops/map_fn.py:490\u001b[39m, in \u001b[36mmap_fn.<locals>.compute\u001b[39m\u001b[34m(i, tas)\u001b[39m\n\u001b[32m    488\u001b[39m nest.assert_same_structure(fn_output_signature \u001b[38;5;129;01mor\u001b[39;00m elems, result_value)\n\u001b[32m    489\u001b[39m result_value_flat = nest.flatten(result_value)\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m result_value_batchable = \u001b[43m_result_value_flat_to_batchable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresult_value_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_flat_signature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m tas = [\n\u001b[32m    493\u001b[39m     ta.write(i, value) \u001b[38;5;28;01mfor\u001b[39;00m (ta, value) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tas, result_value_batchable)\n\u001b[32m    494\u001b[39m ]\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (i + \u001b[32m1\u001b[39m, tas)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/ops/map_fn.py:588\u001b[39m, in \u001b[36m_result_value_flat_to_batchable\u001b[39m\u001b[34m(result_value_flat, result_flat_signature)\u001b[39m\n\u001b[32m    586\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    587\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m r_spec.is_compatible_with(r_value):\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    589\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mError in map_fn:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  Expected `fn` to return a:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m    \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    590\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33m  But it returned a:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m    \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m    (value=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    591\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33m  To fix, update the `fn_output_signature` (or `dtype`) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    592\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33margument to `map_fn`.\u001b[39m\u001b[33m\"\u001b[39m %\n\u001b[32m    593\u001b[39m           (r_spec, type_spec.type_spec_from_value(r_value), r_value))\n\u001b[32m    594\u001b[39m     result_value_batchable.extend(r_spec._to_tensor_list(r_value))  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result_value_batchable\n",
      "\u001b[31mValueError\u001b[39m: Error in map_fn:\n  Expected `fn` to return a:\n    RaggedTensorSpec(TensorShape([None, 2]), tf.float32, 1, tf.int64)\n  But it returned a:\n    TensorSpec(shape=(4, 2), dtype=tf.float32, name=None)\n    (value=tf.Tensor(\n[[1. 1.]\n [1. 1.]\n [1. 1.]\n [1. 1.]], shape=(4, 2), dtype=float32))\n  To fix, update the `fn_output_signature` (or `dtype`) argument to `map_fn`."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def process_element(x):\n",
    "    # Create tensor with variable first dimension\n",
    "    size = tf.cast(x * 3, tf.int32) + 1\n",
    "    return tf.ones([size, 2]) * x\n",
    "\n",
    "# Input tensor\n",
    "inputs = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
    "\n",
    "# Map with ragged output\n",
    "ragged_result = tf.map_fn(\n",
    "    process_element,\n",
    "    inputs,\n",
    "    fn_output_signature=tf.RaggedTensorSpec(shape=[None, 2], dtype=tf.float32)\n",
    ")\n",
    "\n",
    "print(ragged_result)\n",
    "# Result will be a RaggedTensor with shapes: (4, 2), (7, 2), (10, 2), (13, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08e13176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 15, 1), dtype=float32, numpy=\n",
       "array([[[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = tf.zeros(shape=(3,15))    \n",
    "pred = tf.expand_dims(pred, axis = 2)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30f18cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5, 1), dtype=int32, numpy=\n",
       "array([[[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]],\n",
       "\n",
       "       [[2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2]]], dtype=int32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "combine_update_index = tf.range(batch_size)\n",
    "combine_update_index = tf.reshape(\n",
    "        combine_update_index, shape=(batch_size, 1, 1))\n",
    "\n",
    "combine_update_index = tf.tile(\n",
    "        combine_update_index, [1, 5, 1])    \n",
    "\n",
    "combine_update_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79547983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
