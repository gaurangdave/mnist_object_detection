{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b335c0b",
   "metadata": {},
   "source": [
    "# Training & Evaluation\n",
    "* In this notebook we are going to 2 kinds of object detection models,\n",
    "    * An Object Detection CNN from scratch, the hypothesis is that since the dataset is simple, we won't need an expert model for object detection. A simple CNN should be able to give us a descent accuracy.\n",
    "    * Object detection using transfer learning - This is going to more of a hands on experience of transfer learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4838cf",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0af58b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 14:09:02.199401: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753304942.213800   62514 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753304942.218254   62514 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753304942.230164   62514 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753304942.230179   62514 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753304942.230181   62514 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753304942.230182   62514 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-23 14:09:02.234661: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "## import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d221c8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "## validate tensorflow \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e49fdf",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c523f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"..\",\"data\")\n",
    "models_dir = Path(\"..\",\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c628582",
   "metadata": {},
   "source": [
    "## Import Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "733001cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Build an absolute path from this notebook's parent directory\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "# Add to sys.path if not already present\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src import data_generator\n",
    "\n",
    "## logic to auto reload scripts without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac63cdf",
   "metadata": {},
   "source": [
    "## Training Object Detection CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf21a93",
   "metadata": {},
   "source": [
    "### Step 1: Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a181f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(Path(data_dir,\"raw\",\"raw_mnist_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aab81f",
   "metadata": {},
   "source": [
    "### Step 2: Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e66e460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_images = data.drop(columns=[\"class\"])\n",
    "raw_labels = data[\"class\"]\n",
    "raw_images.shape, raw_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1f691",
   "metadata": {},
   "source": [
    "### Step 3: Initialize Map Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f3b52c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753304954.919051   62514 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6055 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "X_tensor = tf.convert_to_tensor(raw_images, dtype=tf.float32)\n",
    "X_tensor = tf.reshape(X_tensor,shape=(-1,28,28,1))\n",
    "y_tensor = tf.convert_to_tensor(raw_labels, dtype=tf.float32)\n",
    "\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor,y_tensor))\n",
    "\n",
    "processed_dataset = raw_dataset.map(lambda X,y: tf.numpy_function(data_generator.generate_training_example, inp=[X,y],Tout=(tf.float32,tf.float32)), num_parallel_calls=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc65486",
   "metadata": {},
   "source": [
    "### Step 4: Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1ce7114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Rescaling(scale=1./255),\n",
    "\n",
    "    ## starting with a larger filter since we are dealing with 100x100x1 image\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=5, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=5, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    ## rest of the layers are same as our original mnist classifier\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    ## finaly layers to output 6x6x45 grid of predictions\n",
    "    tf.keras.layers.Conv2D(filters=45, kernel_size=1, padding='same', activation='linear'),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "961fbeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_5 (\u001b[38;5;33mRescaling\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_45 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_46 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_47 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_48 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_21 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_49 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_50 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_22 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_51 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_52 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_23 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_53 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b42f731",
   "metadata": {},
   "source": [
    "### Step 4.1 Define Custom Loss Function\n",
    "Right now our model output has the shape of 6x6x45. Which means we have 36 grid cells, each with 3 possible bounding box and each bounding box is defined by 1 cell for objectness i.e. is a object present this this box, 4 cells for bounding box dimensions (2 for center coordinates and 2 for width and height), and finally 10 cells for one hot encoded classification of digits from 0 to 9.\n",
    "\n",
    "We can break down prediction of these slices into different machine learning problems, for e.g.\n",
    "\n",
    "- 0/1 for objectness score is a binary classification problem\n",
    "- 4 digit bounding box prediction is a regression problem\n",
    "- 10 digits number prediction is multi-class classification problem\n",
    "\n",
    "Since these are different ML problems we cannot have same activation function for them, so our final activation layer needs to be linear (i.e. no activation) and then we’ll apply specific activation to specific slice based on the prediction we want. So\n",
    "\n",
    "- 0/1 problem will be activated using `Sigmoid Activation` function\n",
    "- 4 digit bounding box will be same, a linear activation\n",
    "- 10 digit number problem will be activated using `Softmax Activation`\n",
    "\n",
    "Similarly we’ll use different loss functions for all 3, so\n",
    "\n",
    "- 0/1 problem will use LogLoss function\n",
    "- 4 digit bounding box will use RMSE or MSE loss function\n",
    "- 10 digit class prediction we’ll use `SparseCategoricalCrossEntropy`\n",
    "\n",
    "#### Match Making\n",
    "* We'll also need to find the right grid to calculate the loss function against. We do that by finding the grid cell in which center of ground truth might be present.\n",
    "* In our case we have a 6x6 grid, so 36 cells and lets say we just have 2 images in our ground truth and 3 anchor boxes.\n",
    "* In our first step out of 36 cells we find one or may be 2 cells where the center of these cells lie\n",
    "* For each of cell we'll have 3 anchor boxes and so we'll calculate the IOUs and the 2 with maximum IOUs will win\n",
    "* We take those 2 anchor box, slice the output, apply activation function for objectness and 10 digit classification. Keep coordinates as it is since output of final layer is already linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d1383b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_model_loss(y_true, y_pred):\n",
    "    total_loss = 0\n",
    "    print(f\"y_true.shape {y_true.shape}\")\n",
    "    print(f\"y_pred.shape {y_pred}\")\n",
    "    \n",
    "    return tf.reduce_sum(y_pred)\n",
    "\n",
    "\n",
    "def calculate_model_metrics(y_true, y_pred):\n",
    "    return 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4e5bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is temp code to test the loss function do not use this for training.\n",
    "X_tensor = tf.convert_to_tensor(raw_images.iloc[0:10], dtype=tf.float32)\n",
    "X_tensor = tf.reshape(X_tensor, shape=(-1, 28, 28, 1))\n",
    "y_tensor = tf.convert_to_tensor(raw_labels.iloc[0:10], dtype=tf.float32)\n",
    "\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "\n",
    "def generative_py_function(func, inp, Tout, shape_out):\n",
    "    # This is the bridge that calls your NumPy code\n",
    "    y = tf.numpy_function(func, inp, Tout)\n",
    "    # This is the crucial step: re-apply the shape information\n",
    "    y[0].set_shape(shape_out[0]) # Set shape for the image\n",
    "    y[1].set_shape(shape_out[1]) # Set shape for the labels\n",
    "    return y\n",
    "\n",
    "# Define the exact output shapes you expect\n",
    "output_shapes = ([100, 100, 1], [5, 15]) \n",
    "# Define the exact output data types you expect\n",
    "output_types = (tf.float32, tf.float32)\n",
    "\n",
    "\n",
    "# processed_dataset = raw_dataset.map(lambda X, y: tf.numpy_function(data_generator.generate_training_example, inp=[X, y], Tout=(\n",
    "#     tf.float32, tf.float32)), num_parallel_calls=15);\n",
    "\n",
    "# Use the wrapper inside the map\n",
    "processed_dataset = raw_dataset.map(lambda X, y: generative_py_function(\n",
    "    data_generator.generate_training_example, \n",
    "    inp=[X, y], \n",
    "    Tout=output_types, # Pass the dtypes to Tout\n",
    "    shape_out=output_shapes # Pass the shapes to our new argument\n",
    ")).batch(batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0655a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=calculate_model_loss,\n",
    "              metrics=[calculate_model_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c7d7e1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true.shape (None, 5, 15)\n",
      "y_pred.shape Tensor(\"sequential_5_1/conv2d_53_1/BiasAdd:0\", shape=(None, 6, 6, 45), dtype=float32)\n",
      "y_true.shape (None, 5, 15)\n",
      "y_pred.shape Tensor(\"sequential_5_1/conv2d_53_1/BiasAdd:0\", shape=(None, 6, 6, 45), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753316503.916880   62889 service.cc:152] XLA service 0x7f0ecc027810 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753316503.916925   62889 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 SUPER, Compute Capability 7.5\n",
      "2025-07-23 17:21:44.008538: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1753316504.369609   62889 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-07-23 17:21:45.261050: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.29 = (f32[5,8,50,50]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,8,50,50]{3,2,1,0} %bitcast.4457, f32[8,8,3,3]{3,2,1,0} %bitcast.3642, f32[8]{0} %bitcast.4517), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/conv2d_47_1/convolution\" source_file=\"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-23 17:21:45.316542: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.32 = (f32[5,16,25,25]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,16,25,25]{3,2,1,0} %bitcast.4821, f32[16,16,3,3]{3,2,1,0} %bitcast.3697, f32[16]{0} %bitcast.4881), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/conv2d_50_1/convolution\" source_file=\"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-23 17:21:45.367952: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.33 = (f32[5,32,12,12]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,16,12,12]{3,2,1,0} %bitcast.4942, f32[32,16,3,3]{3,2,1,0} %bitcast.3716, f32[32]{0} %bitcast.5002), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/conv2d_51_1/convolution\" source_file=\"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-07-23 17:21:45.373189: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.34 = (f32[5,32,12,12]{3,2,1,0}, u8[0]{0}) custom-call(f32[5,32,12,12]{3,2,1,0} %bitcast.5064, f32[32,32,3,3]{3,2,1,0} %bitcast.3734, f32[32]{0} %bitcast.5124), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/conv2d_52_1/convolution\" source_file=\"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - calculate_model_metrics: 0.9000 - loss: -17.2397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753316507.235004   62889 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f0fc7009700>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "model.fit(processed_dataset,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc6f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
