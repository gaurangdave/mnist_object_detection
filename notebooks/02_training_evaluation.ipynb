{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b335c0b",
   "metadata": {},
   "source": [
    "# Training & Evaluation\n",
    "* In this notebook we are going to 2 kinds of object detection models,\n",
    "    * An Object Detection CNN from scratch, the hypothesis is that since the dataset is simple, we won't need an expert model for object detection. A simple CNN should be able to give us a descent accuracy.\n",
    "    * Object detection using transfer learning - This is going to more of a hands on experience of transfer learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4838cf",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0af58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d221c8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "## validate tensorflow \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e49fdf",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0c523f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"..\",\"data\")\n",
    "models_dir = Path(\"..\",\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c628582",
   "metadata": {},
   "source": [
    "## Import Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "733001cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Build an absolute path from this notebook's parent directory\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "# Add to sys.path if not already present\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src import data_generator,training_utils\n",
    "\n",
    "## logic to auto reload scripts without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac63cdf",
   "metadata": {},
   "source": [
    "## Training Object Detection CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf21a93",
   "metadata": {},
   "source": [
    "### Step 1: Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a181f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(Path(data_dir,\"raw\",\"raw_mnist_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aab81f",
   "metadata": {},
   "source": [
    "### Step 2: Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e66e460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_images = data.drop(columns=[\"class\"])\n",
    "raw_labels = data[\"class\"]\n",
    "raw_images.shape, raw_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1f691",
   "metadata": {},
   "source": [
    "### Step 3: Initialize Map Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f3b52c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = tf.convert_to_tensor(raw_images, dtype=tf.float32)\n",
    "X_tensor = tf.reshape(X_tensor,shape=(-1,28,28,1))\n",
    "y_tensor = tf.convert_to_tensor(raw_labels, dtype=tf.float32)\n",
    "\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor,y_tensor))\n",
    "\n",
    "processed_dataset = raw_dataset.map(lambda X,y: tf.numpy_function(data_generator.generate_training_example, inp=[X,y],Tout=(tf.float32,tf.float32)), num_parallel_calls=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc65486",
   "metadata": {},
   "source": [
    "### Step 4: Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ce7114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Rescaling(scale=1./255),\n",
    "\n",
    "    ## starting with a larger filter since we are dealing with 100x100x1 image\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=5, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=5, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    ## rest of the layers are same as our original mnist classifier\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    ## finaly layers to output 6x6x45 grid of predictions\n",
    "    tf.keras.layers.Conv2D(filters=45, kernel_size=1, padding='same', activation='linear'),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "961fbeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_2 (\u001b[38;5;33mRescaling\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_54 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_55 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_24 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_56 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_57 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_25 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_58 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_59 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_26 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_60 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_61 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_27 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_62 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b42f731",
   "metadata": {},
   "source": [
    "### Step 4.1 Define Custom Loss Function\n",
    "Right now our model output has the shape of 6x6x45. Which means we have 36 grid cells, each with 3 possible bounding box and each bounding box is defined by 1 cell for objectness i.e. is a object present this this box, 4 cells for bounding box dimensions (2 for center coordinates and 2 for width and height), and finally 10 cells for one hot encoded classification of digits from 0 to 9.\n",
    "\n",
    "We can break down prediction of these slices into different machine learning problems, for e.g.\n",
    "\n",
    "- 0/1 for objectness score is a binary classification problem\n",
    "- 4 digit bounding box prediction is a regression problem\n",
    "- 10 digits number prediction is multi-class classification problem\n",
    "\n",
    "Since these are different ML problems we cannot have same activation function for them, so our final activation layer needs to be linear (i.e. no activation) and then we’ll apply specific activation to specific slice based on the prediction we want. So\n",
    "\n",
    "- 0/1 problem will be activated using `Sigmoid Activation` function\n",
    "- 4 digit bounding box will be same, a linear activation\n",
    "- 10 digit number problem will be activated using `Softmax Activation`\n",
    "\n",
    "Similarly we’ll use different loss functions for all 3, so\n",
    "\n",
    "- 0/1 problem will use LogLoss function\n",
    "- 4 digit bounding box will use RMSE or MSE loss function\n",
    "- 10 digit class prediction we’ll use `SparseCategoricalCrossEntropy`\n",
    "\n",
    "#### Match Making\n",
    "* We'll also need to find the right grid to calculate the loss function against. We do that by finding the grid cell in which center of ground truth might be present.\n",
    "* In our case we have a 6x6 grid, so 36 cells and lets say we just have 2 images in our ground truth and 3 anchor boxes.\n",
    "* In our first step out of 36 cells we find one or may be 2 cells where the center of these cells lie\n",
    "* For each of cell we'll have 3 anchor boxes and so we'll calculate the IOUs and the 2 with maximum IOUs will win\n",
    "* We take those 2 anchor box, slice the output, apply activation function for objectness and 10 digit classification. Keep coordinates as it is since output of final layer is already linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9707dc57",
   "metadata": {},
   "source": [
    "Quick Notes on how to Match make\n",
    "* Create a empty 100x100 grid (we can also create constant for grid cells)\n",
    "* For each cell check if "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c6938",
   "metadata": {},
   "source": [
    "##### Cutom Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6d955",
   "metadata": {},
   "source": [
    "* The cell below manually runs the model for one instance of dataset. This was used to verify and debug custom loss and metrics function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b302aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is temp code to test the loss function do not use this for training.\n",
    "# X_tensor = tf.convert_to_tensor(raw_images.iloc[0:10], dtype=tf.float32)\n",
    "# X_tensor = tf.reshape(X_tensor, shape=(-1, 28, 28, 1))\n",
    "# y_tensor = tf.convert_to_tensor(raw_labels.iloc[0:10], dtype=tf.float32)\n",
    "\n",
    "\n",
    "# raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "\n",
    "# def generative_py_function(func, inp, Tout, shape_out):\n",
    "#     # This is the bridge that calls your NumPy code\n",
    "#     y = tf.numpy_function(func, inp, Tout)\n",
    "#     # This is the crucial step: re-apply the shape information\n",
    "#     y[0].set_shape(shape_out[0]) # Set shape for the image\n",
    "#     y[1].set_shape(shape_out[1]) # Set shape for the labels\n",
    "#     return y\n",
    "\n",
    "# # Define the exact output shapes you expect\n",
    "# output_shapes = ([100, 100, 1], [5, 15]) \n",
    "# # Define the exact output data types you expect\n",
    "# output_types = (tf.float32, tf.float32)\n",
    "\n",
    "\n",
    "# processed_dataset = raw_dataset.map(lambda X, y: tf.numpy_function(data_generator.generate_training_example, inp=[X, y], Tout=(\n",
    "#     tf.float32, tf.float32)), num_parallel_calls=15);\n",
    "\n",
    "# # Use the wrapper inside the map\n",
    "# processed_dataset = raw_dataset.map(lambda X, y: generative_py_function(\n",
    "#     data_generator.generate_training_example, \n",
    "#     inp=[X, y], \n",
    "#     Tout=output_types, # Pass the dtypes to Tout\n",
    "#     shape_out=output_shapes # Pass the shapes to our new argument\n",
    "# )).batch(batch_size=8)\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=training_utils.calculate_model_loss,\n",
    "#               metrics=[training_utils.objectness_metrics, training_utils.bounding_box_metrics, training_utils.classification_metrics])\n",
    "# # Step 1: Get one batch of data from your dataset pipeline\n",
    "# # The .take(1) method creates a new dataset with only the first element.\n",
    "# one_batch = processed_dataset.take(1)\n",
    "\n",
    "# # Step 2: Iterate over the single batch to get the tensors\n",
    "# for images, labels in one_batch:\n",
    "    \n",
    "#     # --- THIS IS YOUR DEBUGGING ZONE ---\n",
    "#     # Now you have the concrete tensors for one batch.\n",
    "#     # You can inspect them with regular print() and .numpy()\n",
    "    \n",
    "#     # print(\"--- Inspecting Data Before Loss Calculation ---\")\n",
    "#     # print(\"Shape of images (X_batch):\", images.shape)\n",
    "#     # print(\"Shape of labels (y_true_batch):\", labels.shape)\n",
    "#     # print(\"\\nSample y_true label tensor:\\n\", labels.numpy()[0]) # Print the first label in the batch\n",
    "#     # ------------------------------------\n",
    "\n",
    "#     # Step 3: Manually run the forward pass and gradient calculation\n",
    "#     with tf.GradientTape() as tape:\n",
    "        \n",
    "#         # Get the model's raw predictions for this batch\n",
    "#         y_pred = model(images, training=True)  # Pass the images through the model\n",
    "        \n",
    "#         # --- MORE DEBUGGING ---\n",
    "#         print(\"\\n--- Inspecting Tensors Passed to Loss Function ---\")\n",
    "#         print(\"Shape of y_pred from model:\", y_pred.shape)\n",
    "#         # print(\"\\nSample y_pred tensor (first 5 values of first anchor):\\n\", y_pred.numpy()[0, 0, 0, :5])\n",
    "#         # ----------------------\n",
    "\n",
    "#         # Call your custom loss function\n",
    "#         # You can now add print statements INSIDE your loss function too!\n",
    "#         loss_value = calculate_model_loss(labels, y_pred)\n",
    "        \n",
    "#         print(\"\\n--- Final Calculated Loss ---\")\n",
    "#         print(\"Total Loss for the batch:\", loss_value.numpy())\n",
    "#         # -----------------------------\n",
    "\n",
    "#     # Step 4 (Optional): Calculate and apply gradients to see the full loop\n",
    "#     # grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "#     # model.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "#     print(\"\\n--- Manual Step Complete ---\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fa6935",
   "metadata": {},
   "source": [
    "### Step 4.2 Train the Model for 20 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f9a6a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = tf.convert_to_tensor(raw_images, dtype=tf.float32)\n",
    "X_tensor = tf.reshape(X_tensor,shape=(-1,28,28,1))\n",
    "y_tensor = tf.convert_to_tensor(raw_labels, dtype=tf.float32)\n",
    "batch_size = 8\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "def generative_py_function(func, inp, Tout, shape_out):\n",
    "    # This is the bridge that calls your NumPy code\n",
    "    y = tf.numpy_function(func, inp, Tout)\n",
    "    # This is the crucial step: re-apply the shape information\n",
    "    y[0].set_shape(shape_out[0]) # Set shape for the image\n",
    "    y[1].set_shape(shape_out[1]) # Set shape for the labels\n",
    "    return y\n",
    "\n",
    "# Define the exact output shapes you expect\n",
    "output_shapes = ([100, 100, 1], [5,15]) \n",
    "# Define the exact output data types you expect\n",
    "output_types = (tf.float32, tf.float32)\n",
    "\n",
    "# Use the wrapper inside the map\n",
    "processed_dataset = raw_dataset.map(lambda X, y: generative_py_function(\n",
    "    data_generator.generate_training_example, \n",
    "    inp=[X, y], \n",
    "    Tout=output_types, # Pass the dtypes to Tout\n",
    "    shape_out=output_shapes # Pass the shapes to our new argument\n",
    ")).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5898ea11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,485</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_63 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m8\u001b[0m)       │           \u001b[38;5;34m208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_64 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m8\u001b[0m)       │         \u001b[38;5;34m1,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_28 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_65 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │           \u001b[38;5;34m584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_66 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │           \u001b[38;5;34m584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_29 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_67 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m1,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_68 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m2,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_30 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_69 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_70 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_31 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_71 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m45\u001b[0m)          │         \u001b[38;5;34m1,485\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,845</span> (85.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,845\u001b[0m (85.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,845</span> (85.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,845\u001b[0m (85.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(100,100,1),batch_size=batch_size ,name=\"input_layer\")\n",
    "\n",
    "x = tf.keras.layers.Rescaling(scale=1./255, name=\"rescaling\")(inputs)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=5, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=5, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "outputs = tf.keras.layers.Conv2D(filters=45, kernel_size=1, padding='same', activation='linear')(x)\n",
    "\n",
    "# Define the final model by specifying its inputs and outputs\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b023cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: Define the callbacks\n",
    "checkpoint_filepath = '../models/experiment_1_{epoch:02d}.keras'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "56deb57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- True Values -----\n",
      "y_true.shape (None, 5, 15)\n",
      "----- Pred Values -----\n",
      "y_pred.shape (None, 6, 6, 45)\n",
      "anchor_boxes.shape (None, 6, 6, 3, 15)\n",
      "grid indices shape (None, 5, 2)\n",
      "selected_anchor_boxes.shape :(None, 5, 3, 15)\n",
      "y_true_boxes.shape (None, 5, 1, 4)\n",
      "y_pred_boxes.shape (None, 5, 3, 4)\n",
      "intersection_box_corners.shape (None, 5, 3, 4)\n",
      "intersection_area.shape (None, 5, 3)\n",
      "union_area.shape (None, 5, 3)\n",
      "iou.shape (None, 5, 3)\n",
      "highest_iou_index.shape (None, 5)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Failed to convert elements of (None, 5, -1) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m## step 5: Fit the model\u001b[39;00m\n\u001b[32m      5\u001b[39m epochs=\u001b[32m20\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m  \u001b[49m\u001b[43mprocessed_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/src/training_utils.py:166\u001b[39m, in \u001b[36mcalculate_model_loss\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalculate_model_loss\u001b[39m(y_true, y_pred):\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m## Find best anchor box\u001b[39;00m\n\u001b[32m    165\u001b[39m     expanded_y_true = tf.expand_dims(y_true, axis=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     best_anchor_boxes = \u001b[43mcalculate_best_anchor_boxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m## Loss Calculation\u001b[39;00m\n\u001b[32m    169\u001b[39m     objectness_loss, bounding_box_loss, classification_loss = calculate_loss(best_anchor_boxes,expanded_y_true)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/src/training_utils.py:115\u001b[39m, in \u001b[36mcalculate_best_anchor_boxes\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m    113\u001b[39m highest_iou_index = tf.argmax(iou, axis=\u001b[32m2\u001b[39m)\n\u001b[32m    114\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhighest_iou_index.shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhighest_iou_index.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m highest_iou_index = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhighest_iou_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43miou\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43miou\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhighest_iou_index.shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhighest_iou_index.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m## select the anchor box based on the index\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: Failed to convert elements of (None, 5, -1) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=training_utils.calculate_model_loss,\n",
    "              metrics=[training_utils.objectness_metrics, training_utils.bounding_box_metrics, training_utils.classification_metrics])\n",
    "## step 5: Fit the model\n",
    "epochs=20\n",
    "\n",
    "history = model.fit(\n",
    "  processed_dataset,\n",
    "  epochs=epochs,\n",
    "  callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13c3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
