{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b335c0b",
   "metadata": {},
   "source": [
    "# Training & Evaluation\n",
    "* In this notebook we are going to 2 kinds of object detection models,\n",
    "    * An Object Detection CNN from scratch, the hypothesis is that since the dataset is simple, we won't need an expert model for object detection. A simple CNN should be able to give us a descent accuracy.\n",
    "    * Object detection using transfer learning - This is going to more of a hands on experience of transfer learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4838cf",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0af58b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 23:35:28.517643: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753857328.533077  438852 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753857328.537871  438852 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753857328.550861  438852 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753857328.550888  438852 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753857328.550889  438852 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753857328.550891  438852 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-29 23:35:28.555464: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "## import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d221c8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "## validate tensorflow \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e49fdf",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c523f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"..\",\"data\")\n",
    "models_dir = Path(\"..\",\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c628582",
   "metadata": {},
   "source": [
    "## Import Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "733001cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Build an absolute path from this notebook's parent directory\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "# Add to sys.path if not already present\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src import data_generator,training_utils\n",
    "\n",
    "## logic to auto reload scripts without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac63cdf",
   "metadata": {},
   "source": [
    "## Training Object Detection CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf21a93",
   "metadata": {},
   "source": [
    "### Step 1: Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a181f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(Path(data_dir,\"raw\",\"raw_mnist_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aab81f",
   "metadata": {},
   "source": [
    "### Step 2: Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e66e460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_images = data.drop(columns=[\"class\"])\n",
    "raw_labels = data[\"class\"]\n",
    "raw_images.shape, raw_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1f691",
   "metadata": {},
   "source": [
    "### Step 3: Initialize Map Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f3b52c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753857337.672225  438852 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6055 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "X_tensor = tf.convert_to_tensor(raw_images, dtype=tf.float32)\n",
    "X_tensor = tf.reshape(X_tensor,shape=(-1,28,28,1))\n",
    "y_tensor = tf.convert_to_tensor(raw_labels, dtype=tf.float32)\n",
    "\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor,y_tensor))\n",
    "\n",
    "processed_dataset = raw_dataset.map(lambda X,y: tf.numpy_function(data_generator.generate_training_example, inp=[X,y],Tout=(tf.float32,tf.float32)), num_parallel_calls=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc65486",
   "metadata": {},
   "source": [
    "### Step 4: Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce7114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Rescaling(scale=1./255),\n",
    "\n",
    "    ## starting with a larger filter since we are dealing with 100x100x1 image\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=5, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=5, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    ## rest of the layers are same as our original mnist classifier\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    ## finaly layers to output 6x6x45 grid of predictions\n",
    "    tf.keras.layers.Conv2D(filters=45, kernel_size=1, padding='same', activation='linear'),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "961fbeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b42f731",
   "metadata": {},
   "source": [
    "### Step 4.1 Define Custom Loss Function\n",
    "Right now our model output has the shape of 6x6x45. Which means we have 36 grid cells, each with 3 possible bounding box and each bounding box is defined by 1 cell for objectness i.e. is a object present this this box, 4 cells for bounding box dimensions (2 for center coordinates and 2 for width and height), and finally 10 cells for one hot encoded classification of digits from 0 to 9.\n",
    "\n",
    "We can break down prediction of these slices into different machine learning problems, for e.g.\n",
    "\n",
    "- 0/1 for objectness score is a binary classification problem\n",
    "- 4 digit bounding box prediction is a regression problem\n",
    "- 10 digits number prediction is multi-class classification problem\n",
    "\n",
    "Since these are different ML problems we cannot have same activation function for them, so our final activation layer needs to be linear (i.e. no activation) and then we’ll apply specific activation to specific slice based on the prediction we want. So\n",
    "\n",
    "- 0/1 problem will be activated using `Sigmoid Activation` function\n",
    "- 4 digit bounding box will be same, a linear activation\n",
    "- 10 digit number problem will be activated using `Softmax Activation`\n",
    "\n",
    "Similarly we’ll use different loss functions for all 3, so\n",
    "\n",
    "- 0/1 problem will use LogLoss function\n",
    "- 4 digit bounding box will use RMSE or MSE loss function\n",
    "- 10 digit class prediction we’ll use `SparseCategoricalCrossEntropy`\n",
    "\n",
    "#### Match Making\n",
    "* We'll also need to find the right grid to calculate the loss function against. We do that by finding the grid cell in which center of ground truth might be present.\n",
    "* In our case we have a 6x6 grid, so 36 cells and lets say we just have 2 images in our ground truth and 3 anchor boxes.\n",
    "* In our first step out of 36 cells we find one or may be 2 cells where the center of these cells lie\n",
    "* For each of cell we'll have 3 anchor boxes and so we'll calculate the IOUs and the 2 with maximum IOUs will win\n",
    "* We take those 2 anchor box, slice the output, apply activation function for objectness and 10 digit classification. Keep coordinates as it is since output of final layer is already linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9707dc57",
   "metadata": {},
   "source": [
    "Quick Notes on how to Match make\n",
    "* Create a empty 100x100 grid (we can also create constant for grid cells)\n",
    "* For each cell check if "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c6938",
   "metadata": {},
   "source": [
    "##### Cutom Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6d955",
   "metadata": {},
   "source": [
    "* The cell below manually runs the model for one instance of dataset. This was used to verify and debug custom loss and metrics function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b302aa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753857339.485985  438852 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inspecting Tensors Passed to Loss Function ---\n",
      "Shape of y_pred from model: (8, 6, 6, 45)\n",
      "----- True Values -----\n",
      "y_true.shape (8, 5, 15)\n",
      "----- Pred Values -----\n",
      "y_pred.shape (8, 6, 6, 45)\n",
      "anchor_boxes.shape (8, 6, 6, 3, 15)\n",
      "grid indices shape (8, 5, 2)\n",
      "selected_anchor_boxes.shape :(8, 5, 3, 15)\n",
      "anchor_boxes.shape (8, 6, 6, 3, 15)\n",
      "selected_anchor_boxes.shape :(8, 5, 3, 15)\n",
      "y_true_boxes.shape (8, 5, 1, 4)\n",
      "y_pred_boxes.shape (8, 5, 3, 4)\n",
      "intersection_box_corners.shape (8, 5, 3, 4)\n",
      "intersection_area.shape (8, 5, 3)\n",
      "union_area.shape (8, 5, 3)\n",
      "iou.shape (8, 5, 3)\n",
      "highest_iou_index.shape (8, 5)\n",
      "expanded highest_iou_index.shape (8, 5, 1)\n",
      "best_anchor_boxes.shape (8, 5, 1, 15)\n",
      "true_values_with_objects.shape : (16, 15)\n",
      "predicted_values_with_objects.shape : (16, 15)\n",
      "y_pred_objectness.shape : (16,)\n",
      "y_pred_bounding_box.shape : (16, 4)\n",
      "y_pred_classification.shape : (16, 10)\n",
      "y_true_objectness.shape : (16,)\n",
      "y_true_bounding_box.shape : (16, 4)\n",
      "y_true_classification.shape : (16, 10)\n",
      "Post Activation y_pred_objectness.shape : (16,)\n",
      "Post Activation y_pred_classification.shape : (16, 10)\n",
      "\n",
      "\n",
      "----- Localization Loss -----\n",
      "objectness_loss : 0.693651556968689\n",
      "bounding_box_loss : 1854.1263427734375\n",
      "classification_loss : 2.302497386932373\n",
      "\n",
      "\n",
      "----- Calculation Object Less Loss -----\n",
      "positive_mask.shape (8, 6, 6, 3)\n",
      "grid indices shape (8, 5, 2)\n",
      "anchor_boxes.shape (8, 6, 6, 3, 15)\n",
      "selected_anchor_boxes.shape :(8, 5, 3, 15)\n",
      "y_true_boxes.shape (8, 5, 1, 4)\n",
      "y_pred_boxes.shape (8, 5, 3, 4)\n",
      "intersection_box_corners.shape (8, 5, 3, 4)\n",
      "intersection_area.shape (8, 5, 3)\n",
      "union_area.shape (8, 5, 3)\n",
      "iou.shape (8, 5, 3)\n",
      "highest_iou_index.shape (8, 5)\n",
      "expanded highest_iou_index.shape (8, 5, 1)\n",
      "highest_iou_index.shape (8, 5, 1)\n",
      "combine_update_index.shape : (16, 4)\n",
      "negative_mask.shape : (8, 6, 6, 3)\n",
      "masked_values.shape : (848, 15)\n",
      "y_true_objectless.shape (848, 15)\n",
      "y_pred_objectness.shape : (848,)\n",
      "y_true_objectness.shape : (848,)\n",
      "Post Activation y_pred_objectness.shape : (848,)\n",
      "\n",
      "\n",
      "----- Object Less Loss -----\n",
      "objectless_loss : 0.0\n",
      "\n",
      "\n",
      "Total Loss : 4.85027551651001\n",
      "\n",
      "--- Final Calculated Loss ---\n",
      "Total Loss for the batch: 4.8502755\n",
      "\n",
      "--- Manual Step Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 23:35:40.748492: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# This is temp code to test the loss function do not use this for training.\n",
    "X_tensor = tf.convert_to_tensor(raw_images.iloc[0:10], dtype=tf.float32)\n",
    "X_tensor = tf.reshape(X_tensor, shape=(-1, 28, 28, 1))\n",
    "y_tensor = tf.convert_to_tensor(raw_labels.iloc[0:10], dtype=tf.float32)\n",
    "\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "\n",
    "def generative_py_function(func, inp, Tout, shape_out):\n",
    "    # This is the bridge that calls your NumPy code\n",
    "    y = tf.numpy_function(func, inp, Tout)\n",
    "    # This is the crucial step: re-apply the shape information\n",
    "    y[0].set_shape(shape_out[0]) # Set shape for the image\n",
    "    y[1].set_shape(shape_out[1]) # Set shape for the labels\n",
    "    return y\n",
    "\n",
    "# Define the exact output shapes you expect\n",
    "output_shapes = ([100, 100, 1], [5, 15]) \n",
    "# Define the exact output data types you expect\n",
    "output_types = (tf.float32, tf.float32)\n",
    "\n",
    "\n",
    "processed_dataset = raw_dataset.map(lambda X, y: tf.numpy_function(data_generator.generate_training_example, inp=[X, y], Tout=(\n",
    "    tf.float32, tf.float32)), num_parallel_calls=15);\n",
    "\n",
    "# Use the wrapper inside the map\n",
    "processed_dataset = raw_dataset.map(lambda X, y: generative_py_function(\n",
    "    data_generator.generate_training_example, \n",
    "    inp=[X, y], \n",
    "    Tout=output_types, # Pass the dtypes to Tout\n",
    "    shape_out=output_shapes # Pass the shapes to our new argument\n",
    ")).batch(batch_size=8)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=training_utils.calculate_model_loss,\n",
    "              metrics=[training_utils.objectness_metrics, training_utils.bounding_box_metrics, training_utils.classification_metrics])\n",
    "# Step 1: Get one batch of data from your dataset pipeline\n",
    "# The .take(1) method creates a new dataset with only the first element.\n",
    "one_batch = processed_dataset.take(1)\n",
    "\n",
    "# Step 2: Iterate over the single batch to get the tensors\n",
    "for images, labels in one_batch:\n",
    "    \n",
    "    # --- THIS IS YOUR DEBUGGING ZONE ---\n",
    "    # Now you have the concrete tensors for one batch.\n",
    "    # You can inspect them with regular print() and .numpy()\n",
    "    \n",
    "    # print(\"--- Inspecting Data Before Loss Calculation ---\")\n",
    "    # print(\"Shape of images (X_batch):\", images.shape)\n",
    "    # print(\"Shape of labels (y_true_batch):\", labels.shape)\n",
    "    # print(\"\\nSample y_true label tensor:\\n\", labels.numpy()[0]) # Print the first label in the batch\n",
    "    # ------------------------------------\n",
    "\n",
    "    # Step 3: Manually run the forward pass and gradient calculation\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        # Get the model's raw predictions for this batch\n",
    "        y_pred = model(images, training=True)  # Pass the images through the model\n",
    "        \n",
    "        # --- MORE DEBUGGING ---\n",
    "        print(\"\\n--- Inspecting Tensors Passed to Loss Function ---\")\n",
    "        print(\"Shape of y_pred from model:\", y_pred.shape)\n",
    "        # print(\"\\nSample y_pred tensor (first 5 values of first anchor):\\n\", y_pred.numpy()[0, 0, 0, :5])\n",
    "        # ----------------------\n",
    "\n",
    "        # Call your custom loss function\n",
    "        # You can now add print statements INSIDE your loss function too!\n",
    "        loss_value = training_utils.calculate_model_loss(labels, y_pred)\n",
    "        \n",
    "        print(\"\\n--- Final Calculated Loss ---\")\n",
    "        \n",
    "        print(\"Total Loss for the batch:\", loss_value.numpy())\n",
    "        # -----------------------------\n",
    "\n",
    "    # Step 4 (Optional): Calculate and apply gradients to see the full loop\n",
    "    # grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    # model.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    print(\"\\n--- Manual Step Complete ---\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fa6935",
   "metadata": {},
   "source": [
    "### Step 4.2 Train the Model for 20 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "670f11ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63000, 785), (7000, 785))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train test split\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in splitter.split(data,data[\"class\"]):\n",
    "    mnist_dev_set = data.iloc[train_idx].reset_index(drop=True)\n",
    "    mnist_test_set = data.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "mnist_dev_set.shape,mnist_test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd1e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images = mnist_dev_set.drop(columns=[\"class\"])\n",
    "raw_labels = mnist_dev_set[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9a6a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = tf.convert_to_tensor(raw_images, dtype=tf.float32)\n",
    "X_tensor = tf.reshape(X_tensor,shape=(-1,28,28,1))\n",
    "y_tensor = tf.convert_to_tensor(raw_labels, dtype=tf.float32)\n",
    "batch_size = 32\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "def generative_py_function(func, inp, Tout, shape_out):\n",
    "    # This is the bridge that calls your NumPy code\n",
    "    y = tf.numpy_function(func, inp, Tout)\n",
    "    # This is the crucial step: re-apply the shape information\n",
    "    y[0].set_shape(shape_out[0]) # Set shape for the image\n",
    "    y[1].set_shape(shape_out[1]) # Set shape for the labels\n",
    "    return y\n",
    "\n",
    "# Define the exact output shapes you expect\n",
    "output_shapes = ([100, 100, 1], [5,15]) \n",
    "# Define the exact output data types you expect\n",
    "output_types = (tf.float32, tf.float32)\n",
    "\n",
    "# Use the wrapper inside the map\n",
    "processed_dataset = raw_dataset.map(lambda X, y: generative_py_function(\n",
    "    data_generator.generate_training_example, \n",
    "    inp=[X, y], \n",
    "    Tout=output_types, # Pass the dtypes to Tout\n",
    "    shape_out=output_shapes # Pass the shapes to our new argument\n",
    ")).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5898ea11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,485</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │           \u001b[38;5;34m208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │         \u001b[38;5;34m1,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │         \u001b[38;5;34m1,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │         \u001b[38;5;34m2,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m45\u001b[0m)         │         \u001b[38;5;34m1,485\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,845</span> (85.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,845\u001b[0m (85.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,845</span> (85.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,845\u001b[0m (85.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(100,100,1),batch_size=batch_size ,name=\"input_layer\")\n",
    "\n",
    "x = tf.keras.layers.Rescaling(scale=1./255, name=\"rescaling\")(inputs)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=5, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=5, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "outputs = tf.keras.layers.Conv2D(filters=45, kernel_size=1, padding='same', activation='linear')(x)\n",
    "\n",
    "# Define the final model by specifying its inputs and outputs\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b023cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: Define the callbacks\n",
    "checkpoint_filepath = '../models/experiment_1_{epoch:02d}.keras'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56deb57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----- True Values -----\n",
      "y_true.shape (None, 5, 15)\n",
      "----- Pred Values -----\n",
      "y_pred.shape (None, 6, 6, 45)\n",
      "anchor_boxes.shape (None, 6, 6, 3, 15)\n",
      "grid indices shape (None, 5, 2)\n",
      "selected_anchor_boxes.shape :(None, 5, 3, 15)\n",
      "anchor_boxes.shape (None, 6, 6, 3, 15)\n",
      "selected_anchor_boxes.shape :(None, 5, 3, 15)\n",
      "y_true_boxes.shape (None, 5, 1, 4)\n",
      "y_pred_boxes.shape (None, 5, 3, 4)\n",
      "intersection_box_corners.shape (None, 5, 3, 4)\n",
      "intersection_area.shape (None, 5, 3)\n",
      "union_area.shape (None, 5, 3)\n",
      "iou.shape (None, 5, 3)\n",
      "highest_iou_index.shape (None, 5)\n",
      "expanded highest_iou_index.shape (None, 5, 1)\n",
      "best_anchor_boxes.shape (None, 5, 1, 15)\n",
      "true_values_with_objects.shape : (None, 15)\n",
      "predicted_values_with_objects.shape : (None, 15)\n",
      "y_pred_objectness.shape : (None,)\n",
      "y_pred_bounding_box.shape : (None, 4)\n",
      "y_pred_classification.shape : (None, 10)\n",
      "y_true_objectness.shape : (None,)\n",
      "y_true_bounding_box.shape : (None, 4)\n",
      "y_true_classification.shape : (None, 10)\n",
      "Post Activation y_pred_objectness.shape : (None,)\n",
      "Post Activation y_pred_classification.shape : (None, 10)\n",
      "\n",
      "\n",
      "----- Localization Loss -----\n",
      "objectness_loss : Tensor(\"compile_loss/calculate_model_loss/binary_crossentropy/Mean:0\", shape=(), dtype=float32)\n",
      "bounding_box_loss : Tensor(\"compile_loss/calculate_model_loss/mean_squared_error/div_no_nan:0\", shape=(), dtype=float32)\n",
      "classification_loss : Tensor(\"compile_loss/calculate_model_loss/categorical_crossentropy/div_no_nan:0\", shape=(), dtype=float32)\n",
      "\n",
      "\n",
      "----- Calculation Object Less Loss -----\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic tf.Tensor (compile_loss/calculate_model_loss/strided_slice_46:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m## step 5: Fit the model\u001b[39;00m\n\u001b[32m      5\u001b[39m epochs=\u001b[32m5\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m  \u001b[49m\u001b[43mprocessed_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:10\u001b[39m, in \u001b[36mcalculate_model_loss\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:4\u001b[39m, in \u001b[36mcalculate_objectless_loss\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3493\u001b[39m, in \u001b[36mprod\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   3369\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[32m   3370\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprod\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue,\n\u001b[32m   3371\u001b[39m          initial=np._NoValue, where=np._NoValue):\n\u001b[32m   3372\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3373\u001b[39m \u001b[33;03m    Return the product of array elements over a given axis.\u001b[39;00m\n\u001b[32m   3374\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3491\u001b[39m \u001b[33;03m    10\u001b[39;00m\n\u001b[32m   3492\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3493\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmultiply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprod\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3494\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:86\u001b[39m, in \u001b[36m_wrapreduction\u001b[39m\u001b[34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis=axis, out=out, **passkwargs)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mNotImplementedError\u001b[39m: Cannot convert a symbolic tf.Tensor (compile_loss/calculate_model_loss/strided_slice_46:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,clipnorm=1.0),\n",
    "              loss=training_utils.calculate_model_loss,\n",
    "              metrics=[training_utils.objectness_metrics, training_utils.bounding_box_metrics, training_utils.classification_metrics])\n",
    "## step 5: Fit the model\n",
    "epochs=5\n",
    "\n",
    "history = model.fit(\n",
    "  processed_dataset,\n",
    "  epochs=epochs,\n",
    "  callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13c3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
