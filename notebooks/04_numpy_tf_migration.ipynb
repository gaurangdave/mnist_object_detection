{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364c7e70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05508ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 12:16:57.376813: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757531817.395613   23614 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757531817.401381   23614 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757531817.416474   23614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757531817.416499   23614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757531817.416501   23614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757531817.416502   23614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-10 12:16:57.421841: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import fetch_openml\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from matplotlib import patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96daf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d8211",
   "metadata": {},
   "source": [
    "## Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42f27dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"..\",\"data\")\n",
    "models_dir = Path(\"..\",\"models\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c142098",
   "metadata": {},
   "source": [
    "## Defining Bench Mark Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4773b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        print(f\"---- Epoch {epoch_num} ----\")\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            time.sleep(0.01)\n",
    "        print(f\"Execution time for epoch {epoch_num} : {time.perf_counter() - start_time}\")\n",
    "    print(\"Total Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f809c",
   "metadata": {},
   "source": [
    "## Data Generation with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b440b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MNIST_DATA_PIXELS = x_train\n",
    "ALL_MNIST_DATA_CLASSES = y_train\n",
    "\n",
    "# number of digits to overlay on canvas\n",
    "num_of_digits = 2\n",
    "\n",
    "# max digits to define the shape of prediction output\n",
    "MAX_DIGITS = 5\n",
    "\n",
    "\n",
    "# Sample Base Digits\n",
    "def get_sample_indices(dataset, size=5):\n",
    "  random_indices = np.random.choice(len(dataset), size=size, replace=False)\n",
    "  return random_indices\n",
    "\n",
    "# helper function to sample number of digits from master dataset\n",
    "def sample_base_digits(num_of_digits):\n",
    "    \"\"\"\n",
    "    Sample a specified number of digit images and their class labels from the master MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        num_of_digits (int): Number of digit samples to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sample_pixels, sample_values)\n",
    "            sample_pixels (np.ndarray): Array of digit images with shape (num_of_digits, 28, 28, 1).\n",
    "            sample_values (np.ndarray): Array of class labels with shape (num_of_digits, 1).\n",
    "    \"\"\"\n",
    "    sample_indices = get_sample_indices(ALL_MNIST_DATA_PIXELS, size=num_of_digits)\n",
    "    sample_pixels = ALL_MNIST_DATA_PIXELS[sample_indices]\n",
    "    sample_pixels = sample_pixels.reshape(-1,28,28,1)\n",
    "\n",
    "    sample_values = ALL_MNIST_DATA_CLASSES[sample_indices]\n",
    "    sample_values = sample_values.reshape(-1, 1)\n",
    "\n",
    "    # split the digits into pixels and class values\n",
    "    # reshape the data to expected values\n",
    "    # sample_pixels = sample.drop(\n",
    "    #     columns=[\"class\"]).to_numpy().reshape(-1, 28, 28, 1)\n",
    "    # sample_values = sample[\"class\"].values.reshape(-1, 1)\n",
    "    return sample_pixels, sample_values\n",
    "# Augment Digits\n",
    "\n",
    "\n",
    "def plot_before_after(before_image, after_image):\n",
    "    \"\"\"\n",
    "    Display two images side by side for visual comparison (e.g., before and after augmentation).\n",
    "\n",
    "    Args:\n",
    "        before_image (np.ndarray): The original image.\n",
    "        after_image (np.ndarray): The image after transformation or augmentation.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 3))\n",
    "    axs = axs.ravel()\n",
    "    axs[0].imshow(before_image)\n",
    "    axs[1].imshow(after_image)\n",
    "\n",
    "    plt.axis(\"off\")  # Remove axes for better visualization\n",
    "    plt.show()\n",
    "# helper function to apply random augmentation to digits\n",
    "\n",
    "\n",
    "def augment_digits(digits, debug=False):\n",
    "    \"\"\"\n",
    "    Apply random augmentations (translation, zoom, rotation) to a batch of digit images.\n",
    "\n",
    "    Args:\n",
    "        digits (np.ndarray): Array of digit images to augment.\n",
    "        debug (bool, optional): If True, displays before/after images for each digit. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Augmented digit images as a numpy array.\n",
    "    \"\"\"\n",
    "    tensor_digits = tf.convert_to_tensor(digits)\n",
    "\n",
    "    # step 2: apply random augmentation\n",
    "    augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomTranslation(\n",
    "            height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "        tf.keras.layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "        tf.keras.layers.RandomRotation(\n",
    "            factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "    ])\n",
    "    augmented_tensor_digits = augmentation(tensor_digits)\n",
    "\n",
    "    # if debug is true render before digits\n",
    "    if debug == True:\n",
    "        for translated_imgs in range(tensor_digits.shape[0]):\n",
    "            plot_before_after(\n",
    "                tensor_digits[translated_imgs], augmented_tensor_digits[translated_imgs])\n",
    "\n",
    "    # convert the tensor back to numpy to simplify use in map function\n",
    "    return augmented_tensor_digits.numpy()\n",
    "# Calculate Tight BBox\n",
    "# helper function to calculate bounding box for each instance and return it.\n",
    "# we are going to refactor the POC that we created ealier to use it with numpy arrays in the map function\n",
    "\n",
    "\n",
    "def calculate_bounding_box(pixels, class_value, padding=1):\n",
    "    \"\"\"\n",
    "    Calculate the tight bounding box for a digit image and return its coordinates and class value.\n",
    "\n",
    "    Args:\n",
    "        pixels (np.ndarray): 2D array representing the digit image.\n",
    "        class_value (int): The class label of the digit.\n",
    "        padding (int, optional): Padding to add around the bounding box. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        dict: Bounding box information including coordinates, center, width, height, and class value.\n",
    "    \"\"\"\n",
    "    # calculate active rows & columns\n",
    "    active_rows = np.sum(pixels, axis=1)\n",
    "    active_columns = np.sum(pixels, axis=0)\n",
    "\n",
    "    # calculate x_min and x_max coordinate\n",
    "    x_min = np.nonzero(active_columns)[0][0]\n",
    "    x_max = np.nonzero(active_columns)[0][-1]\n",
    "    y_min = np.nonzero(active_rows)[0][0]\n",
    "    y_max = np.nonzero(active_rows)[0][-1]\n",
    "\n",
    "    # add padding to pixels\n",
    "    x_min = x_min - (padding if (x_min != 0) else 0)\n",
    "    x_max = x_max + (padding if (x_max != 27) else 0)\n",
    "    y_min = y_min - (padding if (y_min != 0) else 0)\n",
    "    y_max = y_max + (padding if (y_max != 27) else 0)\n",
    "\n",
    "    # calcualte x_center and y_center\n",
    "    x_center = round((x_min + x_max) / 2)\n",
    "    y_center = round((y_min + y_max) / 2)\n",
    "\n",
    "    # calculate width and height\n",
    "    width = x_max - x_min + 1\n",
    "    height = y_max - y_min + 1\n",
    "\n",
    "    return {\n",
    "        \"x_min\": x_min,\n",
    "        \"x_max\": x_max,\n",
    "        \"y_min\": y_min,\n",
    "        \"y_max\": y_max,\n",
    "        \"x_center\": x_center,\n",
    "        \"y_center\": y_center,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"class_value\": class_value\n",
    "    }\n",
    "\n",
    "\n",
    "# helper function to visualize the bounding box\n",
    "\n",
    "\n",
    "def visualize_bounding_box(pixel_data, bounding_boxes, num_of_columns=5):\n",
    "    \"\"\"\n",
    "    Visualize digit images with their corresponding bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        pixel_data (np.ndarray): Array of digit images.\n",
    "        bounding_boxes (list): List of bounding box dictionaries for each digit.\n",
    "        num_of_columns (int, optional): Number of columns in the plot grid. Defaults to 5.\n",
    "    \"\"\"\n",
    "    num_of_columns = num_of_columns if num_of_columns <= 5 else 5\n",
    "    num_instances = pixel_data.shape[0]\n",
    "    num_of_rows = int(num_instances / num_of_columns) + \\\n",
    "        (1 if int(num_instances % num_of_columns) > 0 else 0)\n",
    "\n",
    "    fig, axs = plt.subplots(num_of_rows, num_of_columns, figsize=(10, 3))\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    for idx in range(0, num_instances, 1):\n",
    "\n",
    "        original = tf.constant(pixel_data[idx].reshape(28, 28, 1))\n",
    "        converted = tf.image.grayscale_to_rgb(original)\n",
    "        target_data = bounding_boxes[idx]\n",
    "        x_center = target_data[\"x_center\"]\n",
    "        y_center = target_data[\"y_center\"]\n",
    "        width = target_data[\"width\"]\n",
    "        height = target_data[\"height\"]\n",
    "\n",
    "        x = target_data[\"x_min\"]\n",
    "        y = target_data[\"y_min\"]\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x, y), width=width, height=height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        image_data = converted.numpy().astype(\"uint8\")\n",
    "        axs[idx].imshow(image_data)\n",
    "        axs[idx].add_patch(rect)\n",
    "\n",
    "        axs[idx].set_title(target_data[\"class_value\"])\n",
    "        axs[idx].axis(\"off\")\n",
    "    plt.show()\n",
    "# helper function to calculate bounding box for digits.\n",
    "\n",
    "\n",
    "def calculate_tight_bbox(pixels, class_values, debug=False):\n",
    "    \"\"\"\n",
    "    Calculate tight bounding boxes for a batch of digit images.\n",
    "\n",
    "    Args:\n",
    "        pixels (np.ndarray): Array of digit images.\n",
    "        class_values (np.ndarray): Array of class labels for each digit.\n",
    "        debug (bool, optional): If True, visualizes the bounding boxes. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        list: List of bounding box dictionaries for each digit.\n",
    "    \"\"\"\n",
    "    class_with_bbox = []\n",
    "    for idx in range(pixels.shape[0]):\n",
    "        class_with_bbox.append(calculate_bounding_box(\n",
    "            pixels[idx], class_values[idx][0]))\n",
    "\n",
    "    # if debug true render digits with bbox\n",
    "    if debug == True:\n",
    "        visualize_bounding_box(pixels, class_with_bbox, pixels.shape[0])\n",
    "\n",
    "    return class_with_bbox\n",
    "# Create Blank Canvas\n",
    "# helper function to create  blank canvas\n",
    "\n",
    "\n",
    "def create_blank_canvas(shape=(100, 100, 1)):\n",
    "    \"\"\"\n",
    "    Create a blank canvas for placing digit images.\n",
    "\n",
    "    Args:\n",
    "        shape (tuple, optional): Shape of the canvas. Defaults to (100, 100, 1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Blank canvas array.\n",
    "    \"\"\"\n",
    "    canvas = np.zeros(shape=(100, 100, 1), dtype=np.float32)\n",
    "    return canvas\n",
    "# Create Prediction Object\n",
    "# helper function to create empty predition structure based on MAX_DIGITS\n",
    "\n",
    "\n",
    "def create_prediction_object():\n",
    "    \"\"\"\n",
    "    Create an empty prediction object for storing digit detection results.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Prediction array of shape (MAX_DIGITS, 15).\n",
    "    \"\"\"\n",
    "    prediction = np.zeros(shape=(MAX_DIGITS, 15), dtype=np.float32)\n",
    "    return prediction\n",
    "# Place Digit On Canvas\n",
    "\n",
    "\n",
    "def is_valid_coordinates(top, left, class_bbox_value, existing_coordinates):\n",
    "    \"\"\"\n",
    "    Check if the proposed top-left coordinates for a digit's bounding box are valid (within canvas and non-overlapping).\n",
    "\n",
    "    Args:\n",
    "        top (int): Proposed top coordinate.\n",
    "        left (int): Proposed left coordinate.\n",
    "        class_bbox_value (dict): Bounding box info for the digit.\n",
    "        existing_coordinates (list): List of existing bounding boxes on the canvas.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if coordinates are valid, False otherwise.\n",
    "    \"\"\"\n",
    "    # # make sure the top and left are withing the canvas\n",
    "    # if (top + 28 >= 100 or left + 28 >= 100):\n",
    "    #     return False\n",
    "    # read current class values\n",
    "    # curr_x_center = class_bbox_value[\"x_center\"]\n",
    "    # curr_y_center = class_bbox_value[\"y_center\"]\n",
    "    curr_width = class_bbox_value[\"width\"]\n",
    "    curr_height = class_bbox_value[\"height\"]\n",
    "    curr_x_min = left\n",
    "    curr_y_min = top\n",
    "    curr_x_max = left + curr_width\n",
    "    curr_y_max = top + curr_height\n",
    "\n",
    "    # recalculate center with proposed top and left values\n",
    "    # curr_x_center = curr_x_center + left\n",
    "    # curr_y_center = curr_y_center + top\n",
    "\n",
    "    # check 1: will the new bounding box go beyond the grid?\n",
    "    if ((curr_x_min + curr_width) >= 100) or ((curr_y_min + curr_height) >= 100):\n",
    "        return False\n",
    "\n",
    "    # check 2: do bounding boxes overlap\n",
    "    # check the current bounding box with every existing box\n",
    "    for coord_idx in range(len(existing_coordinates)):\n",
    "        existing_x_min = existing_coordinates[coord_idx][\"x_min\"]\n",
    "        existing_y_min = existing_coordinates[coord_idx][\"y_min\"]\n",
    "        existing_x_max = existing_coordinates[coord_idx][\"x_max\"]\n",
    "        existing_y_max = existing_coordinates[coord_idx][\"y_max\"]\n",
    "        if ((curr_x_min <= existing_x_max and curr_x_max >= existing_x_min) and (curr_y_min <= existing_y_max and curr_y_max >= existing_y_min)):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def select_top_left(class_bbox_value, existing_coordinates):\n",
    "    \"\"\"\n",
    "    Randomly select valid top-left coordinates for placing a digit on the canvas.\n",
    "\n",
    "    Args:\n",
    "        class_bbox_value (dict): Bounding box info for the digit.\n",
    "        existing_coordinates (list): List of existing bounding boxes on the canvas.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (top, left) coordinates if valid, otherwise (-1, -1).\n",
    "    \"\"\"\n",
    "    got_valid_coordinates = False\n",
    "    # limiting the loop to run only 20 times\n",
    "    retries = 0\n",
    "    while ((not got_valid_coordinates) and (retries < 100)):\n",
    "        top = np.random.randint(0, high=100)\n",
    "        left = np.random.randint(0, high=100)\n",
    "        got_valid_coordinates = is_valid_coordinates(\n",
    "            top, left, class_bbox_value, existing_coordinates)\n",
    "        retries = retries+1\n",
    "\n",
    "    if got_valid_coordinates:\n",
    "        return top, left\n",
    "    return -1, -1\n",
    "\n",
    "\n",
    "# helper function to render the canvas\n",
    "# update the original plotting function to plot canvas as well.\n",
    "\n",
    "\n",
    "def render_canvas(canvas, class_bbox):\n",
    "    \"\"\"\n",
    "    Render the canvas with all placed digits and their bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        canvas (np.ndarray): The canvas image.\n",
    "        class_bbox (list): List of bounding box dictionaries for each digit.\n",
    "    \"\"\"\n",
    "    num_of_digits = len(class_bbox)\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(10, 3))\n",
    "    axs.imshow(canvas)  # Use 'gray' colormap to render grayscale\n",
    "    axs.axis(\"off\")\n",
    "\n",
    "    for idx in range(0, num_of_digits, 1):\n",
    "        width = class_bbox[idx][\"width\"]\n",
    "        height = class_bbox[idx][\"height\"]\n",
    "\n",
    "        x = class_bbox[idx][\"x_min\"]\n",
    "        y = class_bbox[idx][\"y_min\"]\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x, y), width=width, height=height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        axs.add_patch(rect)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def place_digit_on_canvas(canvas, pixels, class_bbox, debug=False):\n",
    "    \"\"\"\n",
    "    Place digit images on the canvas at valid, non-overlapping locations.\n",
    "\n",
    "    Args:\n",
    "        canvas (np.ndarray): The blank canvas to place digits on.\n",
    "        pixels (np.ndarray): Array of digit images.\n",
    "        class_bbox (list): List of bounding box dictionaries for each digit.\n",
    "        debug (bool, optional): If True, renders the canvas after placement. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (canvas, class_bbox) with updated canvas and bounding boxes.\n",
    "    \"\"\"\n",
    "    # list to save all the valid existing coordinates\n",
    "    existing_coordinates = []\n",
    "\n",
    "    # in case if the algorithm cannot place a digit on canvas we'll drop that digit from pixel and class_bbox\n",
    "    digits_to_drop = []\n",
    "\n",
    "    total_digits = pixels.shape[0]\n",
    "    # loop thru all the pixel values\n",
    "    for idx in range(total_digits):\n",
    "        class_bbox_value = class_bbox[idx]\n",
    "        x_center = class_bbox_value[\"x_center\"]\n",
    "        y_center = class_bbox_value[\"y_center\"]\n",
    "        width = class_bbox_value[\"width\"]\n",
    "        height = class_bbox_value[\"height\"]\n",
    "        class_value = class_bbox_value[\"class_value\"]\n",
    "        x_min = class_bbox_value[\"x_min\"]\n",
    "        y_min = class_bbox_value[\"y_min\"]\n",
    "        x_max = class_bbox_value[\"x_max\"]\n",
    "        y_max = class_bbox_value[\"y_max\"]\n",
    "\n",
    "        # print(f\"Width {width} & {int(width)}, Height {height} & {int(height)}\")\n",
    "        # width = int(width)\n",
    "        # height = int(height)\n",
    "\n",
    "        # step 1: find the right coordinates to place the digit\n",
    "        top, left = select_top_left(class_bbox_value, existing_coordinates)\n",
    "        if top != -1 and left != -1:\n",
    "            # step 2: place the digit\n",
    "            # canvas[y_min + top:y_min + top+height, x_min + left:x_min +\n",
    "            #        left + width] = pixels[idx][y_min:y_min+height, x_min:x_min+width]\n",
    "\n",
    "            canvas[top:top+height, left:\n",
    "                   left + width] = pixels[idx][y_min:y_min+height, x_min:x_min+width]\n",
    "\n",
    "            # step 3: recalculate the center based on top,left and update the class values with new center\n",
    "            class_bbox_value[\"x_center\"] = x_center + left\n",
    "            class_bbox_value[\"x_min\"] = left\n",
    "            class_bbox_value[\"x_max\"] = left + width\n",
    "\n",
    "            class_bbox_value[\"y_center\"] = y_center + top\n",
    "            class_bbox_value[\"y_min\"] = top\n",
    "            class_bbox_value[\"y_max\"] = top + height\n",
    "\n",
    "            # update the array\n",
    "            class_bbox[idx] = class_bbox_value\n",
    "            # step 5: save the existing bounding box coordinates to help select the new one\n",
    "            existing_coordinates.append(\n",
    "                class_bbox_value\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"Error placing digit {class_value} on canvas. Couldn't fild valid coordinates\")\n",
    "            digits_to_drop.append(idx)\n",
    "\n",
    "    # drop any bbox for which we couldn't find space in canvas\n",
    "    filtered_bbox = [bbox for idx, bbox in enumerate(\n",
    "        class_bbox) if idx not in digits_to_drop]\n",
    "\n",
    "    if debug == True:\n",
    "        render_canvas(canvas=canvas, class_bbox=filtered_bbox)\n",
    "\n",
    "    return canvas, class_bbox\n",
    "# Translate BBox To Prediction Object\n",
    "# helper function to convert bbox diction to prediction object\n",
    "\n",
    "\n",
    "def translate_bbox_to_prediction(current_bbox, prediction, debug=False):\n",
    "    \"\"\"\n",
    "    Convert bounding box dictionaries to a prediction object suitable for training.\n",
    "\n",
    "    Args:\n",
    "        current_bbox (list): List of bounding box dictionaries.\n",
    "        prediction (np.ndarray): Prediction array to update.\n",
    "        debug (bool, optional): If True, prints mapping details. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Updated prediction array.\n",
    "    \"\"\"\n",
    "    # Sanity check - ideally prediction shape should be larger than or equal to number of elements in bbox\n",
    "    if (prediction.shape[0] < len(current_bbox)):\n",
    "        print(f\"Error shape mismatch between prediction and bbox\")\n",
    "        return prediction\n",
    "\n",
    "    for idx, bbox in enumerate(current_bbox):\n",
    "        # set the flag indicating the digit is present\n",
    "        prediction[idx][0] = 1\n",
    "        # set x_center\n",
    "        prediction[idx][1] = bbox[\"x_center\"]\n",
    "        # set y_center\n",
    "        prediction[idx][2] = bbox[\"y_center\"]\n",
    "        # set width\n",
    "        prediction[idx][3] = bbox[\"width\"]\n",
    "        # set height\n",
    "        prediction[idx][4] = bbox[\"height\"]\n",
    "        # set one hot encoded value of the class\n",
    "        # read the class value\n",
    "        class_value = int(bbox[\"class_value\"])\n",
    "        # set the cell corresponding to class value to 1\n",
    "        prediction[idx][5 + class_value] = 1\n",
    "        if debug == True:\n",
    "            print(f\"current bbox is {bbox}\")\n",
    "            print(f\"mapped prediction is {prediction[idx]}\")\n",
    "\n",
    "    return prediction\n",
    "# Generate Training Example\n",
    "# helper map function to map 28x28x1 image and its class to 100x100x1 canvas and prediction object\n",
    "\n",
    "def generate_training_example(x, y, debug=False):\n",
    "    \"\"\"\n",
    "    Generate a training example by placing digits on a canvas and creating the corresponding prediction object.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Input digit image(s).\n",
    "        y (np.ndarray): Corresponding class label(s).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (canvas, prediction) where canvas is the composed image and prediction is the label array.\n",
    "    \"\"\"\n",
    "    pixels = x.reshape(-1, 28, 28, 1)\n",
    "    class_values = y.reshape(-1, 1)\n",
    "    # step 1: sample additional digits\n",
    "    if num_of_digits - 1 > 0:\n",
    "        sample_pixels, sample_values = sample_base_digits(num_of_digits - 1)\n",
    "        pixels = np.concatenate((pixels, sample_pixels))\n",
    "        class_values = np.concatenate((class_values, sample_values), axis=0)\n",
    "\n",
    "    # step 2: augment digits\n",
    "    pixels = augment_digits(pixels, debug=debug)\n",
    "\n",
    "    # step 3: calculate bounding box\n",
    "    class_with_bbox = calculate_tight_bbox(pixels, class_values, debug=debug)\n",
    "\n",
    "    # step 4: create blank canvas and prediction\n",
    "    canvas = create_blank_canvas()\n",
    "    prediction = create_prediction_object()\n",
    "\n",
    "    # step 5: place digit on canvas\n",
    "    canvas, class_bbox = place_digit_on_canvas(\n",
    "        canvas, pixels, class_with_bbox, debug=debug)\n",
    "\n",
    "    # step 6: translate bbox to prediction object\n",
    "    prediction = translate_bbox_to_prediction(\n",
    "        class_bbox, prediction, debug=debug)\n",
    "\n",
    "    # print(f\"Final canvas shape {canvas.shape}, final prediction shape {prediction.shape}\")\n",
    "    return (canvas, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c493d06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757531822.081810   23614 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2358 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:2e:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "X_tensor = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "X_tensor = tf.reshape(X_tensor,shape=(-1,28,28,1))\n",
    "y_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "batch_size = 32\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "def generative_py_function(func, inp, Tout, shape_out):\n",
    "    # This is the bridge that calls your NumPy code\n",
    "    y = tf.numpy_function(func, inp, Tout)\n",
    "    # This is the crucial step: re-apply the shape information\n",
    "    y[0].set_shape(shape_out[0]) # Set shape for the image\n",
    "    y[1].set_shape(shape_out[1]) # Set shape for the labels\n",
    "    return y\n",
    "\n",
    "# Define the exact output shapes you expect\n",
    "output_shapes = ([100, 100, 1], [5,15])\n",
    "# Define the exact output data types you expect\n",
    "output_types = (tf.float32, tf.float32)\n",
    "\n",
    "# Use the wrapper inside the map\n",
    "processed_dataset = raw_dataset.map(lambda X, y: generative_py_function(\n",
    "    generate_training_example,\n",
    "    inp=[X, y],\n",
    "    Tout=output_types, # Pass the dtypes to Tout\n",
    "    shape_out=output_shapes # Pass the shapes to our new argument\n",
    ")).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4757d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 0 ----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for epoch 0 : 2857.236867081\n",
      "Total Execution time: 2857.2369908419996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 13:06:03.265640: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Commenting this out to avoid running long bench mark again. \n",
    "# benchmark(processed_dataset.prefetch(tf.data.AUTOTUNE), num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538acc3",
   "metadata": {},
   "source": [
    "* So single epoch took 2857.236867081 seconds so ~47 mins mamjority of that time went to data generation since we spent only 0.01s perbatch for \"training\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb18704",
   "metadata": {},
   "source": [
    "## Data Generation With Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b91c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MNIST_DATA_PIXELS_TF = tf.constant(x_train, dtype=tf.float32)\n",
    "ALL_MNIST_DATA_CLASSES_TF = tf.constant(y_train, dtype=tf.float32)\n",
    "\n",
    "# number of digits to overlay on canvas\n",
    "num_of_digits = tf.constant(2, dtype=tf.int32)\n",
    "\n",
    "# max digits to define the shape of prediction output\n",
    "MAX_DIGITS = tf.constant(5, dtype=tf.int32)\n",
    "\n",
    "\n",
    "# Sample Base Digits\n",
    "@tf.function\n",
    "def get_sample_indices(dataset, size=5):\n",
    "  dataset_len = tf.shape(dataset)[0] - 1\n",
    "  random_indices = tf.random.uniform(shape=[size], minval=0,maxval=dataset_len,dtype=tf.int32)\n",
    "  return random_indices\n",
    "\n",
    "# helper function to sample number of digits from master dataset\n",
    "@tf.function\n",
    "def sample_base_digits(num_of_digits):\n",
    "    \"\"\"\n",
    "    Sample a specified number of digit images and their class labels from the master MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        num_of_digits (int): Number of digit samples to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sample_pixels, sample_values)\n",
    "            sample_pixels (np.ndarray): Array of digit images with shape (num_of_digits, 28, 28, 1).\n",
    "            sample_values (np.ndarray): Array of class labels with shape (num_of_digits, 1).\n",
    "    \"\"\"\n",
    "    sample_indices = get_sample_indices(ALL_MNIST_DATA_CLASSES_TF, size=num_of_digits)\n",
    "    sample_pixels = tf.gather(ALL_MNIST_DATA_PIXELS_TF, indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_pixels = tf.reshape(sample_pixels, shape=(num_of_digits,28,28))\n",
    "\n",
    "    sample_values = tf.gather(ALL_MNIST_DATA_CLASSES_TF, indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_values = tf.reshape(sample_values, shape=(num_of_digits,1))\n",
    "    return sample_pixels, sample_values\n",
    "\n",
    "\n",
    "def plot_before_after(before_image, after_image):\n",
    "    \"\"\"\n",
    "    Display two images side by side for visual comparison (e.g., before and after augmentation).\n",
    "\n",
    "    Args:\n",
    "        before_image (np.ndarray): The original image.\n",
    "        after_image (np.ndarray): The image after transformation or augmentation.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 3))\n",
    "    axs = axs.ravel()\n",
    "    axs[0].imshow(before_image)\n",
    "    axs[1].imshow(after_image)\n",
    "\n",
    "    plt.axis(\"off\")  # Remove axes for better visualization\n",
    "    plt.show()\n",
    "# helper function to apply random augmentation to digits\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomTranslation(\n",
    "      height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "  tf.keras.layers.RandomZoom(\n",
    "      height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "  tf.keras.layers.RandomRotation(\n",
    "      factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "  ])\n",
    "\n",
    "\n",
    "def augment_digits(digits, debug=False):\n",
    "    \"\"\"\n",
    "    Apply random augmentations (translation, zoom, rotation) to a batch of digit images.\n",
    "\n",
    "    Args:\n",
    "        digits (np.ndarray): Array of digit images to augment.\n",
    "        debug (bool, optional): If True, displays before/after images for each digit. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Augmented digit images as a numpy array.\n",
    "    \"\"\"\n",
    "    # step 2: apply random augmentation\n",
    "    augmented_tensor_digits = augmentation(digits)\n",
    "    return augmented_tensor_digits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_bounding_box(pixels, class_value, padding=1):\n",
    "    \"\"\"\n",
    "    Calculate the tight bounding box for a digit image and return its coordinates and class value.\n",
    "    helper function to calculate bounding box for each instance and return it.\n",
    "    we are going to refactor the POC that we created ealier to use it with numpy arrays in the map function\n",
    "\n",
    "\n",
    "    Args:\n",
    "        pixels (np.ndarray): 2D array representing the digit image.\n",
    "        class_value (int): The class label of the digit.\n",
    "        padding (int, optional): Padding to add around the bounding box. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        dict: Bounding box information including coordinates, center, width, height, and class value.\n",
    "    \"\"\"\n",
    "    # calculate active rows & columns\n",
    "    # this gives us rows with non zero pixels\n",
    "    active_rows = tf.reduce_sum(pixels, axis=1, keepdims=True)\n",
    "\n",
    "    # this gives us columns with non zero pixels\n",
    "    active_columns = tf.reduce_sum(pixels, axis=0, keepdims=True)\n",
    "\n",
    "    # calculate x_min and x_max coordinate\n",
    "\n",
    "    x_min = tf.cast(tf.where(active_columns != 0)[0][0], tf.int32)\n",
    "    x_max = tf.cast(tf.where(active_columns != 0)[0][-1], tf.int32)\n",
    "    y_min = tf.cast(tf.where(active_rows != 0)[0][0], tf.int32)\n",
    "    y_max = tf.cast(tf.where(active_rows != 0)[0][-1], tf.int32)\n",
    "\n",
    "    # add padding to pixels\n",
    "    x_min = x_min - (padding if (x_min != 0) else 0)\n",
    "    x_max = x_max + (padding if (x_max != 27) else 0)\n",
    "    y_min = y_min - (padding if (y_min != 0) else 0)\n",
    "    y_max = y_max + (padding if (y_max != 27) else 0)\n",
    "\n",
    "    # calcualte x_center and y_center\n",
    "    x_center = tf.round((x_min + x_max) / 2)\n",
    "    y_center = tf.round((y_min + y_max) / 2)\n",
    "\n",
    "    # calculate width and height\n",
    "    width = x_max - x_min + 1\n",
    "    height = y_max - y_min + 1\n",
    "\n",
    "    # return {\n",
    "    #     \"x_min\": x_min,\n",
    "    #     \"x_max\": x_max,\n",
    "    #     \"y_min\": y_min,\n",
    "    #     \"y_max\": y_max,\n",
    "    #     \"x_center\": x_center,\n",
    "    #     \"y_center\": y_center,\n",
    "    #     \"width\": width,\n",
    "    #     \"height\": height,\n",
    "    #     \"class_value\": class_value\n",
    "    # }\n",
    "    return [x_min,x_max,y_min,y_max,x_center,y_center,width,height,class_value]\n",
    "\n",
    "\n",
    "# helper function to visualize the bounding box\n",
    "\n",
    "\n",
    "def visualize_bounding_box(pixel_data, bounding_boxes, num_of_columns=5):\n",
    "    \"\"\"\n",
    "    Visualize digit images with their corresponding bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        pixel_data (np.ndarray): Array of digit images.\n",
    "        bounding_boxes (list): List of bounding box dictionaries for each digit.\n",
    "        num_of_columns (int, optional): Number of columns in the plot grid. Defaults to 5.\n",
    "    \"\"\"\n",
    "    num_of_columns = num_of_columns if num_of_columns <= 5 else 5\n",
    "    num_instances = pixel_data.shape[0]\n",
    "    num_of_rows = int(num_instances / num_of_columns) + \\\n",
    "        (1 if int(num_instances % num_of_columns) > 0 else 0)\n",
    "\n",
    "    fig, axs = plt.subplots(num_of_rows, num_of_columns, figsize=(10, 3))\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    for idx in range(0, num_instances, 1):\n",
    "\n",
    "        original = tf.constant(pixel_data[idx].reshape(28, 28, 1))\n",
    "        converted = tf.image.grayscale_to_rgb(original)\n",
    "        target_data = bounding_boxes[idx]\n",
    "        x_center = target_data[\"x_center\"]\n",
    "        y_center = target_data[\"y_center\"]\n",
    "        width = target_data[\"width\"]\n",
    "        height = target_data[\"height\"]\n",
    "\n",
    "        x = target_data[\"x_min\"]\n",
    "        y = target_data[\"y_min\"]\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x, y), width=width, height=height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        image_data = converted.numpy().astype(\"uint8\")\n",
    "        axs[idx].imshow(image_data)\n",
    "        axs[idx].add_patch(rect)\n",
    "\n",
    "        axs[idx].set_title(target_data[\"class_value\"])\n",
    "        axs[idx].axis(\"off\")\n",
    "    plt.show()\n",
    "# helper function to calculate bounding box for digits.\n",
    "\n",
    "\n",
    "def calculate_tight_bbox(pixels, class_values, debug=False):\n",
    "    \"\"\"\n",
    "    Calculate tight bounding boxes for a batch of digit images.\n",
    "\n",
    "    Args:\n",
    "        pixels (np.ndarray): Array of digit images.\n",
    "        class_values (np.ndarray): Array of class labels for each digit.\n",
    "        debug (bool, optional): If True, visualizes the bounding boxes. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        list: List of bounding box dictionaries for each digit.\n",
    "    \"\"\"\n",
    "    num_of_boxes = tf.shape(pixels)[0]\n",
    "    class_with_bbox = []\n",
    "    for idx in range(num_of_boxes):\n",
    "        class_with_bbox.append(calculate_bounding_box(\n",
    "            pixels[idx], class_values[idx][0]))\n",
    "\n",
    "    # # if debug true render digits with bbox\n",
    "    # if debug == True:\n",
    "    #     visualize_bounding_box(pixels, class_with_bbox, pixels.shape[0])\n",
    "\n",
    "    return tf.convert_to_tensor(class_with_bbox, dtype=tf.float32)\n",
    "    # return class_with_bbox\n",
    "# Create Blank Canvas\n",
    "# helper function to create  blank canvas\n",
    "\n",
    "\n",
    "def create_blank_canvas(shape=(100, 100, 1)):\n",
    "    \"\"\"\n",
    "    Create a blank canvas for placing digit images.\n",
    "\n",
    "    Args:\n",
    "        shape (tuple, optional): Shape of the canvas. Defaults to (100, 100, 1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Blank canvas array.\n",
    "    \"\"\"\n",
    "    canvas = tf.zeros(shape=(100, 100, 1), dtype=tf.float32)\n",
    "    return canvas\n",
    "# Create Prediction Object\n",
    "# helper function to create empty predition structure based on MAX_DIGITS\n",
    "\n",
    "\n",
    "def create_prediction_object():\n",
    "    \"\"\"\n",
    "    Create an empty prediction object for storing digit detection results.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Prediction array of shape (MAX_DIGITS, 15).\n",
    "    \"\"\"\n",
    "    prediction = tf.zeros(shape=(MAX_DIGITS, 15), dtype=tf.float32)\n",
    "    return prediction\n",
    "# Place Digit On Canvas\n",
    "\n",
    "\n",
    "def is_valid_coordinates(top, left, class_bbox_value, existing_coordinates):\n",
    "    \"\"\"\n",
    "    Check if the proposed top-left coordinates for a digit's bounding box are valid (within canvas and non-overlapping).\n",
    "\n",
    "    Args:\n",
    "        top (int): Proposed top coordinate.\n",
    "        left (int): Proposed left coordinate.\n",
    "        class_bbox_value (dict): Bounding box info for the digit.\n",
    "        existing_coordinates (list): List of existing bounding boxes on the canvas.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if coordinates are valid, False otherwise.\n",
    "    \"\"\"\n",
    "    # # make sure the top and left are withing the canvas\n",
    "    # if (top + 28 >= 100 or left + 28 >= 100):\n",
    "    #     return False\n",
    "    # read current class values\n",
    "    # curr_x_center = class_bbox_value[\"x_center\"]\n",
    "    # curr_y_center = class_bbox_value[\"y_center\"]\n",
    "    curr_width = class_bbox_value[\"width\"]\n",
    "    curr_height = class_bbox_value[\"height\"]\n",
    "    curr_x_min = left\n",
    "    curr_y_min = top\n",
    "    curr_x_max = left + curr_width\n",
    "    curr_y_max = top + curr_height\n",
    "\n",
    "    # recalculate center with proposed top and left values\n",
    "    # curr_x_center = curr_x_center + left\n",
    "    # curr_y_center = curr_y_center + top\n",
    "\n",
    "    # check 1: will the new bounding box go beyond the grid?\n",
    "    if ((curr_x_min + curr_width) >= 100) or ((curr_y_min + curr_height) >= 100):\n",
    "        return False\n",
    "\n",
    "    # check 2: do bounding boxes overlap\n",
    "    # check the current bounding box with every existing box\n",
    "    for coord_idx in range(len(existing_coordinates)):\n",
    "        existing_x_min = existing_coordinates[coord_idx][\"x_min\"]\n",
    "        existing_y_min = existing_coordinates[coord_idx][\"y_min\"]\n",
    "        existing_x_max = existing_coordinates[coord_idx][\"x_max\"]\n",
    "        existing_y_max = existing_coordinates[coord_idx][\"y_max\"]\n",
    "        if ((curr_x_min <= existing_x_max and curr_x_max >= existing_x_min) and (curr_y_min <= existing_y_max and curr_y_max >= existing_y_min)):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def select_top_left(class_bbox_value, existing_coordinates):\n",
    "    \"\"\"\n",
    "    Randomly select valid top-left coordinates for placing a digit on the canvas.\n",
    "\n",
    "    Args:\n",
    "        class_bbox_value (dict): Bounding box info for the digit.\n",
    "        existing_coordinates (list): List of existing bounding boxes on the canvas.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (top, left) coordinates if valid, otherwise (-1, -1).\n",
    "    \"\"\"\n",
    "    got_valid_coordinates = False\n",
    "    # limiting the loop to run only 20 times\n",
    "    retries = 0\n",
    "    while ((not got_valid_coordinates) and (retries < 50)):\n",
    "        top = tf.random.uniform(shape=[1], minval=0,maxval=100,dtype=tf.int32)[0]\n",
    "        left = tf.random.uniform(shape=[1], minval=0,maxval=100,dtype=tf.int32)[0]\n",
    "        got_valid_coordinates = is_valid_coordinates(\n",
    "            top, left, class_bbox_value, existing_coordinates)\n",
    "        retries = retries+1\n",
    "\n",
    "    if got_valid_coordinates:\n",
    "        return top, left\n",
    "    return -1, -1\n",
    "\n",
    "\n",
    "# helper function to render the canvas\n",
    "# update the original plotting function to plot canvas as well.\n",
    "\n",
    "\n",
    "def render_canvas(canvas, class_bbox):\n",
    "    \"\"\"\n",
    "    Render the canvas with all placed digits and their bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        canvas (np.ndarray): The canvas image.\n",
    "        class_bbox (list): List of bounding box dictionaries for each digit.\n",
    "    \"\"\"\n",
    "    num_of_digits = len(class_bbox)\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(10, 3))\n",
    "    axs.imshow(canvas)  # Use 'gray' colormap to render grayscale\n",
    "    axs.axis(\"off\")\n",
    "\n",
    "    for idx in range(0, num_of_digits, 1):\n",
    "        width = class_bbox[idx][\"width\"]\n",
    "        height = class_bbox[idx][\"height\"]\n",
    "\n",
    "        x = class_bbox[idx][\"x_min\"]\n",
    "        y = class_bbox[idx][\"y_min\"]\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x, y), width=width, height=height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        axs.add_patch(rect)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def place_digit_on_canvas(canvas, pixels, class_bbox, debug=False):\n",
    "    \"\"\"\n",
    "    Place digit images on the canvas at valid, non-overlapping locations.\n",
    "\n",
    "    Args:\n",
    "        canvas (np.ndarray): The blank canvas to place digits on.\n",
    "        pixels (np.ndarray): Array of digit images.\n",
    "        class_bbox (list): List of bounding box dictionaries for each digit.\n",
    "        debug (bool, optional): If True, renders the canvas after placement. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (canvas, class_bbox) with updated canvas and bounding boxes.\n",
    "    \"\"\"\n",
    "    # list to save all the valid existing coordinates\n",
    "    existing_coordinates = []\n",
    "\n",
    "    # in case if the algorithm cannot place a digit on canvas we'll drop that digit from pixel and class_bbox\n",
    "    digits_to_drop = []\n",
    "\n",
    "    total_digits = tf.shape(pixels)[0]\n",
    "    # loop thru all the pixel values\n",
    "    for idx in range(total_digits):\n",
    "        print(f\"idx type {idx.dtype}\")\n",
    "        class_bbox_value = class_bbox[idx]\n",
    "        x_center = class_bbox_value[\"x_center\"]\n",
    "        y_center = class_bbox_value[\"y_center\"]\n",
    "        width = class_bbox_value[\"width\"]\n",
    "        height = class_bbox_value[\"height\"]\n",
    "        class_value = class_bbox_value[\"class_value\"]\n",
    "        x_min = class_bbox_value[\"x_min\"]\n",
    "        y_min = class_bbox_value[\"y_min\"]\n",
    "        x_max = class_bbox_value[\"x_max\"]\n",
    "        y_max = class_bbox_value[\"y_max\"]\n",
    "\n",
    "        # print(f\"Width {width} & {int(width)}, Height {height} & {int(height)}\")\n",
    "        # width = int(width)\n",
    "        # height = int(height)\n",
    "\n",
    "        # step 1: find the right coordinates to place the digit\n",
    "        top, left = select_top_left(class_bbox_value, existing_coordinates)\n",
    "        if top != -1 and left != -1:\n",
    "            # step 2: place the digit\n",
    "            # canvas[y_min + top:y_min + top+height, x_min + left:x_min +\n",
    "            #        left + width] = pixels[idx][y_min:y_min+height, x_min:x_min+width]\n",
    "            canvas[top:top+height, left:\n",
    "                   left + width] = pixels[idx][y_min:y_min+height, x_min:x_min+width]\n",
    "\n",
    "            # step 3: recalculate the center based on top,left and update the class values with new center\n",
    "            class_bbox_value[\"x_center\"] = x_center + left\n",
    "            class_bbox_value[\"x_min\"] = left\n",
    "            class_bbox_value[\"x_max\"] = left + width\n",
    "\n",
    "            class_bbox_value[\"y_center\"] = y_center + top\n",
    "            class_bbox_value[\"y_min\"] = top\n",
    "            class_bbox_value[\"y_max\"] = top + height\n",
    "\n",
    "            # update the array\n",
    "            class_bbox[idx] = class_bbox_value\n",
    "            # step 5: save the existing bounding box coordinates to help select the new one\n",
    "            existing_coordinates.append(\n",
    "                class_bbox_value\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"Error placing digit {class_value} on canvas. Couldn't fild valid coordinates\")\n",
    "            digits_to_drop.append(idx)\n",
    "\n",
    "    # drop any bbox for which we couldn't find space in canvas\n",
    "    filtered_bbox = [bbox for idx, bbox in enumerate(\n",
    "        class_bbox) if idx not in digits_to_drop]\n",
    "\n",
    "    # if debug == True:\n",
    "    #     render_canvas(canvas=canvas, class_bbox=filtered_bbox)\n",
    "\n",
    "    return canvas, class_bbox\n",
    "# Translate BBox To Prediction Object\n",
    "# helper function to convert bbox diction to prediction object\n",
    "\n",
    "\n",
    "def translate_bbox_to_prediction(current_bbox, prediction, debug=False):\n",
    "    \"\"\"\n",
    "    Convert bounding box dictionaries to a prediction object suitable for training.\n",
    "\n",
    "    Args:\n",
    "        current_bbox (list): List of bounding box dictionaries.\n",
    "        prediction (np.ndarray): Prediction array to update.\n",
    "        debug (bool, optional): If True, prints mapping details. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Updated prediction array.\n",
    "    \"\"\"\n",
    "    # Sanity check - ideally prediction shape should be larger than or equal to number of elements in bbox\n",
    "    if (prediction.shape[0] < len(current_bbox)):\n",
    "        print(f\"Error shape mismatch between prediction and bbox\")\n",
    "        return prediction\n",
    "\n",
    "    for idx, bbox in enumerate(current_bbox):\n",
    "        # set the flag indicating the digit is present\n",
    "        prediction[idx][0] = 1\n",
    "        # set x_center\n",
    "        prediction[idx][1] = bbox[\"x_center\"]\n",
    "        # set y_center\n",
    "        prediction[idx][2] = bbox[\"y_center\"]\n",
    "        # set width\n",
    "        prediction[idx][3] = bbox[\"width\"]\n",
    "        # set height\n",
    "        prediction[idx][4] = bbox[\"height\"]\n",
    "        # set one hot encoded value of the class\n",
    "        # read the class value\n",
    "        class_value = int(bbox[\"class_value\"])\n",
    "        # set the cell corresponding to class value to 1\n",
    "        prediction[idx][5 + class_value] = 1\n",
    "        if debug == True:\n",
    "            print(f\"current bbox is {bbox}\")\n",
    "            print(f\"mapped prediction is {prediction[idx]}\")\n",
    "\n",
    "    return prediction\n",
    "# Generate Training Example\n",
    "# helper map function to map 28x28x1 image and its class to 100x100x1 canvas and prediction object\n",
    "\n",
    "\n",
    "def generate_training_example_tf(x, y, debug=False):\n",
    "    \"\"\"\n",
    "    Generate a training example by placing digits on a canvas and creating the corresponding prediction object.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Input digit image(s).\n",
    "        y (np.ndarray): Corresponding class label(s).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (canvas, prediction) where canvas is the composed image and prediction is the label array.\n",
    "    \"\"\"\n",
    "    pixels = tf.reshape(x, shape = (1,28,28))\n",
    "    class_values = tf.reshape(y,shape=(1,1))\n",
    "\n",
    "    # step 1: sample additional digits\n",
    "    if num_of_digits - 1 > 0:\n",
    "        sample_pixels, sample_values = sample_base_digits(num_of_digits - 1)\n",
    "        pixels = tf.concat([pixels, sample_pixels], axis=0)\n",
    "        class_values = tf.concat([class_values, sample_values], axis=0)\n",
    "\n",
    "    # # step 2: augment digits\n",
    "    pixels = augment_digits(pixels, debug=True)\n",
    "\n",
    "    # # step 3: calculate bounding box and return it as tensor\n",
    "    class_with_bbox = calculate_tight_bbox(pixels, class_values, debug=debug)\n",
    "\n",
    "    # # step 4: create blank canvas and prediction\n",
    "    canvas = create_blank_canvas()\n",
    "    prediction = create_prediction_object()\n",
    "\n",
    "    # # step 5: place digit on canvas\n",
    "    # canvas, class_bbox = place_digit_on_canvas(\n",
    "    #     canvas, pixels, class_with_bbox, debug=debug)\n",
    "\n",
    "    # # step 6: translate bbox to prediction object\n",
    "    # prediction = translate_bbox_to_prediction(\n",
    "    #     class_bbox, prediction, debug=debug)\n",
    "\n",
    "    # # print(f\"Final canvas shape {canvas.shape}, final prediction shape {prediction.shape}\")\n",
    "    return canvas, prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ba9529",
   "metadata": {},
   "outputs": [
    {
     "ename": "InaccessibleTensorError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_23614/1296142893.py\", line 496, in generate_training_example_tf  *\n        class_with_bbox = calculate_tight_bbox(pixels, class_values, debug=debug)\n    File \"/tmp/ipykernel_23614/1296142893.py\", line 213, in calculate_tight_bbox  *\n        return tf.convert_to_tensor(class_with_bbox, dtype=tf.float32)\n    File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/core/function/capture/capture_container.py\", line 144, in capture_by_value\n        graph._validate_in_scope(tensor)  # pylint: disable=protected-access\n\n    InaccessibleTensorError: <tf.Tensor 'while/sub:0' shape=() dtype=int32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it.\n    Please see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.\n    \n    <tf.Tensor 'while/sub:0' shape=() dtype=int32> was defined here:\n        File \"<frozen runpy>\", line 198, in _run_module_as_main\n        File \"<frozen runpy>\", line 88, in _run_code\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n        File \"/home/gaurangdave/anaconda3/envs/ml/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n        File \"/home/gaurangdave/anaconda3/envs/ml/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n        File \"/home/gaurangdave/anaconda3/envs/ml/lib/python3.12/asyncio/events.py\", line 88, in _run\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n        File \"/tmp/ipykernel_23614/1812299449.py\", line 9, in <module>\n        File \"/tmp/ipykernel_23614/1296142893.py\", line 496, in generate_training_example_tf\n        File \"/tmp/ipykernel_23614/1296142893.py\", line 205, in calculate_tight_bbox\n        File \"/tmp/ipykernel_23614/1296142893.py\", line 206, in calculate_tight_bbox\n        File \"/tmp/ipykernel_23614/1296142893.py\", line 119, in calculate_bounding_box\n    \n    The tensor <tf.Tensor 'while/sub:0' shape=() dtype=int32> cannot be accessed from FuncGraph(name=Dataset_map_generate_training_example_tf, id=140088841131072), because it was defined in FuncGraph(name=while_body_18724211, id=140088841551168), which is out of scope.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInaccessibleTensorError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Use the wrapper inside the map\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m tf_processed_dataset = \u001b[43mraw_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerate_training_example_tf\u001b[49m\u001b[43m)\u001b[49m.batch(batch_size=batch_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:2341\u001b[39m, in \u001b[36mDatasetV2.map\u001b[39m\u001b[34m(self, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[39m\n\u001b[32m   2336\u001b[39m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[32m   2337\u001b[39m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[32m   2338\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[32m   2339\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[32m-> \u001b[39m\u001b[32m2341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2342\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2346\u001b[39m \u001b[43m    \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2347\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_unbounded_threadpool\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_unbounded_threadpool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2349\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/data/ops/map_op.py:43\u001b[39m, in \u001b[36m_map_v2\u001b[39m\u001b[34m(input_dataset, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[39m\n\u001b[32m     38\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode.DEBUG_MODE:\n\u001b[32m     39\u001b[39m     warnings.warn(\n\u001b[32m     40\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     41\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`num_parallel_calls` argument is specified.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m      \u001b[49m\u001b[43mforce_synchronous\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     51\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/data/ops/map_op.py:157\u001b[39m, in \u001b[36m_MapDataset.__init__\u001b[39m\u001b[34m(self, input_dataset, map_func, force_synchronous, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28mself\u001b[39m._use_inter_op_parallelism = use_inter_op_parallelism\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._preserve_cardinality = preserve_cardinality\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[38;5;28mself\u001b[39m._map_func = \u001b[43mstructured_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mself\u001b[39m._force_synchronous = force_synchronous\n\u001b[32m    163\u001b[39m \u001b[38;5;28mself\u001b[39m._name = name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[39m, in \u001b[36mStructuredFunctionWrapper.__init__\u001b[39m\u001b[34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[39m\n\u001b[32m    258\u001b[39m       warnings.warn(\n\u001b[32m    259\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    260\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    261\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    262\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    263\u001b[39m     fn_factory = trace_tf_function(defun_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m \u001b[38;5;28mself\u001b[39m._function = \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[32m    267\u001b[39m add_to_graph &= \u001b[38;5;129;01mnot\u001b[39;00m context.executing_eagerly()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1256\u001b[39m, in \u001b[36mFunction.get_concrete_function\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1255\u001b[39m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m   concrete = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m   concrete._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m   1258\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1226\u001b[39m, in \u001b[36mFunction._get_concrete_function_garbage_collected\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1224\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     initializers = []\n\u001b[32m-> \u001b[39m\u001b[32m1226\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1227\u001b[39m     \u001b[38;5;28mself\u001b[39m._initialize_uninitialized_variables(initializers)\n\u001b[32m   1229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m   1230\u001b[39m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[32m   1231\u001b[39m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[39m, in \u001b[36mFunction._initialize\u001b[39m\u001b[34m(self, args, kwds, add_initializers_to)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28mself\u001b[39m._variable_creation_config = \u001b[38;5;28mself\u001b[39m._generate_scoped_tracing_options(\n\u001b[32m    692\u001b[39m     variable_capturing_scope,\n\u001b[32m    693\u001b[39m     tracing_compilation.ScopeType.VARIABLE_CREATION,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    695\u001b[39m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvalid_creator_scope\u001b[39m(*unused_args, **unused_kwds):\n\u001b[32m    701\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m   target_func_type = lookup_func_type\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m concrete_function = \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m   tracing_options.function_cache.add(\n\u001b[32m    289\u001b[39m       concrete_function, current_func_context\n\u001b[32m    290\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[39m, in \u001b[36m_create_concrete_function\u001b[39m\u001b[34m(function_type, type_context, func_graph, tracing_options)\u001b[39m\n\u001b[32m    303\u001b[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001b[32m    304\u001b[39m       placeholder_context\n\u001b[32m    305\u001b[39m   )\n\u001b[32m    307\u001b[39m disable_acd = tracing_options.attributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options.attributes.get(\n\u001b[32m    308\u001b[39m     attributes_lib.DISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    309\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m traced_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001b[32m    324\u001b[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/framework/func_graph.py:1060\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1057\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1059\u001b[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m func_outputs = \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1064\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[39m, in \u001b[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m default_graph._variable_creator_scope(scope, priority=\u001b[32m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    596\u001b[39m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[32m    597\u001b[39m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[32m    598\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     out = \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[39m, in \u001b[36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_fn\u001b[39m(*args):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m   ret = \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m   ret = structure.to_tensor_list(\u001b[38;5;28mself\u001b[39m._output_structure, ret)\n\u001b[32m    233\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops.convert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[39m, in \u001b[36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[32m    160\u001b[39m   nested_args = (nested_args,)\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m ret = \u001b[43mautograph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m ret = variable_utils.convert_variables_to_tensors(ret)\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[39m, in \u001b[36mconvert.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m    692\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m'\u001b[39m\u001b[33mag_error_metadata\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.ag_error_metadata.to_exception(e)\n\u001b[32m    694\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    695\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mInaccessibleTensorError\u001b[39m: in user code:\n\n    File \"/tmp/ipykernel_23614/1296142893.py\", line 496, in generate_training_example_tf  *\n        class_with_bbox = calculate_tight_bbox(pixels, class_values, debug=debug)\n    File \"/tmp/ipykernel_23614/1296142893.py\", line 213, in calculate_tight_bbox  *\n        return tf.convert_to_tensor(class_with_bbox, dtype=tf.float32)\n    File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tensorflow/core/function/capture/capture_container.py\", line 144, in capture_by_value\n        graph._validate_in_scope(tensor)  # pylint: disable=protected-access\n\n    InaccessibleTensorError: <tf.Tensor 'while/sub:0' shape=() dtype=int32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it.\n    Please see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.\n    \n    <tf.Tensor 'while/sub:0' shape=() dtype=int32> was defined here:\n        File \"<frozen runpy>\", line 198, in _run_module_as_main\n        File \"<frozen runpy>\", line 88, in _run_code\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n        File \"/home/gaurangdave/anaconda3/envs/ml/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n        File \"/home/gaurangdave/anaconda3/envs/ml/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n        File \"/home/gaurangdave/anaconda3/envs/ml/lib/python3.12/asyncio/events.py\", line 88, in _run\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n        File \"/home/gaurangdave/workspace/mnist_object_detection/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n        File \"/tmp/ipykernel_23614/1812299449.py\", line 9, in <module>\n        File \"/tmp/ipykernel_23614/1296142893.py\", line 496, in generate_training_example_tf\n        File \"/tmp/ipykernel_23614/1296142893.py\", line 205, in calculate_tight_bbox\n        File \"/tmp/ipykernel_23614/1296142893.py\", line 206, in calculate_tight_bbox\n        File \"/tmp/ipykernel_23614/1296142893.py\", line 119, in calculate_bounding_box\n    \n    The tensor <tf.Tensor 'while/sub:0' shape=() dtype=int32> cannot be accessed from FuncGraph(name=Dataset_map_generate_training_example_tf, id=140088841131072), because it was defined in FuncGraph(name=while_body_18724211, id=140088841551168), which is out of scope.\n"
     ]
    }
   ],
   "source": [
    "## temporary just selecting first 32 records to test quickly\n",
    "X_tensor = tf.convert_to_tensor(x_train[:32], dtype=tf.float32)\n",
    "y_tensor = tf.convert_to_tensor(y_train[:32], dtype=tf.float32)\n",
    "batch_size = 32\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "# Use the wrapper inside the map\n",
    "tf_processed_dataset = raw_dataset.map(generate_training_example_tf).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f4af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(processed_dataset.prefetch(tf.data.AUTOTUNE), num_epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
