{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364c7e70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05508ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 09:23:46.606590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761150226.694633    4518 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761150226.721039    4518 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1761150226.920131    4518 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761150226.920190    4518 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761150226.920191    4518 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761150226.920193    4518 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-22 09:23:46.944282: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import fetch_openml\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from matplotlib import patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96daf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d8211",
   "metadata": {},
   "source": [
    "## Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42f27dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"..\",\"data\")\n",
    "models_dir = Path(\"..\",\"models\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c142098",
   "metadata": {},
   "source": [
    "## Defining Bench Mark Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4773b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        print(f\"---- Epoch {epoch_num} ----\")\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        print(f\"Execution time for epoch {epoch_num} : {time.perf_counter() - start_time}\")\n",
    "    print(\"Total Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538acc3",
   "metadata": {},
   "source": [
    "* So single epoch took 2857.236867081 seconds so ~47 mins mamjority of that time went to data generation since we spent only 0.01s perbatch for \"training\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb18704",
   "metadata": {},
   "source": [
    "## Data Generation With Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b91c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MNIST_DATA_PIXELS_TF = tf.constant(x_train, dtype=tf.float32)\n",
    "ALL_MNIST_DATA_CLASSES_TF = tf.constant(y_train, dtype=tf.float32)\n",
    "\n",
    "# number of digits to overlay on canvas\n",
    "num_of_digits = tf.constant(3, dtype=tf.int32)\n",
    "\n",
    "# max digits to define the shape of prediction output\n",
    "MAX_DIGITS = tf.constant(5, dtype=tf.int32)\n",
    "\n",
    "\n",
    "# Sample Base Digits\n",
    "@tf.function\n",
    "def get_sample_indices(dataset, size=5):\n",
    "    dataset_len = tf.shape(dataset)[0] - 1\n",
    "    random_indices = tf.random.uniform(\n",
    "        shape=[size], minval=0, maxval=dataset_len, dtype=tf.int32)\n",
    "    return random_indices\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def sample_base_digits(num_of_digits):\n",
    "    \"\"\"\n",
    "    Sample a specified number of digit images and their class labels from the master MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        num_of_digits (int): Number of digit samples to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sample_pixels, sample_values)\n",
    "            sample_pixels (np.ndarray): Array of digit images with shape (num_of_digits, 28, 28, 1).\n",
    "            sample_values (np.ndarray): Array of class labels with shape (num_of_digits, 1).\n",
    "    \"\"\"\n",
    "    sample_indices = get_sample_indices(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, size=num_of_digits)\n",
    "    sample_pixels = tf.gather(ALL_MNIST_DATA_PIXELS_TF,\n",
    "                              indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_pixels = tf.reshape(sample_pixels, shape=(num_of_digits, 28, 28))\n",
    "\n",
    "    sample_values = tf.gather(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_values = tf.reshape(sample_values, shape=(num_of_digits, 1))\n",
    "    return sample_pixels, sample_values\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "def augment_digits(digits, debug=False):\n",
    "    \"\"\"\n",
    "    Apply random augmentations (translation, zoom, rotation) to a batch of digit images.\n",
    "\n",
    "    Args:\n",
    "        digits (np.ndarray): Array of digit images to augment.\n",
    "        debug (bool, optional): If True, displays before/after images for each digit. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Augmented digit images as a numpy array.\n",
    "    \"\"\"\n",
    "    # step 2: apply random augmentation\n",
    "    augmented_tensor_digits = augmentation(digits)\n",
    "    return augmented_tensor_digits\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_min_max(active_rows, active_cols):\n",
    "    # find x_min, x_max\n",
    "    # step 1 find indices for active x\n",
    "    non_zero_active_cols = tf.where(active_cols != 0)\n",
    "    # get the first and last active x as x_min and x_max\n",
    "    x_min = tf.cast(tf.reduce_min(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "    x_max = tf.cast(tf.reduce_max(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "\n",
    "    ##\n",
    "    non_zero_active_rows = tf.where(active_rows != 0)\n",
    "    y_min = tf.cast(tf.reduce_min(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "    y_max = tf.cast(tf.reduce_max(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_blank_canvas(shape=(100, 100, 1)):\n",
    "    \"\"\"\n",
    "    Create a blank canvas for placing digit images.\n",
    "\n",
    "    Args:\n",
    "        shape (tuple, optional): Shape of the canvas. Defaults to (100, 100, 1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Blank canvas array.\n",
    "    \"\"\"\n",
    "    canvas = tf.zeros(shape=(100, 100, 1), dtype=tf.float32)\n",
    "    return canvas\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_prediction_object():\n",
    "    \"\"\"\n",
    "    Create an empty prediction object for storing digit detection results.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Prediction array of shape (MAX_DIGITS, 15).\n",
    "    \"\"\"\n",
    "    prediction = tf.zeros(shape=(MAX_DIGITS, 15), dtype=tf.float32)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def calculate_tight_bbox(pixels, class_values, padding=1):\n",
    "    \"\"\"Creates bounding box for the digits in pixel tensor and returns a concatenated tensor with bounding box and class\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28) tensor of pixels\n",
    "        class_values (_type_): (m,1) tensor of class values\n",
    "    \"\"\"\n",
    "    # step 1: calculate active rows and cols\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the col\n",
    "    active_rows = tf.reduce_sum(pixels, axis=2)\n",
    "    # tf.print(\"----- active_rows shape : \", tf.shape(active_rows))\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the row\n",
    "    active_cols = tf.reduce_sum(pixels, axis=1)\n",
    "    # tf.print(\"----- active_cols shape : \", tf.shape(active_cols))\n",
    "\n",
    "    # step 2: find non zero coordinates\n",
    "    # create boolean mask for active rows\n",
    "    non_zero_row_mask = active_rows > 0\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_row_mask shape : \", tf.shape(non_zero_row_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_row_coordinates = tf.where(non_zero_row_mask)\n",
    "    # tf.print(\"----- non_zero_row_coordinates shape : \", tf.shape(non_zero_row_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_row_coordinates[:, 1]\n",
    "    segment_ids = non_zero_row_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the rows it gives us y-coordinates of the image\n",
    "    y_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    y_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "\n",
    "    # create boolean mask for active cols\n",
    "    non_zero_col_mask = active_cols > 0\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_col_mask shape : \", tf.shape(non_zero_col_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_col_coordinates = tf.where(non_zero_col_mask)\n",
    "    # tf.print(\"----- non_zero_col_coordinates shape : \", tf.shape(non_zero_col_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_col_coordinates[:, 1]\n",
    "    segment_ids = non_zero_col_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the rows it gives us y-coordinates of the image\n",
    "    x_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    x_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "\n",
    "    # step 3: add padding to pixels\n",
    "    # calculate padding condition for x_min\n",
    "    x_min_padding_cond = x_min > 0\n",
    "    padded_x_min = x_min - padding\n",
    "    x_min = tf.where(x_min_padding_cond, padded_x_min, x_min)\n",
    "\n",
    "    # calculate padding condition for x_max\n",
    "    x_max_padding_cond = x_max < 27\n",
    "    padded_x_max = x_max + padding\n",
    "    x_max = tf.where(x_max_padding_cond, padded_x_max, x_max)\n",
    "\n",
    "    # calculate padding condition for y_min\n",
    "    y_min_padding_cond = y_min > 0\n",
    "    padded_y_min = y_min - padding\n",
    "    y_min = tf.where(y_min_padding_cond, padded_y_min, y_min)\n",
    "\n",
    "    # calculate padding condition for y_max\n",
    "    y_max_padding_cond = y_max < 27\n",
    "    padded_y_max = y_max + padding\n",
    "    y_max = tf.where(y_max_padding_cond, padded_y_max, y_max)\n",
    "\n",
    "    # step 4: calculate x_center & y_center\n",
    "    x_center = tf.round((x_min + x_max) / 2)\n",
    "    y_center = tf.round((y_min + y_max) / 2)\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "\n",
    "    # step 5: calculate width and height\n",
    "    width = x_max - x_min + 1\n",
    "    height = y_max - y_min + 1\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "\n",
    "    # reshape all the values to match class_values\n",
    "    x_min = tf.reshape(x_min, shape=(-1, 1))\n",
    "    x_max = tf.reshape(x_max, shape=(-1, 1))\n",
    "    y_min = tf.reshape(y_min, shape=(-1, 1))\n",
    "    y_max = tf.reshape(y_max, shape=(-1, 1))\n",
    "    x_center = tf.reshape(x_center, shape=(-1, 1))\n",
    "    y_center = tf.reshape(y_center, shape=(-1, 1))\n",
    "    width = tf.reshape(width, shape=(-1, 1))\n",
    "    height = tf.reshape(height, shape=(-1, 1))\n",
    "\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- y_center shape : \", tf.shape(y_center))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- height shape : \", tf.shape(height))\n",
    "\n",
    "    # casting all values to same dtype\n",
    "    x_min = tf.cast(x_min, dtype=tf.int32)\n",
    "    x_max = tf.cast(x_max, dtype=tf.int32)\n",
    "    y_min = tf.cast(y_min, dtype=tf.int32)\n",
    "    y_max = tf.cast(y_max, dtype=tf.int32)\n",
    "    x_center = tf.cast(x_center, dtype=tf.int32)\n",
    "    y_center = tf.cast(y_center, dtype=tf.int32)\n",
    "    width = tf.cast(width, dtype=tf.int32)\n",
    "    height = tf.cast(height, dtype=tf.int32)\n",
    "    class_values = tf.cast(class_values, dtype=tf.int32)\n",
    "\n",
    "    bounding_box = tf.concat(\n",
    "        [x_min, x_max, y_min, y_max, x_center, y_center, width, height, class_values], axis=-1)\n",
    "    # tf.print(\"----- bounding_box shape : \", tf.shape(bounding_box))\n",
    "    return bounding_box\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def augment_digits(pixels):\n",
    "    augmented_pixels = augmentation(pixels)\n",
    "    return augmented_pixels\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def generate_grid(grid_size):\n",
    "    coorinate_range = tf.range(grid_size, dtype=tf.float32)\n",
    "    grid_X, grid_Y = tf.meshgrid(coorinate_range, coorinate_range)\n",
    "    coordinate_grid = tf.stack(values=[grid_X, grid_Y], axis=2)\n",
    "    # normalized_grid = (coordinate_grid + 0.5) / grid_size\n",
    "    return coordinate_grid\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def is_valid_top_left(top, left, width, height, width_limit, height_limit):\n",
    "    return (top + height < height_limit) and (left + width < width_limit)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def map_bbox_to_grid_cells(bbox_grid_cells):\n",
    "    \"\"\"Helper function maps bbox x_min,y_min to top,left inside the cell\n",
    "\n",
    "    Args:\n",
    "        bbox_grid_cells (_type_): tensor of shape (13)\n",
    "\n",
    "    Returns:\n",
    "        _type_: tensor\n",
    "    \"\"\"\n",
    "    # x_min,x_max,y_min,y_max = bbox_grid_cells[0:4]\n",
    "    bbox_width = bbox_grid_cells[6]\n",
    "    bbox_height = bbox_grid_cells[7]\n",
    "    # grid_cell_x, grid_cell_y,grid_width,grid_height = bbox_grid_cells[9:]\n",
    "    # step 1: generate random top/left pair\n",
    "    grid_cell_x = bbox_grid_cells[9]\n",
    "    grid_cell_y = bbox_grid_cells[10]\n",
    "    grid_cell_width_limit = bbox_grid_cells[11]\n",
    "    grid_cell_height_limit = bbox_grid_cells[12]\n",
    "    \n",
    "    max_left = grid_cell_width_limit - bbox_width\n",
    "    max_top = grid_cell_height_limit - bbox_height\n",
    "    \n",
    "    left = tf.random.uniform(shape=[], minval=grid_cell_x,\n",
    "                             maxval=max_left, dtype=tf.int32)\n",
    "    top = tf.random.uniform(shape=[], minval=grid_cell_y,\n",
    "                            maxval=max_top, dtype=tf.int32)\n",
    "    # tf.print(\"grid_cell_x,grid_cell_y,grid_cell_width,grid_cell_height : \",\n",
    "    #          grid_cell_x, grid_cell_y, grid_cell_width_limit, grid_cell_height_limit)\n",
    "    # tf.print(\"top : \", top)\n",
    "    # tf.print(\"left : \", left)\n",
    "\n",
    "    return tf.stack([top,left], axis=-1)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def place_digit_on_canvas(pixels, class_values_with_bbox):\n",
    "    \"\"\"Function to extract the place the digits from pixels tensor on a 100x100 canvas\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28) - tensor of m 28x28 images\n",
    "        class_values_with_bbox (_type_): (m,9) - tensor of bounding box coordinates for m digits.\n",
    "    \"\"\"\n",
    "    pixels_dimensions = tf.shape(pixels)\n",
    "    batch_size = pixels_dimensions[0]\n",
    "\n",
    "    # step 1: Divide the 100x100 canvas with 3x3 cells and select random grid cells to place the digit in.\n",
    "    # generate grid size\n",
    "    grid_size = 3\n",
    "    grid = generate_grid(grid_size=grid_size)\n",
    "    # reshape the grid so that we can select from the pool of 9 coordinates\n",
    "    grid = tf.reshape(grid, shape=(-1,2))\n",
    "    # shuffle grid indices for random selection - this would create grid coordinates in random order\n",
    "    # which means first row can have coordinates for other rows as well.\n",
    "    shuffled_grid = tf.random.shuffle(value=grid)\n",
    "    # create random grid cells\n",
    "    random_grid_cells = shuffled_grid[:batch_size,:]\n",
    "    # tf.print(\"----- random_grid_cells shape : \", tf.shape(random_grid_cells))\n",
    "    grid_cell_size = tf.floor(100 / grid_size)\n",
    "    # scale grid cell coordinates\n",
    "    scalled_random_grid_cells = random_grid_cells * grid_cell_size\n",
    "    # tf.print(\"----- scalled_random_grid_cells shape : \", tf.shape(scalled_random_grid_cells))\n",
    "    # calculate the width and height limit of grid cells\n",
    "    grid_cell_dimensions = scalled_random_grid_cells + grid_cell_size\n",
    "    # tf.print(\"----- grid_cell_dimensions shape : \", tf.shape(grid_cell_dimensions))\n",
    "    # concatenate the info\n",
    "    final_grid_cells = tf.concat(\n",
    "        [scalled_random_grid_cells, grid_cell_dimensions], axis=-1)\n",
    "    final_grid_cells = tf.cast(final_grid_cells, dtype=tf.int32)\n",
    "    # tf.print(\"----- final_grid_cells shape : \", tf.shape(final_grid_cells))\n",
    "\n",
    "    # step 2: get the top/left pixels in each cell where we can place the bbox in the cell\n",
    "    bbox_grid_cells = tf.concat(\n",
    "        [class_values_with_bbox, final_grid_cells], axis=-1)\n",
    "\n",
    "    # tf.print(\"----- bbox_grid_cells.shape : \", tf.shape(bbox_grid_cells))\n",
    "    bbox_grid_cell_top_left = tf.map_fn(\n",
    "        map_bbox_to_grid_cells, bbox_grid_cells)\n",
    "    tf.print(\"----- bbox_grid_cell_top_left shape : \", tf.shape(bbox_grid_cell_top_left))\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def generate_training_example_tf(x, y, debug=True):\n",
    "    \"\"\"\n",
    "    Generate a training example by placing digits on a canvas and creating the corresponding prediction object.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Input digit image(s).\n",
    "        y (np.ndarray): Corresponding class label(s).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (canvas, prediction) where canvas is the composed image and prediction is the label array.\n",
    "    \"\"\"\n",
    "    pixels = tf.reshape(x, shape=(-1, 28, 28))\n",
    "    class_values = tf.reshape(y, shape=(-1, 1))\n",
    "\n",
    "    # if debug:\n",
    "    # tf.print(\"----- pixels shape : \", tf.shape(pixels))\n",
    "    # tf.print(\"----- class_values shape : \", tf.shape(class_values))\n",
    "    # step 1: sample additional digits\n",
    "    if num_of_digits - 1 > 0:\n",
    "        additional_digits, additional_class_values = sample_base_digits(\n",
    "            num_of_digits - 1)\n",
    "        pixels = tf.concat([pixels, additional_digits], axis=0)\n",
    "        class_values = tf.concat(\n",
    "            [class_values, additional_class_values], axis=0)\n",
    "\n",
    "        # if debug:\n",
    "        # tf.print(\"----- pixels with additional_digits shape : \", tf.shape(pixels))\n",
    "        # tf.print(\"----- class_values with additional_class_values shape : \", tf.shape(class_values))\n",
    "\n",
    "    # step 2: augment digits\n",
    "    augmented_pixels = augment_digits(pixels)\n",
    "    # if debug:\n",
    "    # tf.print(\"----- augmented_pixels shape : \", tf.shape(augmented_pixels))\n",
    "\n",
    "    # step 3: calculate bounding box\n",
    "    class_values_with_bbox = calculate_tight_bbox(\n",
    "        augmented_pixels, class_values)\n",
    "\n",
    "    # # step 4: create blank canvas and prediction\n",
    "    canvas = create_blank_canvas()\n",
    "    prediction = create_prediction_object()\n",
    "\n",
    "    # # step 5: place digit on canvas\n",
    "    canvas, class_bbox = place_digit_on_canvas(\n",
    "        pixels, class_values_with_bbox)\n",
    "\n",
    "    # # step 6: translate bbox to prediction object\n",
    "    # prediction = translate_bbox_to_prediction(\n",
    "    #     class_bbox, prediction, debug=debug)\n",
    "\n",
    "    # # print(f\"Final canvas shape {canvas.shape}, final prediction shape {prediction.shape}\")\n",
    "    # tf.print(\"----- Processed Sample -----\")\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d6ba9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "## temporary just selecting first 32 records to test quickly\n",
    "X_tensor = tf.convert_to_tensor(x_train[:32], dtype=tf.float32)\n",
    "y_tensor = tf.convert_to_tensor(y_train[:32], dtype=tf.float32)\n",
    "batch_size = 32\n",
    "\n",
    "# print(tf.shape(X_tensor))\n",
    "# print(tf.shape(y_tensor))\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "# Use the wrapper inside the map\n",
    "tf_processed_dataset = raw_dataset.map(generate_training_example_tf).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f5710",
   "metadata": {},
   "source": [
    "### Bench Marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9b6f4af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 0 ----\n",
      "----- bbox_grid_cell_top_left :  [[46 9]\n",
      " [80 3]\n",
      " [33 73]]\n",
      "----- bbox_grid_cell_top_left :  [[9 76]\n",
      " [38 34]\n",
      " [5 34]]\n",
      "----- bbox_grid_cell_top_left :  [[15 67]\n",
      " [11 34]\n",
      " [87 6]]\n",
      "----- bbox_grid_cell_top_left :  [[46 9]\n",
      " [80 3]\n",
      " [33 73]]\n",
      "----- bbox_grid_cell_top_left :  [[9 76]\n",
      " [38 34]\n",
      " [5 34]]\n",
      "----- bbox_grid_cell_top_left :  [[15 67]\n",
      " [11 34]\n",
      " [87 6]]\n",
      "----- bbox_grid_cell_top_left :  [[53 39]\n",
      " [69 35]\n",
      " [43 13]]\n",
      "----- bbox_grid_cell_top_left :  [[36 79]\n",
      " [88 33]\n",
      " [81 11]]\n",
      "----- bbox_grid_cell_top_left :  [[22 68]\n",
      " [48 10]\n",
      " [15 40]]\n",
      "----- bbox_grid_cell_top_left :  [[53 39]\n",
      " [69 35]\n",
      " [43 13]]\n",
      "----- bbox_grid_cell_top_left :  [[36 79]\n",
      " [88 33]\n",
      " [81 11]]\n",
      "----- bbox_grid_cell_top_left :  [[22 68]\n",
      " [48 10]\n",
      " [15 40]]\n",
      "----- bbox_grid_cell_top_left :  [[6 76]\n",
      " [4 2]\n",
      " [40 3]]\n",
      "----- bbox_grid_cell_top_left :  [[77 33]\n",
      " [5 71]\n",
      " [70 67]]\n",
      "----- bbox_grid_cell_top_left :  [[51 75]\n",
      " [14 73]\n",
      " [71 76]]\n",
      "----- bbox_grid_cell_top_left :  [[6 76]\n",
      " [4 2]\n",
      " [40 3]]\n",
      "----- bbox_grid_cell_top_left :  [[77 33]\n",
      " [5 71]\n",
      " [70 67]]\n",
      "----- bbox_grid_cell_top_left :  [[51 75]\n",
      " [14 73]\n",
      " [71 76]]\n",
      "----- bbox_grid_cell_top_left :  [[68 69]\n",
      " [3 70]\n",
      " [53 2]]\n",
      "----- bbox_grid_cell_top_left :  [[0 74]\n",
      " [40 42]\n",
      " [36 74]]\n",
      "----- bbox_grid_cell_top_left :  [[78 70]\n",
      " [75 4]\n",
      " [37 34]]\n",
      "----- bbox_grid_cell_top_left :  [[68 69]\n",
      " [3 70]\n",
      " [53 2]]\n",
      "----- bbox_grid_cell_top_left :  [[0 74]\n",
      " [40 42]\n",
      " [36 74]]\n",
      "----- bbox_grid_cell_top_left :  [[78 70]\n",
      " [75 4]\n",
      " [37 34]]\n",
      "----- bbox_grid_cell_top_left :  [[76 74]\n",
      " [39 33]\n",
      " [36 75]]\n",
      "----- bbox_grid_cell_top_left :  [[35 2]\n",
      " [41 72]\n",
      " [15 70]]\n",
      "----- bbox_grid_cell_top_left :  [[70 43]\n",
      " [43 11]\n",
      " [55 35]]\n",
      "----- bbox_grid_cell_top_left :  [[76 74]\n",
      " [39 33]\n",
      " [36 75]]\n",
      "----- bbox_grid_cell_top_left :  [[35 2]\n",
      " [41 72]\n",
      " [15 70]]\n",
      "----- bbox_grid_cell_top_left :  [[70 43]\n",
      " [43 11]\n",
      " [55 35]]\n",
      "----- bbox_grid_cell_top_left :  [[5 33]\n",
      " [74 11]\n",
      " [75 41]]\n",
      "----- bbox_grid_cell_top_left :  [[16 37]\n",
      " [33 39]\n",
      " [6 10]]\n",
      "----- bbox_grid_cell_top_left :  [[1 75]\n",
      " [1 6]\n",
      " [45 68]]\n",
      "----- bbox_grid_cell_top_left :  [[5 33]\n",
      " [74 11]\n",
      " [75 41]]\n",
      "----- bbox_grid_cell_top_left :  [[16 37]\n",
      " [33 39]\n",
      " [6 10]]\n",
      "----- bbox_grid_cell_top_left :  [[1 75]\n",
      " [1 6]\n",
      " [45 68]]\n",
      "----- bbox_grid_cell_top_left :  [[42 38]\n",
      " [44 12]\n",
      " [14 76]]\n",
      "----- bbox_grid_cell_top_left :  [[1 44]\n",
      " [86 35]\n",
      " [16 71]]\n",
      "----- bbox_grid_cell_top_left :  [[34 33]\n",
      " [72 76]\n",
      " [80 36]]\n",
      "----- bbox_grid_cell_top_left :  [[42 38]\n",
      " [44 12]\n",
      " [14 76]]\n",
      "----- bbox_grid_cell_top_left :  [[1 44]\n",
      " [86 35]\n",
      " [16 71]]\n",
      "----- bbox_grid_cell_top_left :  [[34 33]\n",
      " [72 76]\n",
      " [80 36]]\n",
      "----- bbox_grid_cell_top_left :  [[7 40]\n",
      " [36 66]\n",
      " [1 72]]\n",
      "----- bbox_grid_cell_top_left :  [[42 72]\n",
      " [68 40]\n",
      " [4 79]]\n",
      "----- bbox_grid_cell_top_left :  [[5 68]\n",
      " [35 33]\n",
      " [69 70]]\n",
      "----- bbox_grid_cell_top_left :  [[7 40]\n",
      " [36 66]\n",
      " [1 72]]\n",
      "----- bbox_grid_cell_top_left :  [[42 72]\n",
      " [68 40]\n",
      " [4 79]]\n",
      "----- bbox_grid_cell_top_left :  [[5 68]\n",
      " [35 33]\n",
      " [69 70]]\n",
      "----- bbox_grid_cell_top_left :  [[74 7]\n",
      " [73 74]\n",
      " [48 34]]\n",
      "----- bbox_grid_cell_top_left :  [[48 34]\n",
      " [74 70]\n",
      " [34 0]]\n",
      "----- bbox_grid_cell_top_left :  [[46 39]\n",
      " [3 0]\n",
      " [70 42]]\n",
      "----- bbox_grid_cell_top_left :  [[74 7]\n",
      " [73 74]\n",
      " [48 34]]\n",
      "----- bbox_grid_cell_top_left :  [[48 34]\n",
      " [74 70]\n",
      " [34 0]]\n",
      "----- bbox_grid_cell_top_left :  [[46 39]\n",
      " [3 0]\n",
      " [70 42]]\n",
      "----- bbox_grid_cell_top_left :  [[38 68]\n",
      " [75 0]\n",
      " [40 47]]\n",
      "----- bbox_grid_cell_top_left :  [[80 8]\n",
      " [81 68]\n",
      " [8 4]]\n",
      "----- bbox_grid_cell_top_left :  [[77 0]\n",
      " [8 34]\n",
      " [33 0]]\n",
      "----- bbox_grid_cell_top_left :  [[38 68]\n",
      " [75 0]\n",
      " [40 47]]\n",
      "----- bbox_grid_cell_top_left :  [[80 8]\n",
      " [81 68]\n",
      " [8 4]]\n",
      "----- bbox_grid_cell_top_left :  [[77 0]\n",
      " [8 34]\n",
      " [33 0]]\n",
      "----- bbox_grid_cell_top_left :  [[66 72]\n",
      " [79 33]\n",
      " [44 71]]\n",
      "----- bbox_grid_cell_top_left :  [[41 72]\n",
      " [34 3]\n",
      " [67 66]]\n",
      "----- bbox_grid_cell_top_left :  [[66 72]\n",
      " [79 33]\n",
      " [44 71]]\n",
      "----- bbox_grid_cell_top_left :  [[41 72]\n",
      " [34 3]\n",
      " [67 66]]\n",
      "Execution time for epoch 0 : 0.42352819300140254\n",
      "Total Execution time: 0.42546846500772517\n",
      "Execution time for epoch 0 : 0.42352819300140254\n",
      "Total Execution time: 0.42546846500772517\n"
     ]
    }
   ],
   "source": [
    "benchmark(tf_processed_dataset.prefetch(tf.data.AUTOTUNE), num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ceba19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
