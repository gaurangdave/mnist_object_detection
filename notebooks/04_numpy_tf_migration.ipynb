{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364c7e70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05508ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f96daf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d8211",
   "metadata": {},
   "source": [
    "## Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e42f27dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"..\",\"data\")\n",
    "models_dir = Path(\"..\",\"models\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c142098",
   "metadata": {},
   "source": [
    "## Defining Bench Mark Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca4773b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        print(f\"---- Epoch {epoch_num} ----\")\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        print(f\"Execution time for epoch {epoch_num} : {time.perf_counter() - start_time}\")\n",
    "    print(\"Total Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538acc3",
   "metadata": {},
   "source": [
    "* So single epoch took 2857.236867081 seconds so ~47 mins mamjority of that time went to data generation since we spent only 0.01s perbatch for \"training\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb18704",
   "metadata": {},
   "source": [
    "## Data Generation With Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5b91c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MNIST_DATA_PIXELS_TF = tf.constant(x_train, dtype=tf.float32)\n",
    "ALL_MNIST_DATA_CLASSES_TF = tf.constant(y_train, dtype=tf.float32)\n",
    "\n",
    "# number of digits to overlay on canvas\n",
    "num_of_digits = tf.constant(5, dtype=tf.int32)\n",
    "\n",
    "# max digits to define the shape of prediction output\n",
    "MAX_DIGITS = tf.constant(5, dtype=tf.int32)\n",
    "\n",
    "\n",
    "# Sample Base Digits\n",
    "@tf.function\n",
    "def get_sample_indices(dataset, size=5):\n",
    "    dataset_len = tf.shape(dataset)[0] - 1\n",
    "    random_indices = tf.random.uniform(\n",
    "        shape=[size], minval=0, maxval=dataset_len, dtype=tf.int32)\n",
    "    return random_indices\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def sample_base_digits(num_of_digits):\n",
    "    \"\"\"\n",
    "    Sample a specified number of digit images and their class labels from the master MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        num_of_digits (int): Number of digit samples to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sample_pixels, sample_values)\n",
    "            sample_pixels (np.ndarray): Array of digit images with shape (num_of_digits, 28, 28, 1).\n",
    "            sample_values (np.ndarray): Array of class labels with shape (num_of_digits, 1).\n",
    "    \"\"\"\n",
    "    sample_indices = get_sample_indices(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, size=num_of_digits)\n",
    "    sample_pixels = tf.gather(ALL_MNIST_DATA_PIXELS_TF,\n",
    "                              indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_pixels = tf.reshape(sample_pixels, shape=(num_of_digits, 28, 28, 1))\n",
    "\n",
    "    sample_values = tf.gather(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_values = tf.reshape(sample_values, shape=(num_of_digits, 1))\n",
    "    return sample_pixels, sample_values\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "def augment_digits(digits):\n",
    "    \"\"\"\n",
    "    Apply random augmentations (translation, zoom, rotation) to a batch of digit images.\n",
    "\n",
    "    Args:\n",
    "        digits (np.ndarray): Array of digit images to augment.\n",
    "        debug (bool, optional): If True, displays before/after images for each digit. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Augmented digit images as a numpy array.\n",
    "    \"\"\"\n",
    "    # step 2: apply random augmentation\n",
    "    augmented_tensor_digits = augmentation(digits)\n",
    "    return augmented_tensor_digits\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_min_max(active_rows, active_cols):\n",
    "    # find x_min, x_max\n",
    "    # step 1 find indices for active x\n",
    "    non_zero_active_cols = tf.where(active_cols != 0)\n",
    "    # get the first and last active x as x_min and x_max\n",
    "    x_min = tf.cast(tf.reduce_min(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "    x_max = tf.cast(tf.reduce_max(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "\n",
    "    ##\n",
    "    non_zero_active_rows = tf.where(active_rows != 0)\n",
    "    y_min = tf.cast(tf.reduce_min(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "    y_max = tf.cast(tf.reduce_max(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_blank_canvas(shape=(100, 100, 1)):\n",
    "    \"\"\"\n",
    "    Create a blank canvas for placing digit images.\n",
    "\n",
    "    Args:\n",
    "        shape (tuple, optional): Shape of the canvas. Defaults to (100, 100, 1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Blank canvas array.\n",
    "    \"\"\"\n",
    "    canvas = tf.zeros(shape=(100, 100, 1), dtype=tf.float32)\n",
    "    return canvas\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_prediction_object():\n",
    "    \"\"\"\n",
    "    Create an empty prediction object for storing digit detection results.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Prediction array of shape (MAX_DIGITS, 15).\n",
    "    \"\"\"\n",
    "    prediction = tf.zeros(shape=(MAX_DIGITS, 15), dtype=tf.float32)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def calculate_tight_bbox(pixels, class_values, padding=1):\n",
    "    \"\"\"Creates bounding box for the digits in pixel tensor and returns a concatenated tensor with bounding box and class\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28,1) tensor of pixels\n",
    "        class_values (_type_): (m,1) tensor of class values\n",
    "    \"\"\"\n",
    "    # step 1: calculate active rows and cols\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the col\n",
    "    active_rows = tf.reduce_sum(pixels, axis=[2, 3])\n",
    "    # tf.print(\"----- active_rows shape : \", tf.shape(active_rows))\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the row\n",
    "    active_cols = tf.reduce_sum(pixels, axis=[1, 3])\n",
    "    # tf.print(\"----- active_cols shape : \", tf.shape(active_cols))\n",
    "\n",
    "    # step 2: find non zero coordinates\n",
    "    # create boolean mask for active rows\n",
    "    non_zero_row_mask = active_rows != 0\n",
    "\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_row_mask shape : \", tf.shape(non_zero_row_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_row_coordinates = tf.where(non_zero_row_mask)\n",
    "    # tf.print(\"----- non_zero_row_coordinates shape : \", tf.shape(non_zero_row_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_row_coordinates[:, 1]\n",
    "    segment_ids = non_zero_row_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the rows it gives us y-coordinates of the image\n",
    "    y_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    y_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "\n",
    "    # create boolean mask for active cols\n",
    "    non_zero_col_mask = active_cols != 0\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_col_mask shape : \", tf.shape(non_zero_col_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_col_coordinates = tf.where(non_zero_col_mask)\n",
    "    # tf.print(\"----- non_zero_col_coordinates shape : \", tf.shape(non_zero_col_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_col_coordinates[:, 1]\n",
    "    segment_ids = non_zero_col_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the cols it gives us x-coordinates of the image\n",
    "    x_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    x_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "\n",
    "    # step 3: add padding to pixels\n",
    "    # calculate padding condition for x_min\n",
    "    x_min_padding_cond = x_min > 0\n",
    "    padded_x_min = x_min - padding\n",
    "    x_min = tf.where(x_min_padding_cond, padded_x_min, x_min)\n",
    "\n",
    "    # calculate padding condition for x_max\n",
    "    x_max_padding_cond = x_max < 27\n",
    "    padded_x_max = x_max + padding\n",
    "    x_max = tf.where(x_max_padding_cond, padded_x_max, x_max)\n",
    "\n",
    "    # calculate padding condition for y_min\n",
    "    y_min_padding_cond = y_min > 0\n",
    "    padded_y_min = y_min - padding\n",
    "    y_min = tf.where(y_min_padding_cond, padded_y_min, y_min)\n",
    "\n",
    "    # calculate padding condition for y_max\n",
    "    y_max_padding_cond = y_max < 27\n",
    "    padded_y_max = y_max + padding\n",
    "    y_max = tf.where(y_max_padding_cond, padded_y_max, y_max)\n",
    "\n",
    "    # step 4: calculate x_center & y_center\n",
    "    x_center = tf.round((x_min + x_max) / 2)\n",
    "    y_center = tf.round((y_min + y_max) / 2)\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "\n",
    "    # step 5: calculate width and height\n",
    "    width = x_max - x_min + 1\n",
    "    height = y_max - y_min + 1\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "\n",
    "    # reshape all the values to match class_values\n",
    "    x_min = tf.reshape(x_min, shape=(-1, 1))\n",
    "    x_max = tf.reshape(x_max, shape=(-1, 1))\n",
    "    y_min = tf.reshape(y_min, shape=(-1, 1))\n",
    "    y_max = tf.reshape(y_max, shape=(-1, 1))\n",
    "    x_center = tf.reshape(x_center, shape=(-1, 1))\n",
    "    y_center = tf.reshape(y_center, shape=(-1, 1))\n",
    "    width = tf.reshape(width, shape=(-1, 1))\n",
    "    height = tf.reshape(height, shape=(-1, 1))\n",
    "\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- y_center shape : \", tf.shape(y_center))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- height shape : \", tf.shape(height))\n",
    "\n",
    "    # casting all values to same dtype\n",
    "    x_min = tf.cast(x_min, dtype=tf.int32)\n",
    "    x_max = tf.cast(x_max, dtype=tf.int32)\n",
    "    y_min = tf.cast(y_min, dtype=tf.int32)\n",
    "    y_max = tf.cast(y_max, dtype=tf.int32)\n",
    "    x_center = tf.cast(x_center, dtype=tf.int32)\n",
    "    y_center = tf.cast(y_center, dtype=tf.int32)\n",
    "    width = tf.cast(width, dtype=tf.int32)\n",
    "    height = tf.cast(height, dtype=tf.int32)\n",
    "    class_values = tf.cast(class_values, dtype=tf.int32)\n",
    "\n",
    "    bounding_box = tf.concat(\n",
    "        [x_min, x_max, y_min, y_max, x_center, y_center, width, height, class_values], axis=-1)\n",
    "    # tf.print(\"----- bounding_box shape : \", tf.shape(bounding_box))\n",
    "    return bounding_box\n",
    "\n",
    "\n",
    "# BBOX Indices\n",
    "BBOX_XMIN_IDX = 0\n",
    "BBOX_XMAX_IDX = 1\n",
    "BBOX_YMIN_IDX = 2\n",
    "BBOX_YMAX_IDX = 3\n",
    "BBOX_XCENTER_IDX = 4\n",
    "BBOX_YCENTER_IDX = 5  # (This might be the same as CLASS_IDX)\n",
    "BBOX_WIDTH_IDX = 6\n",
    "BBOX_HEIGHT_IDX = 7\n",
    "BBOX_CLASS_IDX = 8\n",
    "BBOX_CANVAS_TOP_IDX = 9\n",
    "BBOX_CANVAS_LEFT_IDX = 10\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_corners(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    y_min = tf.cast(bbox_info[..., BBOX_YMIN_IDX], dtype=tf.int32)\n",
    "    x_min = tf.cast(bbox_info[..., BBOX_XMIN_IDX], dtype=tf.int32)\n",
    "    y_max = tf.cast(bbox_info[..., BBOX_YMAX_IDX], dtype=tf.int32)\n",
    "    x_max = tf.cast(bbox_info[..., BBOX_XMAX_IDX], dtype=tf.int32)\n",
    "    return y_min, x_min, y_max, x_max\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_dimensions(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    height = tf.cast(bbox_info[..., BBOX_HEIGHT_IDX], dtype=tf.int32)\n",
    "    width = tf.cast(bbox_info[..., BBOX_WIDTH_IDX], dtype=tf.int32)\n",
    "    return height, width\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_center(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    y_center = tf.cast(bbox_info[..., BBOX_YCENTER_IDX], dtype=tf.int32)\n",
    "    x_center = tf.cast(bbox_info[..., BBOX_XCENTER_IDX], dtype=tf.int32)\n",
    "    return y_center, x_center\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_canvas_placement(bbox_info):\n",
    "    \"\"\"Extracts the final (top, left) coords for the canvas.\"\"\"\n",
    "    # Assuming you concatenated these at indices 9 and 10\n",
    "    canvas_top = tf.cast(bbox_info[..., BBOX_CANVAS_TOP_IDX], dtype=tf.int32)\n",
    "    canvas_left = tf.cast(bbox_info[..., BBOX_CANVAS_LEFT_IDX], dtype=tf.int32)\n",
    "    return canvas_top, canvas_left\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def augment_digits(pixels):\n",
    "    augmented_pixels = augmentation(pixels)\n",
    "    return augmented_pixels\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def generate_grid(grid_size):\n",
    "    coorinate_range = tf.range(grid_size, dtype=tf.float32)\n",
    "    grid_X, grid_Y = tf.meshgrid(coorinate_range, coorinate_range)\n",
    "    coordinate_grid = tf.stack(values=[grid_X, grid_Y], axis=2)\n",
    "    # normalized_grid = (coordinate_grid + 0.5) / grid_size\n",
    "    return coordinate_grid\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def map_bbox_to_grid_cells(bbox_grid_cells):\n",
    "    \"\"\"Helper function maps bbox x_min,y_min to top,left inside the cell\n",
    "\n",
    "    Args:\n",
    "        bbox_grid_cells (_type_): tensor of shape (13)\n",
    "\n",
    "    Returns:\n",
    "        _type_: tensor\n",
    "    \"\"\"\n",
    "    # x_min,x_max,y_min,y_max = bbox_grid_cells[0:4]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cells)\n",
    "    # grid_cell_x, grid_cell_y,grid_width,grid_height = bbox_grid_cells[9:]\n",
    "    # step 1: generate random top/left pair\n",
    "    grid_cell_x = bbox_grid_cells[9]\n",
    "    grid_cell_y = bbox_grid_cells[10]\n",
    "    grid_cell_width_limit = bbox_grid_cells[11]\n",
    "    grid_cell_height_limit = bbox_grid_cells[12]\n",
    "\n",
    "    max_left = grid_cell_width_limit - bbox_width\n",
    "    max_top = grid_cell_height_limit - bbox_height\n",
    "\n",
    "    left = tf.random.uniform(shape=[], minval=grid_cell_x,\n",
    "                             maxval=max_left+1, dtype=tf.int32)\n",
    "    top = tf.random.uniform(shape=[], minval=grid_cell_y,\n",
    "                            maxval=max_top+1, dtype=tf.int32)\n",
    "    return tf.stack([top, left], axis=-1)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_canvas_grid_cells(batch_size, grid_size):\n",
    "    \"\"\"Helper function that creates a grid of shape (grid_size,grid_size), scales it to 100x100 canvas and returns random grid cells and its dimensions\n",
    "\n",
    "    Args:\n",
    "        batch_size (_type_): _description_\n",
    "        grid_size (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    grid = generate_grid(grid_size=grid_size)\n",
    "    # reshape the grid so that we can select from the pool of 9 coordinates\n",
    "    grid = tf.reshape(grid, shape=(-1, 2))\n",
    "    # shuffle grid indices for random selection - this would create grid coordinates in random order\n",
    "    # which means first row can have coordinates for other rows as well.\n",
    "    shuffled_grid = tf.random.shuffle(value=grid)\n",
    "    # create random grid cells\n",
    "    random_grid_cells = shuffled_grid[:batch_size, :]\n",
    "    # tf.print(\"----- random_grid_cells shape : \", tf.shape(random_grid_cells))\n",
    "    grid_cell_size = tf.floor(100 / grid_size)\n",
    "    # scale grid cell coordinates\n",
    "    scalled_random_grid_cells = random_grid_cells * grid_cell_size\n",
    "    # tf.print(\"----- scalled_random_grid_cells shape : \", tf.shape(scalled_random_grid_cells))\n",
    "    # calculate the width and height limit of grid cells\n",
    "    grid_cell_dimensions = scalled_random_grid_cells + grid_cell_size\n",
    "    # tf.print(\"----- grid_cell_dimensions shape : \", tf.shape(grid_cell_dimensions))\n",
    "    # concatenate the info\n",
    "    final_grid_cells = tf.concat(\n",
    "        [scalled_random_grid_cells, grid_cell_dimensions], axis=-1)\n",
    "    final_grid_cells = tf.cast(final_grid_cells, dtype=tf.int32)\n",
    "    return final_grid_cells\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def map_bbox_to_patch_indices(elems):\n",
    "    \"\"\"Helper function to map bounding boxes to patches with coordinates\n",
    "\n",
    "    Args:\n",
    "        bbox_grid_cell_top_left (_type_): _description_\n",
    "    \"\"\"\n",
    "    single_image_data, bbox_grid_cell_top_left = elems\n",
    "    # tf.print(\"pixels shape : \", tf.shape(pixels))\n",
    "\n",
    "    # bbbox_grid_cell_top_left order x_min, x_max, y_min, y_max, x_center, y_center, width, height, class_values,top,left\n",
    "    # tf.print(\"bbox_grid_cell_top_left : \", bbox_grid_cell_top_left)\n",
    "\n",
    "    # step 1: create mesh grid indices based on width and height\n",
    "    # width_height = bbox_grid_cell_top_left[BBOX_WIDTH_IDX:BBOX_HEIGHT_IDX+1]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cell_top_left)\n",
    "    bbox_y_min, bbox_x_min, bbox_y_max, bbox_x_max = get_bbox_corners(\n",
    "        bbox_grid_cell_top_left)\n",
    "\n",
    "    patch_y, patch_x = tf.meshgrid(\n",
    "        tf.range(0, bbox_height), tf.range(0, bbox_width), indexing=\"ij\")\n",
    "    patch_grid = tf.stack([patch_y, patch_x], axis=-1)\n",
    "    # tf.print(\"----- patch_grid shape : \", tf.shape(patch_grid))\n",
    "\n",
    "    # create patch indices\n",
    "    y_min_x_min_slice = tf.gather(bbox_grid_cell_top_left, [2, 0])\n",
    "\n",
    "    # add dimensions to match patch_grid shape\n",
    "    y_min_x_min_slice = y_min_x_min_slice[tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    # add x_min, y_min to the patch grid\n",
    "    patch_indices = tf.add(y_min_x_min_slice, patch_grid)\n",
    "    # reshape patch_indices to make them flat\n",
    "    patch_indices = tf.reshape(patch_indices, shape=(-1, 2))\n",
    "    # cast to int32\n",
    "    patch_indices = tf.cast(patch_indices, dtype=tf.int32)\n",
    "\n",
    "    # read single_image_data data\n",
    "    # single_image_data is (28, 28, 1)\n",
    "    # begin must be 3D: [y, x, channel_start]\n",
    "    # size must be 3D: [h, w, num_channels]\n",
    "    patch_data = tf.slice(single_image_data,\n",
    "                          begin=[bbox_y_min, bbox_x_min, 0],\n",
    "                          size=[bbox_height, bbox_width, 1])\n",
    "\n",
    "    patch_data = tf.reshape(patch_data, shape=[-1])\n",
    "    # tf.print(\"patch_data : \", tf.shape(patch_data))\n",
    "\n",
    "    # create canvas indices\n",
    "    top_left_slice = tf.gather(bbox_grid_cell_top_left, [9, 10])\n",
    "    top_left_offset = top_left_slice[tf.newaxis, tf.newaxis, :]\n",
    "    canvas_indices = tf.add(top_left_offset, patch_grid)\n",
    "    # reshape patch_indices to make them flat\n",
    "    canvas_indices = tf.reshape(canvas_indices, shape=(-1, 2))\n",
    "    # cast to int32\n",
    "    canvas_indices = tf.cast(canvas_indices, dtype=tf.int32)\n",
    "\n",
    "    # tf.print(\"----- patch_indices shape : \", tf.shape(patch_indices))\n",
    "    return patch_data, canvas_indices\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def place_digit_on_canvas(pixels, class_values_with_bbox):\n",
    "    \"\"\"Function to extract the place the digits from pixels tensor on a 100x100 canvas\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28,1) - tensor of m 28x28 images\n",
    "        class_values_with_bbox (_type_): (m,9) - tensor of bounding box coordinates for m digits.\n",
    "    \"\"\"\n",
    "    pixels_dimensions = tf.shape(pixels)\n",
    "    batch_size = pixels_dimensions[0]\n",
    "\n",
    "    # step 1: Divide the 100x100 canvas with 3x3 cells and select random grid cells to place the digit in.\n",
    "    # generate grid size\n",
    "    grid_size = 3\n",
    "    final_grid_cells = get_canvas_grid_cells(batch_size, grid_size)\n",
    "    # tf.print(\"----- final_grid_cells shape : \", tf.shape(final_grid_cells))\n",
    "\n",
    "    # step 2: get the top/left pixels in each cell where we can place the bbox in the cell\n",
    "    bbox_grid_cells = tf.concat(\n",
    "        [class_values_with_bbox, final_grid_cells], axis=-1)\n",
    "\n",
    "    # tf.print(\"----- bbox_grid_cells.shape : \", tf.shape(bbox_grid_cells))\n",
    "    top_left = tf.map_fn(\n",
    "        map_bbox_to_grid_cells, bbox_grid_cells)\n",
    "    bbox_grid_cell_top_left = tf.concat(\n",
    "        [class_values_with_bbox, top_left], axis=-1)\n",
    "    # tf.print(\"----- bbox_grid_cell_top_left shape : \",tf.shape(bbox_grid_cell_top_left))\n",
    "\n",
    "    # step 3: Read image data from pixels using bbox\n",
    "    # step 3.1: create patch matching bounding box height and width\n",
    "    spec_patch_data = tf.RaggedTensorSpec(\n",
    "        shape=(None,), dtype=tf.float32, ragged_rank=0)\n",
    "    spec_canvas_indices = tf.RaggedTensorSpec(\n",
    "        shape=(None, 2), dtype=tf.int32, ragged_rank=0)\n",
    "\n",
    "    patch_data, canvas_indices = tf.map_fn(map_bbox_to_patch_indices, elems=(\n",
    "        pixels, bbox_grid_cell_top_left), fn_output_signature=(spec_patch_data, spec_canvas_indices))\n",
    "\n",
    "    all_updates = patch_data.flat_values\n",
    "    all_indices = canvas_indices.flat_values\n",
    "\n",
    "    # step 4: Update the canvas with the patch data.\n",
    "    canvas = tf.scatter_nd(\n",
    "        indices=all_indices,\n",
    "        updates=all_updates,\n",
    "        shape=[100, 100]\n",
    "    )\n",
    "\n",
    "    return canvas, bbox_grid_cell_top_left\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def translate_bbox_to_prediction(bbox_grid_cell_top_left):\n",
    "    \"\"\"creates a prediction object using the bbox grid and class value\n",
    "\n",
    "    Args:\n",
    "        prediction (_type_): tensor filled with zeroes of shape (MAX_OBJECTS, 15)\n",
    "        bbox_grid_cell_top_left (_type_): tensor of shape (num_digits, 11)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "        Prediction tensor value order \n",
    "        flag, x_center, y_center, width, height, one hot encoded class values (0 to 9)\n",
    "    \"\"\"\n",
    "    bbox_shape = tf.shape(bbox_grid_cell_top_left)\n",
    "    num_of_digits = bbox_shape[0]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cell_top_left)\n",
    "    bbox_class_val = bbox_grid_cell_top_left[..., BBOX_CLASS_IDX]\n",
    "    bbox_canvas_top = bbox_grid_cell_top_left[..., BBOX_CANVAS_TOP_IDX]\n",
    "    bbox_canvas_left = bbox_grid_cell_top_left[..., BBOX_CANVAS_LEFT_IDX]\n",
    "\n",
    "    # calculate the new canvas centers\n",
    "    canvas_x_center = (2 * bbox_canvas_left + bbox_width - 1)/2\n",
    "    canvas_y_center = (2 * bbox_canvas_top + bbox_height - 1)/2\n",
    "\n",
    "    # normalize the values\n",
    "    canvas_x_center = tf.cast(canvas_x_center / 100.0, dtype=tf.float32)\n",
    "    canvas_y_center = tf.cast(canvas_y_center / 100.0, dtype=tf.float32)\n",
    "\n",
    "    # one hot encoded class values\n",
    "    one_hot_encoded_class = tf.one_hot(indices=bbox_class_val, depth=10)\n",
    "\n",
    "    # flag for prediction\n",
    "    flag = tf.ones(shape=(num_of_digits, 1), dtype=tf.float32)\n",
    "\n",
    "    # reshape width & height\n",
    "    bbox_height = tf.reshape(bbox_height, shape=(-1, 1))\n",
    "    bbox_width = tf.reshape(bbox_width, shape=(-1, 1))\n",
    "\n",
    "    # cast to float32 and NORMALIZE\n",
    "    bbox_height = tf.cast(bbox_height, dtype=tf.float32) / 100.0\n",
    "    bbox_width = tf.cast(bbox_width, dtype=tf.float32) / 100.0\n",
    "\n",
    "    # reshape coordinates\n",
    "    canvas_x_center = tf.reshape(canvas_x_center, shape=(-1, 1))\n",
    "    canvas_y_center = tf.reshape(canvas_y_center, shape=(-1, 1))\n",
    "\n",
    "    # final updates tensor\n",
    "    updates = tf.concat([flag, canvas_x_center, canvas_y_center,\n",
    "                        bbox_width, bbox_height, one_hot_encoded_class], axis=-1)\n",
    "\n",
    "    # indices for scatter_nd\n",
    "    indices = tf.range(15, dtype=tf.int32)\n",
    "    indices = tf.repeat([indices], repeats=num_of_digits, axis=0)\n",
    "    indices = tf.reshape(indices, shape=(-1, 15, 1))\n",
    "    batch_indices = tf.range(num_of_digits, dtype=tf.int32)\n",
    "    batch_indices = batch_indices[:, tf.newaxis, tf.newaxis]\n",
    "    ones_tensor = tf.ones(shape=(num_of_digits, 15, 1), dtype=tf.int32)\n",
    "    stretched_batch_indices = tf.multiply(ones_tensor, batch_indices)\n",
    "\n",
    "    final_indices = tf.concat([stretched_batch_indices, indices], axis=-1)\n",
    "\n",
    "    prediction = tf.scatter_nd(\n",
    "        indices=final_indices, updates=updates, shape=(5, 15))\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def generate_training_example_tf(x, y, debug=True):\n",
    "    \"\"\"\n",
    "    Generate a training example by placing digits on a canvas and creating the corresponding prediction object.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Input digit image(s).\n",
    "        y (np.ndarray): Corresponding class label(s).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (canvas, prediction) where canvas is the composed image and prediction is the label array.\n",
    "    \"\"\"\n",
    "    pixels = tf.reshape(x, shape=(-1, 28, 28, 1))\n",
    "    class_values = tf.reshape(y, shape=(-1, 1))\n",
    "\n",
    "    # if debug:\n",
    "    # tf.print(\"----- pixels shape : \", tf.shape(pixels))\n",
    "    # tf.print(\"----- class_values shape : \", tf.shape(class_values))\n",
    "    # step 1: sample additional digits\n",
    "    if num_of_digits - 1 > 0:\n",
    "        additional_digits, additional_class_values = sample_base_digits(\n",
    "            num_of_digits - 1)\n",
    "        pixels = tf.concat([pixels, additional_digits], axis=0)\n",
    "        class_values = tf.concat(\n",
    "            [class_values, additional_class_values], axis=0)\n",
    "\n",
    "        # if debug:\n",
    "        # tf.print(\"----- pixels with additional_digits shape : \", tf.shape(pixels))\n",
    "        # tf.print(\"----- class_values with additional_class_values shape : \", tf.shape(class_values))\n",
    "\n",
    "    # step 2: augment digits\n",
    "    augmented_pixels = augment_digits(pixels)\n",
    "    cleaned_augmented_pixels = tf.nn.relu(augmented_pixels)\n",
    "\n",
    "    # step 3: calculate bounding box\n",
    "    class_values_with_bbox = calculate_tight_bbox(\n",
    "        cleaned_augmented_pixels, class_values)\n",
    "\n",
    "    # step 4: place digit on canvas\n",
    "    # Returns canvas with digits and bbox grid with new top left\n",
    "    canvas, bbox_grid_cell_top_left = place_digit_on_canvas(\n",
    "        augmented_pixels, class_values_with_bbox)\n",
    "\n",
    "    # step 5: translate bbox to prediction object\n",
    "    prediction = translate_bbox_to_prediction(bbox_grid_cell_top_left)\n",
    "\n",
    "    return canvas, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6ba9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "## temporary just selecting first 32 records to test quickly\n",
    "X_tensor = tf.convert_to_tensor(x_train[:32], dtype=tf.float32)\n",
    "y_tensor = tf.convert_to_tensor(y_train[:32], dtype=tf.float32)\n",
    "batch_size = 32\n",
    "\n",
    "# print(tf.shape(X_tensor))\n",
    "# print(tf.shape(y_tensor))\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "# Use the wrapper inside the map\n",
    "tf_processed_dataset = raw_dataset.map(generate_training_example_tf).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f5710",
   "metadata": {},
   "source": [
    "### Bench Marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b6f4af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 0 ----\n",
      "Execution time for epoch 0 : 0.41120250899984967\n",
      "Total Execution time: 0.41130172299926926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 13:51:56.309647: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "benchmark(tf_processed_dataset.prefetch(tf.data.AUTOTUNE), num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11fd3066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched_canvases shape: (32, 100, 100)\n",
      "predictions shape  tf.Tensor([32  5 15], shape=(3,), dtype=int32)\n",
      "Canvas shape: (100, 100)\n",
      "prediction shape : (5, 15)\n",
      "flag, x_center, y_center, width, height 100.0 67.5 3.5 28.0 22.0\n",
      "flag, x_center, y_center, width, height 100.0 68.5 69.5 25.0 23.0\n",
      "flag, x_center, y_center, width, height 100.0 32.5 72.5 19.0 21.0\n",
      "flag, x_center, y_center, width, height 100.0 7.5 38.5 24.0 26.0\n",
      "flag, x_center, y_center, width, height 100.0 6.5 72.0 21.0 24.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "# Get one batch\n",
    "# Your dataset is batched, so .take(1) gets one full batch\n",
    "for batch in tf_processed_dataset.take(1):\n",
    "    # Your map function returns (canvas, bboxes, labels)\n",
    "    # So, 'batch' is a tuple of (batched_canvases, batched_bboxes, batched_labels)\n",
    "    batched_canvases,predictions = batch\n",
    "    print(f\"batched_canvases shape: {batched_canvases.shape}\")\n",
    "    print(f\"predictions shape \", tf.shape(predictions))\n",
    "    # Get the very first canvas from the batch (shape 100x100)\n",
    "    # We use .numpy() to convert it from a EagerTensor to a NumPy array for plotting\n",
    "    canvas_to_show = batched_canvases[0].numpy()\n",
    "    print(f\"Canvas shape: {canvas_to_show.shape}\")\n",
    "    \n",
    "    # Plot it\n",
    "    # --- Create a figure and axis ---\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "\n",
    "    \n",
    "    prediction = predictions[0]\n",
    "    print(f\"prediction shape : {prediction.shape}\")\n",
    "    ## get the 3 predictions\n",
    "    for i in range(5):\n",
    "        bbox = (prediction[i]).numpy() * 100\n",
    "        \n",
    "        # flag, x_center, y_center, width, height,\n",
    "        flag = bbox[0]\n",
    "        x_center = bbox[1]\n",
    "        y_center = bbox[2]\n",
    "        width = bbox[3]\n",
    "        height = bbox[4]\n",
    "        \n",
    "        x_min = x_center - (width / 2)\n",
    "        y_min = y_center - (width / 2)\n",
    "        \n",
    "        print(\"flag, x_center, y_center, width, height\",flag, x_min, y_min, width, height,)\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min),\n",
    "            width,\n",
    "            height,\n",
    "            linewidth=2,\n",
    "            edgecolor='r',\n",
    "            facecolor='none'\n",
    "        )\n",
    "        \n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(canvas_to_show, cmap='gray')\n",
    "    \n",
    "    \n",
    "    plt.title(\"Generated 100x100 Canvas (Test 1)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0220539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched_canvases shape: (32, 100, 100)\n",
      "predictions shape  tf.Tensor([32  5 15], shape=(3,), dtype=int32)\n",
      "predictions [1.   0.5  0.49 0.25 0.23 0.   0.   0.   0.   0.   1.   0.   0.   0.\n",
      " 0.  ]\n"
     ]
    }
   ],
   "source": [
    "for batch in tf_processed_dataset.take(1):\n",
    "    # Your map function returns (canvas, bboxes, labels)\n",
    "    # So, 'batch' is a tuple of (batched_canvases, batched_bboxes, batched_labels)\n",
    "    batched_canvases,predictions = batch\n",
    "    print(f\"batched_canvases shape: {batched_canvases.shape}\")\n",
    "    print(f\"predictions shape \", tf.shape(predictions))\n",
    "    print(f\"predictions {predictions[0,0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909bad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
