{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364c7e70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05508ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f96daf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d8211",
   "metadata": {},
   "source": [
    "## Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e42f27dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"..\",\"data\")\n",
    "models_dir = Path(\"..\",\"models\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c142098",
   "metadata": {},
   "source": [
    "## Defining Bench Mark Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ca4773b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        print(f\"---- Epoch {epoch_num} ----\")\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        print(f\"Execution time for epoch {epoch_num} : {time.perf_counter() - start_time}\")\n",
    "    print(\"Total Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538acc3",
   "metadata": {},
   "source": [
    "* So single epoch took 2857.236867081 seconds so ~47 mins mamjority of that time went to data generation since we spent only 0.01s perbatch for \"training\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb18704",
   "metadata": {},
   "source": [
    "## Data Generation With Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e5b91c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MNIST_DATA_PIXELS_TF = tf.constant(x_train, dtype=tf.float32)\n",
    "ALL_MNIST_DATA_CLASSES_TF = tf.constant(y_train, dtype=tf.float32)\n",
    "\n",
    "# number of digits to overlay on canvas\n",
    "num_of_digits = tf.constant(3, dtype=tf.int32)\n",
    "\n",
    "# max digits to define the shape of prediction output\n",
    "MAX_DIGITS = tf.constant(5, dtype=tf.int32)\n",
    "\n",
    "\n",
    "# Sample Base Digits\n",
    "@tf.function\n",
    "def get_sample_indices(dataset, size=5):\n",
    "    dataset_len = tf.shape(dataset)[0] - 1\n",
    "    random_indices = tf.random.uniform(\n",
    "        shape=[size], minval=0, maxval=dataset_len, dtype=tf.int32)\n",
    "    return random_indices\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def sample_base_digits(num_of_digits):\n",
    "    \"\"\"\n",
    "    Sample a specified number of digit images and their class labels from the master MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        num_of_digits (int): Number of digit samples to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sample_pixels, sample_values)\n",
    "            sample_pixels (np.ndarray): Array of digit images with shape (num_of_digits, 28, 28, 1).\n",
    "            sample_values (np.ndarray): Array of class labels with shape (num_of_digits, 1).\n",
    "    \"\"\"\n",
    "    sample_indices = get_sample_indices(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, size=num_of_digits)\n",
    "    sample_pixels = tf.gather(ALL_MNIST_DATA_PIXELS_TF,\n",
    "                              indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_pixels = tf.reshape(sample_pixels, shape=(num_of_digits, 28, 28, 1))\n",
    "\n",
    "    sample_values = tf.gather(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_values = tf.reshape(sample_values, shape=(num_of_digits, 1))\n",
    "    return sample_pixels, sample_values\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "def augment_digits(digits):\n",
    "    \"\"\"\n",
    "    Apply random augmentations (translation, zoom, rotation) to a batch of digit images.\n",
    "\n",
    "    Args:\n",
    "        digits (np.ndarray): Array of digit images to augment.\n",
    "        debug (bool, optional): If True, displays before/after images for each digit. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Augmented digit images as a numpy array.\n",
    "    \"\"\"\n",
    "    # step 2: apply random augmentation\n",
    "    augmented_tensor_digits = augmentation(digits)\n",
    "    return augmented_tensor_digits\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_min_max(active_rows, active_cols):\n",
    "    # find x_min, x_max\n",
    "    # step 1 find indices for active x\n",
    "    non_zero_active_cols = tf.where(active_cols != 0)\n",
    "    # get the first and last active x as x_min and x_max\n",
    "    x_min = tf.cast(tf.reduce_min(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "    x_max = tf.cast(tf.reduce_max(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "\n",
    "    ##\n",
    "    non_zero_active_rows = tf.where(active_rows != 0)\n",
    "    y_min = tf.cast(tf.reduce_min(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "    y_max = tf.cast(tf.reduce_max(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_blank_canvas(shape=(100, 100, 1)):\n",
    "    \"\"\"\n",
    "    Create a blank canvas for placing digit images.\n",
    "\n",
    "    Args:\n",
    "        shape (tuple, optional): Shape of the canvas. Defaults to (100, 100, 1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Blank canvas array.\n",
    "    \"\"\"\n",
    "    canvas = tf.zeros(shape=(100, 100, 1), dtype=tf.float32)\n",
    "    return canvas\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_prediction_object():\n",
    "    \"\"\"\n",
    "    Create an empty prediction object for storing digit detection results.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Prediction array of shape (MAX_DIGITS, 15).\n",
    "    \"\"\"\n",
    "    prediction = tf.zeros(shape=(MAX_DIGITS, 15), dtype=tf.float32)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def calculate_tight_bbox(pixels, class_values, padding=1):\n",
    "    \"\"\"Creates bounding box for the digits in pixel tensor and returns a concatenated tensor with bounding box and class\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28,1) tensor of pixels\n",
    "        class_values (_type_): (m,1) tensor of class values\n",
    "    \"\"\"\n",
    "    # step 1: calculate active rows and cols\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the col\n",
    "    active_rows = tf.reduce_sum(pixels, axis=[2, 3])\n",
    "    # tf.print(\"----- active_rows shape : \", tf.shape(active_rows))\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the row\n",
    "    active_cols = tf.reduce_sum(pixels, axis=[1, 3])\n",
    "    # tf.print(\"----- active_cols shape : \", tf.shape(active_cols))\n",
    "\n",
    "    # step 2: find non zero coordinates\n",
    "    # create boolean mask for active rows\n",
    "    non_zero_row_mask = active_rows != 0\n",
    "\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_row_mask shape : \", tf.shape(non_zero_row_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_row_coordinates = tf.where(non_zero_row_mask)\n",
    "    # tf.print(\"----- non_zero_row_coordinates shape : \", tf.shape(non_zero_row_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_row_coordinates[:, 1]\n",
    "    segment_ids = non_zero_row_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the rows it gives us y-coordinates of the image\n",
    "    y_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    y_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "\n",
    "    # create boolean mask for active cols\n",
    "    non_zero_col_mask = active_cols != 0\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_col_mask shape : \", tf.shape(non_zero_col_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_col_coordinates = tf.where(non_zero_col_mask)\n",
    "    # tf.print(\"----- non_zero_col_coordinates shape : \", tf.shape(non_zero_col_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_col_coordinates[:, 1]\n",
    "    segment_ids = non_zero_col_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the cols it gives us x-coordinates of the image\n",
    "    x_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    x_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "\n",
    "    # step 3: add padding to pixels\n",
    "    # calculate padding condition for x_min\n",
    "    x_min_padding_cond = x_min > 0\n",
    "    padded_x_min = x_min - padding\n",
    "    x_min = tf.where(x_min_padding_cond, padded_x_min, x_min)\n",
    "\n",
    "    # calculate padding condition for x_max\n",
    "    x_max_padding_cond = x_max < 27\n",
    "    padded_x_max = x_max + padding\n",
    "    x_max = tf.where(x_max_padding_cond, padded_x_max, x_max)\n",
    "\n",
    "    # calculate padding condition for y_min\n",
    "    y_min_padding_cond = y_min > 0\n",
    "    padded_y_min = y_min - padding\n",
    "    y_min = tf.where(y_min_padding_cond, padded_y_min, y_min)\n",
    "\n",
    "    # calculate padding condition for y_max\n",
    "    y_max_padding_cond = y_max < 27\n",
    "    padded_y_max = y_max + padding\n",
    "    y_max = tf.where(y_max_padding_cond, padded_y_max, y_max)\n",
    "\n",
    "    # step 4: calculate x_center & y_center\n",
    "    x_center = tf.round((x_min + x_max) / 2)\n",
    "    y_center = tf.round((y_min + y_max) / 2)\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "\n",
    "    # step 5: calculate width and height\n",
    "    width = x_max - x_min + 1\n",
    "    height = y_max - y_min + 1\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "\n",
    "    # reshape all the values to match class_values\n",
    "    x_min = tf.reshape(x_min, shape=(-1, 1))\n",
    "    x_max = tf.reshape(x_max, shape=(-1, 1))\n",
    "    y_min = tf.reshape(y_min, shape=(-1, 1))\n",
    "    y_max = tf.reshape(y_max, shape=(-1, 1))\n",
    "    x_center = tf.reshape(x_center, shape=(-1, 1))\n",
    "    y_center = tf.reshape(y_center, shape=(-1, 1))\n",
    "    width = tf.reshape(width, shape=(-1, 1))\n",
    "    height = tf.reshape(height, shape=(-1, 1))\n",
    "\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- y_center shape : \", tf.shape(y_center))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- height shape : \", tf.shape(height))\n",
    "\n",
    "    # casting all values to same dtype\n",
    "    x_min = tf.cast(x_min, dtype=tf.int32)\n",
    "    x_max = tf.cast(x_max, dtype=tf.int32)\n",
    "    y_min = tf.cast(y_min, dtype=tf.int32)\n",
    "    y_max = tf.cast(y_max, dtype=tf.int32)\n",
    "    x_center = tf.cast(x_center, dtype=tf.int32)\n",
    "    y_center = tf.cast(y_center, dtype=tf.int32)\n",
    "    width = tf.cast(width, dtype=tf.int32)\n",
    "    height = tf.cast(height, dtype=tf.int32)\n",
    "    class_values = tf.cast(class_values, dtype=tf.int32)\n",
    "\n",
    "    bounding_box = tf.concat(\n",
    "        [x_min, x_max, y_min, y_max, x_center, y_center, width, height, class_values], axis=-1)\n",
    "    # tf.print(\"----- bounding_box shape : \", tf.shape(bounding_box))\n",
    "    return bounding_box\n",
    "\n",
    "\n",
    "# BBOX Indices\n",
    "BBOX_XMIN_IDX = 0\n",
    "BBOX_XMAX_IDX = 1\n",
    "BBOX_YMIN_IDX = 2\n",
    "BBOX_YMAX_IDX = 3\n",
    "BBOX_XCENTER_IDX = 4\n",
    "BBOX_YCENTER_IDX = 5  # (This might be the same as CLASS_IDX)\n",
    "BBOX_WIDTH_IDX = 6\n",
    "BBOX_HEIGHT_IDX = 7\n",
    "BBOX_CLASS_IDX = 8\n",
    "BBOX_CANVAS_TOP_IDX = 9\n",
    "BBOX_CANVAS_LEFT_IDX = 10\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_corners(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    y_min = tf.cast(bbox_info[..., BBOX_YMIN_IDX], dtype=tf.int32)\n",
    "    x_min = tf.cast(bbox_info[..., BBOX_XMIN_IDX], dtype=tf.int32)\n",
    "    y_max = tf.cast(bbox_info[..., BBOX_YMAX_IDX], dtype=tf.int32)\n",
    "    x_max = tf.cast(bbox_info[..., BBOX_XMAX_IDX], dtype=tf.int32)\n",
    "    return y_min, x_min, y_max, x_max\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_dimensions(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    height = tf.cast(bbox_info[..., BBOX_HEIGHT_IDX], dtype=tf.int32)\n",
    "    width = tf.cast(bbox_info[..., BBOX_WIDTH_IDX], dtype=tf.int32)\n",
    "    return height, width\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_center(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    y_center = tf.cast(bbox_info[..., BBOX_YCENTER_IDX], dtype=tf.int32)\n",
    "    x_center = tf.cast(bbox_info[..., BBOX_XCENTER_IDX], dtype=tf.int32)\n",
    "    return y_center, x_center\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_canvas_placement(bbox_info):\n",
    "    \"\"\"Extracts the final (top, left) coords for the canvas.\"\"\"\n",
    "    # Assuming you concatenated these at indices 9 and 10\n",
    "    canvas_top = tf.cast(bbox_info[..., BBOX_CANVAS_TOP_IDX], dtype=tf.int32)\n",
    "    canvas_left = tf.cast(bbox_info[..., BBOX_CANVAS_LEFT_IDX], dtype=tf.int32)\n",
    "    return canvas_top, canvas_left\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def augment_digits(pixels):\n",
    "    augmented_pixels = augmentation(pixels)\n",
    "    return augmented_pixels\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def generate_grid(grid_size):\n",
    "    coorinate_range = tf.range(grid_size, dtype=tf.float32)\n",
    "    grid_X, grid_Y = tf.meshgrid(coorinate_range, coorinate_range)\n",
    "    coordinate_grid = tf.stack(values=[grid_X, grid_Y], axis=2)\n",
    "    # normalized_grid = (coordinate_grid + 0.5) / grid_size\n",
    "    return coordinate_grid\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def map_bbox_to_grid_cells(bbox_grid_cells):\n",
    "    \"\"\"Helper function maps bbox x_min,y_min to top,left inside the cell\n",
    "\n",
    "    Args:\n",
    "        bbox_grid_cells (_type_): tensor of shape (13)\n",
    "\n",
    "    Returns:\n",
    "        _type_: tensor\n",
    "    \"\"\"\n",
    "    # x_min,x_max,y_min,y_max = bbox_grid_cells[0:4]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cells)\n",
    "    # grid_cell_x, grid_cell_y,grid_width,grid_height = bbox_grid_cells[9:]\n",
    "    # step 1: generate random top/left pair\n",
    "    grid_cell_x = bbox_grid_cells[9]\n",
    "    grid_cell_y = bbox_grid_cells[10]\n",
    "    grid_cell_width_limit = bbox_grid_cells[11]\n",
    "    grid_cell_height_limit = bbox_grid_cells[12]\n",
    "\n",
    "    max_left = grid_cell_width_limit - bbox_width\n",
    "    max_top = grid_cell_height_limit - bbox_height\n",
    "\n",
    "    left = tf.random.uniform(shape=[], minval=grid_cell_x,\n",
    "                             maxval=max_left+1, dtype=tf.int32)\n",
    "    top = tf.random.uniform(shape=[], minval=grid_cell_y,\n",
    "                            maxval=max_top+1, dtype=tf.int32)\n",
    "    return tf.stack([top, left], axis=-1)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_canvas_grid_cells(batch_size, grid_size):\n",
    "    \"\"\"Helper function that creates a grid of shape (grid_size,grid_size), scales it to 100x100 canvas and returns random grid cells and its dimensions\n",
    "\n",
    "    Args:\n",
    "        batch_size (_type_): _description_\n",
    "        grid_size (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    grid = generate_grid(grid_size=grid_size)\n",
    "    # reshape the grid so that we can select from the pool of 9 coordinates\n",
    "    grid = tf.reshape(grid, shape=(-1, 2))\n",
    "    # shuffle grid indices for random selection - this would create grid coordinates in random order\n",
    "    # which means first row can have coordinates for other rows as well.\n",
    "    shuffled_grid = tf.random.shuffle(value=grid)\n",
    "    # create random grid cells\n",
    "    random_grid_cells = shuffled_grid[:batch_size, :]\n",
    "    # tf.print(\"----- random_grid_cells shape : \", tf.shape(random_grid_cells))\n",
    "    grid_cell_size = tf.floor(100 / grid_size)\n",
    "    # scale grid cell coordinates\n",
    "    scalled_random_grid_cells = random_grid_cells * grid_cell_size\n",
    "    # tf.print(\"----- scalled_random_grid_cells shape : \", tf.shape(scalled_random_grid_cells))\n",
    "    # calculate the width and height limit of grid cells\n",
    "    grid_cell_dimensions = scalled_random_grid_cells + grid_cell_size\n",
    "    # tf.print(\"----- grid_cell_dimensions shape : \", tf.shape(grid_cell_dimensions))\n",
    "    # concatenate the info\n",
    "    final_grid_cells = tf.concat(\n",
    "        [scalled_random_grid_cells, grid_cell_dimensions], axis=-1)\n",
    "    final_grid_cells = tf.cast(final_grid_cells, dtype=tf.int32)\n",
    "    return final_grid_cells\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def map_bbox_to_patch_indices(elems):\n",
    "    \"\"\"Helper function to map bounding boxes to patches with coordinates\n",
    "\n",
    "    Args:\n",
    "        bbox_grid_cell_top_left (_type_): _description_\n",
    "    \"\"\"\n",
    "    single_image_data, bbox_grid_cell_top_left = elems\n",
    "    # tf.print(\"pixels shape : \", tf.shape(pixels))\n",
    "\n",
    "    # bbbox_grid_cell_top_left order x_min, x_max, y_min, y_max, x_center, y_center, width, height, class_values,top,left\n",
    "    # tf.print(\"bbox_grid_cell_top_left : \", bbox_grid_cell_top_left)\n",
    "\n",
    "    # step 1: create mesh grid indices based on width and height\n",
    "    # width_height = bbox_grid_cell_top_left[BBOX_WIDTH_IDX:BBOX_HEIGHT_IDX+1]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cell_top_left)\n",
    "    bbox_y_min, bbox_x_min, bbox_y_max, bbox_x_max = get_bbox_corners(\n",
    "        bbox_grid_cell_top_left)\n",
    "\n",
    "    patch_y, patch_x = tf.meshgrid(\n",
    "        tf.range(0, bbox_height), tf.range(0, bbox_width), indexing=\"ij\")\n",
    "    patch_grid = tf.stack([patch_y, patch_x], axis=-1)\n",
    "    # tf.print(\"----- patch_grid shape : \", tf.shape(patch_grid))\n",
    "\n",
    "    # create patch indices\n",
    "    y_min_x_min_slice = tf.gather(bbox_grid_cell_top_left, [2, 0])\n",
    "\n",
    "    # add dimensions to match patch_grid shape\n",
    "    y_min_x_min_slice = y_min_x_min_slice[tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    # add x_min, y_min to the patch grid\n",
    "    patch_indices = tf.add(y_min_x_min_slice, patch_grid)\n",
    "    # reshape patch_indices to make them flat\n",
    "    patch_indices = tf.reshape(patch_indices, shape=(-1, 2))\n",
    "    # cast to int32\n",
    "    patch_indices = tf.cast(patch_indices, dtype=tf.int32)\n",
    "\n",
    "    # read single_image_data data\n",
    "    # single_image_data is (28, 28, 1)\n",
    "    # begin must be 3D: [y, x, channel_start]\n",
    "    # size must be 3D: [h, w, num_channels]\n",
    "    patch_data = tf.slice(single_image_data,\n",
    "                          begin=[bbox_y_min, bbox_x_min, 0],\n",
    "                          size=[bbox_height, bbox_width, 1])\n",
    "\n",
    "    patch_data = tf.reshape(patch_data, shape=[-1])\n",
    "    # tf.print(\"patch_data : \", tf.shape(patch_data))\n",
    "\n",
    "    # create canvas indices\n",
    "    top_left_slice = tf.gather(bbox_grid_cell_top_left, [9, 10])\n",
    "    top_left_offset = top_left_slice[tf.newaxis, tf.newaxis, :]\n",
    "    canvas_indices = tf.add(top_left_offset, patch_grid)\n",
    "    # reshape patch_indices to make them flat\n",
    "    canvas_indices = tf.reshape(canvas_indices, shape=(-1, 2))\n",
    "    # cast to int32\n",
    "    canvas_indices = tf.cast(canvas_indices, dtype=tf.int32)\n",
    "\n",
    "    # tf.print(\"----- patch_indices shape : \", tf.shape(patch_indices))\n",
    "    return patch_data, canvas_indices\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def place_digit_on_canvas(pixels, class_values_with_bbox):\n",
    "    \"\"\"Function to extract the place the digits from pixels tensor on a 100x100 canvas\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28,1) - tensor of m 28x28 images\n",
    "        class_values_with_bbox (_type_): (m,9) - tensor of bounding box coordinates for m digits.\n",
    "    \"\"\"\n",
    "    pixels_dimensions = tf.shape(pixels)\n",
    "    batch_size = pixels_dimensions[0]\n",
    "\n",
    "    # step 1: Divide the 100x100 canvas with 3x3 cells and select random grid cells to place the digit in.\n",
    "    # generate grid size\n",
    "    grid_size = 3\n",
    "    final_grid_cells = get_canvas_grid_cells(batch_size, grid_size)\n",
    "    # tf.print(\"----- final_grid_cells shape : \", tf.shape(final_grid_cells))\n",
    "\n",
    "    # step 2: get the top/left pixels in each cell where we can place the bbox in the cell\n",
    "    bbox_grid_cells = tf.concat(\n",
    "        [class_values_with_bbox, final_grid_cells], axis=-1)\n",
    "\n",
    "    # tf.print(\"----- bbox_grid_cells.shape : \", tf.shape(bbox_grid_cells))\n",
    "    top_left = tf.map_fn(\n",
    "        map_bbox_to_grid_cells, bbox_grid_cells)\n",
    "    bbox_grid_cell_top_left = tf.concat(\n",
    "        [class_values_with_bbox, top_left], axis=-1)\n",
    "    # tf.print(\"----- bbox_grid_cell_top_left shape : \",tf.shape(bbox_grid_cell_top_left))\n",
    "\n",
    "    # step 3: Read image data from pixels using bbox\n",
    "    # step 3.1: create patch matching bounding box height and width\n",
    "    spec_patch_data = tf.RaggedTensorSpec(\n",
    "        shape=(None,), dtype=tf.float32, ragged_rank=0)\n",
    "    spec_canvas_indices = tf.RaggedTensorSpec(\n",
    "        shape=(None, 2), dtype=tf.int32, ragged_rank=0)\n",
    "\n",
    "    patch_data, canvas_indices = tf.map_fn(map_bbox_to_patch_indices, elems=(\n",
    "        pixels, bbox_grid_cell_top_left), fn_output_signature=(spec_patch_data, spec_canvas_indices))\n",
    "\n",
    "    all_updates = patch_data.flat_values\n",
    "    all_indices = canvas_indices.flat_values\n",
    "\n",
    "    # step 4: Update the canvas with the patch data.\n",
    "    canvas = tf.scatter_nd(\n",
    "        indices=all_indices,\n",
    "        updates=all_updates,\n",
    "        shape=[100, 100]\n",
    "    )\n",
    "\n",
    "    return canvas, bbox_grid_cell_top_left\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def translate_bbox_to_prediction(bbox_grid_cell_top_left):\n",
    "    \"\"\"creates a prediction object using the bbox grid and class value\n",
    "\n",
    "    Args:\n",
    "        prediction (_type_): tensor filled with zeroes of shape (MAX_OBJECTS, 15)\n",
    "        bbox_grid_cell_top_left (_type_): tensor of shape (num_digits, 11)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "        Prediction tensor value order \n",
    "        flag, x_center, y_center, width, height, one hot encoded class values (0 to 9)\n",
    "    \"\"\"\n",
    "    bbox_shape = tf.shape(bbox_grid_cell_top_left)\n",
    "    num_of_digits = bbox_shape[0]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cell_top_left)\n",
    "    bbox_class_val = bbox_grid_cell_top_left[..., BBOX_CLASS_IDX]\n",
    "    bbox_canvas_top = bbox_grid_cell_top_left[..., BBOX_CANVAS_TOP_IDX]\n",
    "    bbox_canvas_left = bbox_grid_cell_top_left[..., BBOX_CANVAS_LEFT_IDX]\n",
    "\n",
    "    # calculate the new canvas centers\n",
    "    canvas_x_center = (2 * bbox_canvas_left + bbox_width - 1)/2\n",
    "    canvas_y_center = (2 * bbox_canvas_top + bbox_height - 1)/2\n",
    "\n",
    "    # normalize the values\n",
    "    canvas_x_center = tf.cast(canvas_x_center / 100.0, dtype=tf.float32)\n",
    "    canvas_y_center = tf.cast(canvas_y_center / 100.0, dtype=tf.float32)\n",
    "\n",
    "    # one hot encoded class values\n",
    "    one_hot_encoded_class = tf.one_hot(indices=bbox_class_val, depth=10)\n",
    "\n",
    "    # flag for prediction\n",
    "    flag = tf.ones(shape=(num_of_digits, 1), dtype=tf.float32)\n",
    "\n",
    "    # reshape width & height\n",
    "    bbox_height = tf.reshape(bbox_height, shape=(-1, 1))\n",
    "    bbox_width = tf.reshape(bbox_width, shape=(-1, 1))\n",
    "\n",
    "    # cast to float32 and NORMALIZE\n",
    "    bbox_height = tf.cast(bbox_height, dtype=tf.float32) / 100.0\n",
    "    bbox_width = tf.cast(bbox_width, dtype=tf.float32) / 100.0\n",
    "\n",
    "    # reshape coordinates\n",
    "    canvas_x_center = tf.reshape(canvas_x_center, shape=(-1, 1))\n",
    "    canvas_y_center = tf.reshape(canvas_y_center, shape=(-1, 1))\n",
    "\n",
    "    # final updates tensor\n",
    "    updates = tf.concat([flag, canvas_x_center, canvas_y_center,\n",
    "                        bbox_width, bbox_height, one_hot_encoded_class], axis=-1)\n",
    "\n",
    "    # indices for scatter_nd\n",
    "    indices = tf.range(15, dtype=tf.int32)\n",
    "    indices = tf.repeat([indices], repeats=num_of_digits, axis=0)\n",
    "    indices = tf.reshape(indices, shape=(-1, 15, 1))\n",
    "    batch_indices = tf.range(num_of_digits, dtype=tf.int32)\n",
    "    batch_indices = batch_indices[:, tf.newaxis, tf.newaxis]\n",
    "    ones_tensor = tf.ones(shape=(num_of_digits, 15, 1), dtype=tf.int32)\n",
    "    stretched_batch_indices = tf.multiply(ones_tensor, batch_indices)\n",
    "\n",
    "    final_indices = tf.concat([stretched_batch_indices, indices], axis=-1)\n",
    "\n",
    "    prediction = tf.scatter_nd(\n",
    "        indices=final_indices, updates=updates, shape=(5, 15))\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def generate_training_example_tf(x, y, debug=True):\n",
    "    \"\"\"\n",
    "    Generate a training example by placing digits on a canvas and creating the corresponding prediction object.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Input digit image(s).\n",
    "        y (np.ndarray): Corresponding class label(s).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (canvas, prediction) where canvas is the composed image and prediction is the label array.\n",
    "    \"\"\"\n",
    "    pixels = tf.reshape(x, shape=(-1, 28, 28, 1))\n",
    "    class_values = tf.reshape(y, shape=(-1, 1))\n",
    "\n",
    "    # if debug:\n",
    "    # tf.print(\"----- pixels shape : \", tf.shape(pixels))\n",
    "    # tf.print(\"----- class_values shape : \", tf.shape(class_values))\n",
    "    # step 1: sample additional digits\n",
    "    if num_of_digits - 1 > 0:\n",
    "        additional_digits, additional_class_values = sample_base_digits(\n",
    "            num_of_digits - 1)\n",
    "        pixels = tf.concat([pixels, additional_digits], axis=0)\n",
    "        class_values = tf.concat(\n",
    "            [class_values, additional_class_values], axis=0)\n",
    "\n",
    "        # if debug:\n",
    "        # tf.print(\"----- pixels with additional_digits shape : \", tf.shape(pixels))\n",
    "        # tf.print(\"----- class_values with additional_class_values shape : \", tf.shape(class_values))\n",
    "\n",
    "    # step 2: augment digits\n",
    "    augmented_pixels = augment_digits(pixels)\n",
    "    cleaned_augmented_pixels = tf.nn.relu(augmented_pixels)\n",
    "\n",
    "    # step 3: calculate bounding box\n",
    "    class_values_with_bbox = calculate_tight_bbox(\n",
    "        cleaned_augmented_pixels, class_values)\n",
    "\n",
    "    # step 4: place digit on canvas\n",
    "    # Returns canvas with digits and bbox grid with new top left\n",
    "    canvas, bbox_grid_cell_top_left = place_digit_on_canvas(\n",
    "        augmented_pixels, class_values_with_bbox)\n",
    "\n",
    "    # step 5: translate bbox to prediction object\n",
    "    prediction = translate_bbox_to_prediction(bbox_grid_cell_top_left)\n",
    "\n",
    "    return canvas, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d6ba9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "## temporary just selecting first 32 records to test quickly\n",
    "X_tensor = tf.convert_to_tensor(x_train[:32], dtype=tf.float32)\n",
    "y_tensor = tf.convert_to_tensor(y_train[:32], dtype=tf.float32)\n",
    "batch_size = 32\n",
    "\n",
    "# print(tf.shape(X_tensor))\n",
    "# print(tf.shape(y_tensor))\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "# Use the wrapper inside the map\n",
    "tf_processed_dataset = raw_dataset.map(generate_training_example_tf).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f5710",
   "metadata": {},
   "source": [
    "### Bench Marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9b6f4af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 0 ----\n",
      "Execution time for epoch 0 : 0.4750390039989725\n",
      "Total Execution time: 0.475164745002985\n"
     ]
    }
   ],
   "source": [
    "benchmark(tf_processed_dataset.prefetch(tf.data.AUTOTUNE), num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "11fd3066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched_canvases shape: (32, 100, 100)\n",
      "predictions shape  tf.Tensor([32  5 15], shape=(3,), dtype=int32)\n",
      "Canvas shape: (100, 100)\n",
      "prediction shape : (5, 15)\n",
      "flag, x_center, y_center, width, height 100.0 69.5 71.5 23.0 27.000002\n",
      "flag, x_center, y_center, width, height 100.0 35.5 70.0 20.0 25.0\n",
      "flag, x_center, y_center, width, height 100.0 34.5 4.5 17.0 23.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "# Get one batch\n",
    "# Your dataset is batched, so .take(1) gets one full batch\n",
    "for batch in tf_processed_dataset.take(1):\n",
    "    # Your map function returns (canvas, bboxes, labels)\n",
    "    # So, 'batch' is a tuple of (batched_canvases, batched_bboxes, batched_labels)\n",
    "    batched_canvases,predictions = batch\n",
    "    print(f\"batched_canvases shape: {batched_canvases.shape}\")\n",
    "    print(f\"predictions shape \", tf.shape(predictions))\n",
    "    # Get the very first canvas from the batch (shape 100x100)\n",
    "    # We use .numpy() to convert it from a EagerTensor to a NumPy array for plotting\n",
    "    canvas_to_show = batched_canvases[0].numpy()\n",
    "    print(f\"Canvas shape: {canvas_to_show.shape}\")\n",
    "    \n",
    "    # Plot it\n",
    "    # --- Create a figure and axis ---\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "\n",
    "    \n",
    "    prediction = predictions[0]\n",
    "    print(f\"prediction shape : {prediction.shape}\")\n",
    "    ## get the 3 predictions\n",
    "    for i in range(3):\n",
    "        bbox = (prediction[i]).numpy() * 100\n",
    "        \n",
    "        # flag, x_center, y_center, width, height,\n",
    "        flag = bbox[0]\n",
    "        x_center = bbox[1]\n",
    "        y_center = bbox[2]\n",
    "        width = bbox[3]\n",
    "        height = bbox[4]\n",
    "        \n",
    "        x_min = x_center - (width / 2)\n",
    "        y_min = y_center - (width / 2)\n",
    "        \n",
    "        print(\"flag, x_center, y_center, width, height\",flag, x_min, y_min, width, height,)\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min),\n",
    "            width,\n",
    "            height,\n",
    "            linewidth=2,\n",
    "            edgecolor='r',\n",
    "            facecolor='none'\n",
    "        )\n",
    "        \n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(canvas_to_show, cmap='gray')\n",
    "    \n",
    "    \n",
    "    plt.title(\"Generated 100x100 Canvas (Test 1)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220539b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
