{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364c7e70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "05508ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import fetch_openml\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from matplotlib import patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f96daf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d8211",
   "metadata": {},
   "source": [
    "## Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e42f27dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"..\",\"data\")\n",
    "models_dir = Path(\"..\",\"models\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c142098",
   "metadata": {},
   "source": [
    "## Defining Bench Mark Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ca4773b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        print(f\"---- Epoch {epoch_num} ----\")\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        print(f\"Execution time for epoch {epoch_num} : {time.perf_counter() - start_time}\")\n",
    "    print(\"Total Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538acc3",
   "metadata": {},
   "source": [
    "* So single epoch took 2857.236867081 seconds so ~47 mins mamjority of that time went to data generation since we spent only 0.01s perbatch for \"training\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb18704",
   "metadata": {},
   "source": [
    "## Data Generation With Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e5b91c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MNIST_DATA_PIXELS_TF = tf.constant(x_train, dtype=tf.float32)\n",
    "ALL_MNIST_DATA_CLASSES_TF = tf.constant(y_train, dtype=tf.float32)\n",
    "\n",
    "# number of digits to overlay on canvas\n",
    "num_of_digits = tf.constant(3, dtype=tf.int32)\n",
    "\n",
    "# max digits to define the shape of prediction output\n",
    "MAX_DIGITS = tf.constant(5, dtype=tf.int32)\n",
    "\n",
    "\n",
    "# Sample Base Digits\n",
    "@tf.function\n",
    "def get_sample_indices(dataset, size=5):\n",
    "    dataset_len = tf.shape(dataset)[0] - 1\n",
    "    random_indices = tf.random.uniform(\n",
    "        shape=[size], minval=0, maxval=dataset_len, dtype=tf.int32)\n",
    "    return random_indices\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def sample_base_digits(num_of_digits):\n",
    "    \"\"\"\n",
    "    Sample a specified number of digit images and their class labels from the master MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        num_of_digits (int): Number of digit samples to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sample_pixels, sample_values)\n",
    "            sample_pixels (np.ndarray): Array of digit images with shape (num_of_digits, 28, 28, 1).\n",
    "            sample_values (np.ndarray): Array of class labels with shape (num_of_digits, 1).\n",
    "    \"\"\"\n",
    "    sample_indices = get_sample_indices(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, size=num_of_digits)\n",
    "    sample_pixels = tf.gather(ALL_MNIST_DATA_PIXELS_TF,\n",
    "                              indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_pixels = tf.reshape(sample_pixels, shape=(num_of_digits, 28, 28, 1))\n",
    "\n",
    "    sample_values = tf.gather(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_values = tf.reshape(sample_values, shape=(num_of_digits, 1))\n",
    "    return sample_pixels, sample_values\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "def augment_digits(digits):\n",
    "    \"\"\"\n",
    "    Apply random augmentations (translation, zoom, rotation) to a batch of digit images.\n",
    "\n",
    "    Args:\n",
    "        digits (np.ndarray): Array of digit images to augment.\n",
    "        debug (bool, optional): If True, displays before/after images for each digit. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Augmented digit images as a numpy array.\n",
    "    \"\"\"\n",
    "    # step 2: apply random augmentation\n",
    "    augmented_tensor_digits = augmentation(digits)\n",
    "    return augmented_tensor_digits\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_min_max(active_rows, active_cols):\n",
    "    # find x_min, x_max\n",
    "    # step 1 find indices for active x\n",
    "    non_zero_active_cols = tf.where(active_cols != 0)\n",
    "    # get the first and last active x as x_min and x_max\n",
    "    x_min = tf.cast(tf.reduce_min(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "    x_max = tf.cast(tf.reduce_max(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "\n",
    "    ##\n",
    "    non_zero_active_rows = tf.where(active_rows != 0)\n",
    "    y_min = tf.cast(tf.reduce_min(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "    y_max = tf.cast(tf.reduce_max(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_blank_canvas(shape=(100, 100, 1)):\n",
    "    \"\"\"\n",
    "    Create a blank canvas for placing digit images.\n",
    "\n",
    "    Args:\n",
    "        shape (tuple, optional): Shape of the canvas. Defaults to (100, 100, 1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Blank canvas array.\n",
    "    \"\"\"\n",
    "    canvas = tf.zeros(shape=(100, 100, 1), dtype=tf.float32)\n",
    "    return canvas\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_prediction_object():\n",
    "    \"\"\"\n",
    "    Create an empty prediction object for storing digit detection results.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Prediction array of shape (MAX_DIGITS, 15).\n",
    "    \"\"\"\n",
    "    prediction = tf.zeros(shape=(MAX_DIGITS, 15), dtype=tf.float32)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def calculate_tight_bbox(pixels, class_values, padding=1):\n",
    "    \"\"\"Creates bounding box for the digits in pixel tensor and returns a concatenated tensor with bounding box and class\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28,1) tensor of pixels\n",
    "        class_values (_type_): (m,1) tensor of class values\n",
    "    \"\"\"\n",
    "    # step 1: calculate active rows and cols\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the col\n",
    "    active_rows = tf.reduce_sum(pixels, axis=[2, 3])\n",
    "    # tf.print(\"----- active_rows shape : \", tf.shape(active_rows))\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the row\n",
    "    active_cols = tf.reduce_sum(pixels, axis=[1, 3])\n",
    "    # tf.print(\"----- active_cols shape : \", tf.shape(active_cols))\n",
    "\n",
    "    # step 2: find non zero coordinates\n",
    "    # create boolean mask for active rows\n",
    "    non_zero_row_mask = active_rows != 0\n",
    "\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_row_mask shape : \", tf.shape(non_zero_row_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_row_coordinates = tf.where(non_zero_row_mask)\n",
    "    # tf.print(\"----- non_zero_row_coordinates shape : \", tf.shape(non_zero_row_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_row_coordinates[:, 1]\n",
    "    segment_ids = non_zero_row_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the rows it gives us y-coordinates of the image\n",
    "    y_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    y_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "\n",
    "    # create boolean mask for active cols\n",
    "    non_zero_col_mask = active_cols != 0\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_col_mask shape : \", tf.shape(non_zero_col_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_col_coordinates = tf.where(non_zero_col_mask)\n",
    "    # tf.print(\"----- non_zero_col_coordinates shape : \", tf.shape(non_zero_col_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_col_coordinates[:, 1]\n",
    "    segment_ids = non_zero_col_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the cols it gives us x-coordinates of the image\n",
    "    x_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    x_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "\n",
    "    # step 3: add padding to pixels\n",
    "    # calculate padding condition for x_min\n",
    "    x_min_padding_cond = x_min > 0\n",
    "    padded_x_min = x_min - padding\n",
    "    x_min = tf.where(x_min_padding_cond, padded_x_min, x_min)\n",
    "\n",
    "    # calculate padding condition for x_max\n",
    "    x_max_padding_cond = x_max < 27\n",
    "    padded_x_max = x_max + padding\n",
    "    x_max = tf.where(x_max_padding_cond, padded_x_max, x_max)\n",
    "\n",
    "    # calculate padding condition for y_min\n",
    "    y_min_padding_cond = y_min > 0\n",
    "    padded_y_min = y_min - padding\n",
    "    y_min = tf.where(y_min_padding_cond, padded_y_min, y_min)\n",
    "\n",
    "    # calculate padding condition for y_max\n",
    "    y_max_padding_cond = y_max < 27\n",
    "    padded_y_max = y_max + padding\n",
    "    y_max = tf.where(y_max_padding_cond, padded_y_max, y_max)\n",
    "\n",
    "    # step 4: calculate x_center & y_center\n",
    "    x_center = tf.round((x_min + x_max) / 2)\n",
    "    y_center = tf.round((y_min + y_max) / 2)\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "\n",
    "    # step 5: calculate width and height\n",
    "    width = x_max - x_min + 1\n",
    "    height = y_max - y_min + 1\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "\n",
    "    # reshape all the values to match class_values\n",
    "    x_min = tf.reshape(x_min, shape=(-1, 1))\n",
    "    x_max = tf.reshape(x_max, shape=(-1, 1))\n",
    "    y_min = tf.reshape(y_min, shape=(-1, 1))\n",
    "    y_max = tf.reshape(y_max, shape=(-1, 1))\n",
    "    x_center = tf.reshape(x_center, shape=(-1, 1))\n",
    "    y_center = tf.reshape(y_center, shape=(-1, 1))\n",
    "    width = tf.reshape(width, shape=(-1, 1))\n",
    "    height = tf.reshape(height, shape=(-1, 1))\n",
    "\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- y_center shape : \", tf.shape(y_center))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- height shape : \", tf.shape(height))\n",
    "\n",
    "    # casting all values to same dtype\n",
    "    x_min = tf.cast(x_min, dtype=tf.int32)\n",
    "    x_max = tf.cast(x_max, dtype=tf.int32)\n",
    "    y_min = tf.cast(y_min, dtype=tf.int32)\n",
    "    y_max = tf.cast(y_max, dtype=tf.int32)\n",
    "    x_center = tf.cast(x_center, dtype=tf.int32)\n",
    "    y_center = tf.cast(y_center, dtype=tf.int32)\n",
    "    width = tf.cast(width, dtype=tf.int32)\n",
    "    height = tf.cast(height, dtype=tf.int32)\n",
    "    class_values = tf.cast(class_values, dtype=tf.int32)\n",
    "\n",
    "    bounding_box = tf.concat(\n",
    "        [x_min, x_max, y_min, y_max, x_center, y_center, width, height, class_values], axis=-1)\n",
    "    # tf.print(\"----- bounding_box shape : \", tf.shape(bounding_box))\n",
    "    return bounding_box\n",
    "\n",
    "\n",
    "# BBOX Indices\n",
    "BBOX_XMIN_IDX = 0\n",
    "BBOX_XMAX_IDX = 1\n",
    "BBOX_YMIN_IDX = 2\n",
    "BBOX_YMAX_IDX = 3\n",
    "BBOX_XCENTER_IDX = 4\n",
    "BBOX_YCENTER_IDX = 5  # (This might be the same as CLASS_IDX)\n",
    "BBOX_WIDTH_IDX = 6\n",
    "BBOX_HEIGHT_IDX = 7\n",
    "BBOX_CLASS_IDX = 8\n",
    "BBOX_CANVAS_TOP_IDX = 9\n",
    "BBOX_CANVAS_LEFT_IDX = 10\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_corners(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    y_min = tf.cast(bbox_info[..., BBOX_YMIN_IDX], dtype=tf.int32)\n",
    "    x_min = tf.cast(bbox_info[..., BBOX_XMIN_IDX], dtype=tf.int32)\n",
    "    y_max = tf.cast(bbox_info[..., BBOX_YMAX_IDX], dtype=tf.int32)\n",
    "    x_max = tf.cast(bbox_info[..., BBOX_XMAX_IDX], dtype=tf.int32)\n",
    "    return y_min, x_min, y_max, x_max\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_dimensions(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    height = tf.cast(bbox_info[..., BBOX_HEIGHT_IDX], dtype=tf.int32)\n",
    "    width = tf.cast(bbox_info[..., BBOX_WIDTH_IDX], dtype=tf.int32)\n",
    "    return height, width\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_center(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    y_center = tf.cast(bbox_info[..., BBOX_YCENTER_IDX], dtype=tf.int32)\n",
    "    x_center = tf.cast(bbox_info[..., BBOX_XCENTER_IDX], dtype=tf.int32)\n",
    "    return y_center, x_center\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_canvas_placement(bbox_info):\n",
    "    \"\"\"Extracts the final (top, left) coords for the canvas.\"\"\"\n",
    "    # Assuming you concatenated these at indices 9 and 10\n",
    "    canvas_top = tf.cast(bbox_info[..., BBOX_CANVAS_TOP_IDX], dtype=tf.int32)\n",
    "    canvas_left = tf.cast(bbox_info[..., BBOX_CANVAS_LEFT_IDX], dtype=tf.int32)\n",
    "    return canvas_top, canvas_left\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def augment_digits(pixels):\n",
    "    augmented_pixels = augmentation(pixels)\n",
    "    return augmented_pixels\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def generate_grid(grid_size):\n",
    "    coorinate_range = tf.range(grid_size, dtype=tf.float32)\n",
    "    grid_X, grid_Y = tf.meshgrid(coorinate_range, coorinate_range)\n",
    "    coordinate_grid = tf.stack(values=[grid_X, grid_Y], axis=2)\n",
    "    # normalized_grid = (coordinate_grid + 0.5) / grid_size\n",
    "    return coordinate_grid\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def map_bbox_to_grid_cells(bbox_grid_cells):\n",
    "    \"\"\"Helper function maps bbox x_min,y_min to top,left inside the cell\n",
    "\n",
    "    Args:\n",
    "        bbox_grid_cells (_type_): tensor of shape (13)\n",
    "\n",
    "    Returns:\n",
    "        _type_: tensor\n",
    "    \"\"\"\n",
    "    # x_min,x_max,y_min,y_max = bbox_grid_cells[0:4]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cells)\n",
    "    # grid_cell_x, grid_cell_y,grid_width,grid_height = bbox_grid_cells[9:]\n",
    "    # step 1: generate random top/left pair\n",
    "    grid_cell_x = bbox_grid_cells[9]\n",
    "    grid_cell_y = bbox_grid_cells[10]\n",
    "    grid_cell_width_limit = bbox_grid_cells[11]\n",
    "    grid_cell_height_limit = bbox_grid_cells[12]\n",
    "\n",
    "    max_left = grid_cell_width_limit - bbox_width\n",
    "    max_top = grid_cell_height_limit - bbox_height\n",
    "\n",
    "    left = tf.random.uniform(shape=[], minval=grid_cell_x,\n",
    "                             maxval=max_left+1, dtype=tf.int32)\n",
    "    top = tf.random.uniform(shape=[], minval=grid_cell_y,\n",
    "                            maxval=max_top+1, dtype=tf.int32)\n",
    "    return tf.stack([top, left], axis=-1)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_canvas_grid_cells(batch_size, grid_size):\n",
    "    \"\"\"Helper function that creates a grid of shape (grid_size,grid_size), scales it to 100x100 canvas and returns random grid cells and its dimensions\n",
    "\n",
    "    Args:\n",
    "        batch_size (_type_): _description_\n",
    "        grid_size (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    grid = generate_grid(grid_size=grid_size)\n",
    "    # reshape the grid so that we can select from the pool of 9 coordinates\n",
    "    grid = tf.reshape(grid, shape=(-1, 2))\n",
    "    # shuffle grid indices for random selection - this would create grid coordinates in random order\n",
    "    # which means first row can have coordinates for other rows as well.\n",
    "    shuffled_grid = tf.random.shuffle(value=grid)\n",
    "    # create random grid cells\n",
    "    random_grid_cells = shuffled_grid[:batch_size, :]\n",
    "    # tf.print(\"----- random_grid_cells shape : \", tf.shape(random_grid_cells))\n",
    "    grid_cell_size = tf.floor(100 / grid_size)\n",
    "    # scale grid cell coordinates\n",
    "    scalled_random_grid_cells = random_grid_cells * grid_cell_size\n",
    "    # tf.print(\"----- scalled_random_grid_cells shape : \", tf.shape(scalled_random_grid_cells))\n",
    "    # calculate the width and height limit of grid cells\n",
    "    grid_cell_dimensions = scalled_random_grid_cells + grid_cell_size\n",
    "    # tf.print(\"----- grid_cell_dimensions shape : \", tf.shape(grid_cell_dimensions))\n",
    "    # concatenate the info\n",
    "    final_grid_cells = tf.concat(\n",
    "        [scalled_random_grid_cells, grid_cell_dimensions], axis=-1)\n",
    "    final_grid_cells = tf.cast(final_grid_cells, dtype=tf.int32)\n",
    "    return final_grid_cells\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def map_bbox_to_patch_indices(elems):\n",
    "    \"\"\"Helper function to map bounding boxes to patches with coordinates\n",
    "\n",
    "    Args:\n",
    "        bbox_grid_cell_top_left (_type_): _description_\n",
    "    \"\"\"\n",
    "    single_image_data, bbox_grid_cell_top_left = elems\n",
    "    # tf.print(\"pixels shape : \", tf.shape(pixels))\n",
    "\n",
    "    # bbbox_grid_cell_top_left order x_min, x_max, y_min, y_max, x_center, y_center, width, height, class_values,top,left\n",
    "    # tf.print(\"bbox_grid_cell_top_left : \", bbox_grid_cell_top_left)\n",
    "\n",
    "    # step 1: create mesh grid indices based on width and height\n",
    "    # width_height = bbox_grid_cell_top_left[BBOX_WIDTH_IDX:BBOX_HEIGHT_IDX+1]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cell_top_left)\n",
    "    bbox_y_min, bbox_x_min, bbox_y_max, bbox_x_max = get_bbox_corners(\n",
    "        bbox_grid_cell_top_left)\n",
    "\n",
    "    patch_y, patch_x = tf.meshgrid(\n",
    "        tf.range(0, bbox_height), tf.range(0, bbox_width), indexing=\"ij\")\n",
    "    patch_grid = tf.stack([patch_y, patch_x], axis=-1)\n",
    "    # tf.print(\"----- patch_grid shape : \", tf.shape(patch_grid))\n",
    "\n",
    "    # create patch indices\n",
    "    y_min_x_min_slice = tf.gather(bbox_grid_cell_top_left, [2, 0])\n",
    "\n",
    "    # add dimensions to match patch_grid shape\n",
    "    y_min_x_min_slice = y_min_x_min_slice[tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    # add x_min, y_min to the patch grid\n",
    "    patch_indices = tf.add(y_min_x_min_slice, patch_grid)\n",
    "    # reshape patch_indices to make them flat\n",
    "    patch_indices = tf.reshape(patch_indices, shape=(-1, 2))\n",
    "    # cast to int32\n",
    "    patch_indices = tf.cast(patch_indices, dtype=tf.int32)\n",
    "\n",
    "    # read single_image_data data\n",
    "    # single_image_data is (28, 28, 1)\n",
    "    # begin must be 3D: [y, x, channel_start]\n",
    "    # size must be 3D: [h, w, num_channels]\n",
    "    patch_data = tf.slice(single_image_data,\n",
    "                          begin=[bbox_y_min, bbox_x_min, 0],\n",
    "                          size=[bbox_height, bbox_width, 1])\n",
    "\n",
    "    patch_data = tf.reshape(patch_data, shape=[-1])\n",
    "    # tf.print(\"patch_data : \", tf.shape(patch_data))\n",
    "\n",
    "    # create canvas indices\n",
    "    top_left_slice = tf.gather(bbox_grid_cell_top_left, [9, 10])\n",
    "    top_left_offset = top_left_slice[tf.newaxis, tf.newaxis, :]\n",
    "    canvas_indices = tf.add(top_left_offset, patch_grid)\n",
    "    # reshape patch_indices to make them flat\n",
    "    canvas_indices = tf.reshape(canvas_indices, shape=(-1, 2))\n",
    "    # cast to int32\n",
    "    canvas_indices = tf.cast(canvas_indices, dtype=tf.int32)\n",
    "\n",
    "    # tf.print(\"----- patch_indices shape : \", tf.shape(patch_indices))\n",
    "    return patch_data, canvas_indices\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def place_digit_on_canvas(pixels, class_values_with_bbox):\n",
    "    \"\"\"Function to extract the place the digits from pixels tensor on a 100x100 canvas\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28,1) - tensor of m 28x28 images\n",
    "        class_values_with_bbox (_type_): (m,9) - tensor of bounding box coordinates for m digits.\n",
    "    \"\"\"\n",
    "    pixels_dimensions = tf.shape(pixels)\n",
    "    batch_size = pixels_dimensions[0]\n",
    "\n",
    "    # step 1: Divide the 100x100 canvas with 3x3 cells and select random grid cells to place the digit in.\n",
    "    # generate grid size\n",
    "    grid_size = 3\n",
    "    final_grid_cells = get_canvas_grid_cells(batch_size, grid_size)\n",
    "    # tf.print(\"----- final_grid_cells shape : \", tf.shape(final_grid_cells))\n",
    "\n",
    "    # step 2: get the top/left pixels in each cell where we can place the bbox in the cell\n",
    "    bbox_grid_cells = tf.concat(\n",
    "        [class_values_with_bbox, final_grid_cells], axis=-1)\n",
    "\n",
    "    # tf.print(\"----- bbox_grid_cells.shape : \", tf.shape(bbox_grid_cells))\n",
    "    top_left = tf.map_fn(\n",
    "        map_bbox_to_grid_cells, bbox_grid_cells)\n",
    "    bbox_grid_cell_top_left = tf.concat(\n",
    "        [class_values_with_bbox, top_left], axis=-1)\n",
    "    # tf.print(\"----- bbox_grid_cell_top_left shape : \",tf.shape(bbox_grid_cell_top_left))\n",
    "\n",
    "    # step 3: Read image data from pixels using bbox\n",
    "    # step 3.1: create patch matching bounding box height and width\n",
    "    spec_patch_data = tf.RaggedTensorSpec(\n",
    "        shape=(None,), dtype=tf.float32, ragged_rank=0)\n",
    "    spec_canvas_indices = tf.RaggedTensorSpec(\n",
    "        shape=(None, 2), dtype=tf.int32, ragged_rank=0)\n",
    "\n",
    "    patch_data, canvas_indices = tf.map_fn(map_bbox_to_patch_indices, elems=(\n",
    "        pixels, bbox_grid_cell_top_left), fn_output_signature=(spec_patch_data, spec_canvas_indices))\n",
    "\n",
    "    all_updates = patch_data.flat_values\n",
    "    all_indices = canvas_indices.flat_values\n",
    "\n",
    "    # step 4: Update the canvas with the patch data.\n",
    "    canvas = tf.scatter_nd(\n",
    "        indices=all_indices,\n",
    "        updates=all_updates,\n",
    "        shape=[100, 100]\n",
    "    )\n",
    "\n",
    "    return canvas, bbox_grid_cell_top_left\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def translate_bbox_to_prediction(bbox_grid_cell_top_left):\n",
    "    \"\"\"creates a prediction object using the bbox grid and class value\n",
    "\n",
    "    Args:\n",
    "        prediction (_type_): tensor filled with zeroes of shape (MAX_OBJECTS, 15)\n",
    "        bbox_grid_cell_top_left (_type_): tensor of shape (num_digits, 11)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "        Prediction tensor value order \n",
    "        flag, x_center, y_center, width, height, one hot encoded class values (0 to 9)\n",
    "    \"\"\"\n",
    "    bbox_shape = tf.shape(bbox_grid_cell_top_left)\n",
    "    num_of_digits = bbox_shape[0]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cell_top_left)\n",
    "    bbox_class_val = bbox_grid_cell_top_left[..., BBOX_CLASS_IDX]\n",
    "    bbox_canvas_top = bbox_grid_cell_top_left[..., BBOX_CANVAS_TOP_IDX]\n",
    "    bbox_canvas_left = bbox_grid_cell_top_left[..., BBOX_CANVAS_LEFT_IDX]\n",
    "\n",
    "    # calculate the new canvas centers\n",
    "    canvas_x_center = (2 * bbox_canvas_left + bbox_width - 1)/2\n",
    "    canvas_y_center = (2 * bbox_canvas_top + bbox_height - 1)/2\n",
    "\n",
    "    # normalize the values\n",
    "    canvas_x_center = tf.cast(canvas_x_center / 100.0, dtype=tf.float32)\n",
    "    canvas_y_center = tf.cast(canvas_y_center / 100.0, dtype=tf.float32)\n",
    "\n",
    "    # one hot encoded class values\n",
    "    one_hot_encoded_class = tf.one_hot(indices=bbox_class_val, depth=10)\n",
    "\n",
    "    # flag for prediction\n",
    "    flag = tf.ones(shape=(num_of_digits, 1), dtype=tf.float32)\n",
    "\n",
    "    # reshape width & height\n",
    "    bbox_height = tf.reshape(bbox_height, shape=(-1, 1))\n",
    "    bbox_width = tf.reshape(bbox_width, shape=(-1, 1))\n",
    "\n",
    "    # cast to float32 and NORMALIZE\n",
    "    bbox_height = tf.cast(bbox_height, dtype=tf.float32) / 100.0\n",
    "    bbox_width = tf.cast(bbox_width, dtype=tf.float32) / 100.0\n",
    "\n",
    "    # reshape coordinates\n",
    "    canvas_x_center = tf.reshape(canvas_x_center, shape=(-1, 1))\n",
    "    canvas_y_center = tf.reshape(canvas_y_center, shape=(-1, 1))\n",
    "\n",
    "    # final updates tensor\n",
    "    updates = tf.concat([flag, canvas_x_center, canvas_y_center,\n",
    "                        bbox_width, bbox_height, one_hot_encoded_class], axis=-1)\n",
    "\n",
    "    # indices for scatter_nd\n",
    "    indices = tf.range(15, dtype=tf.int32)\n",
    "    indices = tf.repeat([indices], repeats=num_of_digits, axis=0)\n",
    "    indices = tf.reshape(indices, shape=(-1, 15, 1))\n",
    "    batch_indices = tf.range(num_of_digits, dtype=tf.int32)\n",
    "    batch_indices = batch_indices[:, tf.newaxis, tf.newaxis]\n",
    "    ones_tensor = tf.ones(shape=(num_of_digits, 15, 1), dtype=tf.int32)\n",
    "    stretched_batch_indices = tf.multiply(ones_tensor, batch_indices)\n",
    "\n",
    "    final_indices = tf.concat([stretched_batch_indices, indices], axis=-1)\n",
    "\n",
    "    prediction = tf.scatter_nd(\n",
    "        indices=final_indices, updates=updates, shape=(5, 15))\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def generate_training_example_tf(x, y, debug=True):\n",
    "    \"\"\"\n",
    "    Generate a training example by placing digits on a canvas and creating the corresponding prediction object.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Input digit image(s).\n",
    "        y (np.ndarray): Corresponding class label(s).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (canvas, prediction) where canvas is the composed image and prediction is the label array.\n",
    "    \"\"\"\n",
    "    pixels = tf.reshape(x, shape=(-1, 28, 28, 1))\n",
    "    class_values = tf.reshape(y, shape=(-1, 1))\n",
    "\n",
    "    # if debug:\n",
    "    # tf.print(\"----- pixels shape : \", tf.shape(pixels))\n",
    "    # tf.print(\"----- class_values shape : \", tf.shape(class_values))\n",
    "    # step 1: sample additional digits\n",
    "    if num_of_digits - 1 > 0:\n",
    "        additional_digits, additional_class_values = sample_base_digits(\n",
    "            num_of_digits - 1)\n",
    "        pixels = tf.concat([pixels, additional_digits], axis=0)\n",
    "        class_values = tf.concat(\n",
    "            [class_values, additional_class_values], axis=0)\n",
    "\n",
    "        # if debug:\n",
    "        # tf.print(\"----- pixels with additional_digits shape : \", tf.shape(pixels))\n",
    "        # tf.print(\"----- class_values with additional_class_values shape : \", tf.shape(class_values))\n",
    "\n",
    "    # step 2: augment digits\n",
    "    augmented_pixels = augment_digits(pixels)\n",
    "    cleaned_augmented_pixels = tf.nn.relu(augmented_pixels)\n",
    "\n",
    "    # step 3: calculate bounding box\n",
    "    class_values_with_bbox = calculate_tight_bbox(\n",
    "        cleaned_augmented_pixels, class_values)\n",
    "\n",
    "    # step 4: place digit on canvas\n",
    "    # Returns canvas with digits and bbox grid with new top left\n",
    "    canvas, bbox_grid_cell_top_left = place_digit_on_canvas(\n",
    "        augmented_pixels, class_values_with_bbox)\n",
    "\n",
    "    # step 5: translate bbox to prediction object\n",
    "    prediction = translate_bbox_to_prediction(bbox_grid_cell_top_left)\n",
    "\n",
    "    return canvas, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d6ba9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "## temporary just selecting first 32 records to test quickly\n",
    "X_tensor = tf.convert_to_tensor(x_train[:32], dtype=tf.float32)\n",
    "y_tensor = tf.convert_to_tensor(y_train[:32], dtype=tf.float32)\n",
    "batch_size = 32\n",
    "\n",
    "# print(tf.shape(X_tensor))\n",
    "# print(tf.shape(y_tensor))\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "# Use the wrapper inside the map\n",
    "tf_processed_dataset = raw_dataset.map(generate_training_example_tf).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f5710",
   "metadata": {},
   "source": [
    "### Bench Marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9b6f4af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 0 ----\n",
      "Execution time for epoch 0 : 0.4750390039989725\n",
      "Total Execution time: 0.475164745002985\n"
     ]
    }
   ],
   "source": [
    "benchmark(tf_processed_dataset.prefetch(tf.data.AUTOTUNE), num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "11fd3066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched_canvases shape: (32, 100, 100)\n",
      "predictions shape  tf.Tensor([32  5 15], shape=(3,), dtype=int32)\n",
      "Canvas shape: (100, 100)\n",
      "prediction shape : (5, 15)\n",
      "flag, x_center, y_center, width, height 100.0 36.5 66.5 25.0 23.0\n",
      "flag, x_center, y_center, width, height 100.0 72.5 73.0 24.0 25.0\n",
      "flag, x_center, y_center, width, height 100.0 65.5 38.5 22.0 26.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "# Get one batch\n",
    "# Your dataset is batched, so .take(1) gets one full batch\n",
    "for batch in tf_processed_dataset.take(1):\n",
    "    # Your map function returns (canvas, bboxes, labels)\n",
    "    # So, 'batch' is a tuple of (batched_canvases, batched_bboxes, batched_labels)\n",
    "    batched_canvases,predictions = batch\n",
    "    print(f\"batched_canvases shape: {batched_canvases.shape}\")\n",
    "    print(f\"predictions shape \", tf.shape(predictions))\n",
    "    # Get the very first canvas from the batch (shape 100x100)\n",
    "    # We use .numpy() to convert it from a EagerTensor to a NumPy array for plotting\n",
    "    canvas_to_show = batched_canvases[0].numpy()\n",
    "    print(f\"Canvas shape: {canvas_to_show.shape}\")\n",
    "    \n",
    "    # Plot it\n",
    "    # --- Create a figure and axis ---\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "\n",
    "    \n",
    "    prediction = predictions[0]\n",
    "    print(f\"prediction shape : {prediction.shape}\")\n",
    "    ## get the 3 predictions\n",
    "    for i in range(3):\n",
    "        bbox = (prediction[i]).numpy() * 100\n",
    "        \n",
    "        # flag, x_center, y_center, width, height,\n",
    "        flag = bbox[0]\n",
    "        x_center = bbox[1]\n",
    "        y_center = bbox[2]\n",
    "        width = bbox[3]\n",
    "        height = bbox[4]\n",
    "        \n",
    "        x_min = x_center - (width / 2)\n",
    "        y_min = y_center - (width / 2)\n",
    "        \n",
    "        print(\"flag, x_center, y_center, width, height\",flag, x_min, y_min, width, height,)\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min),\n",
    "            width,\n",
    "            height,\n",
    "            linewidth=2,\n",
    "            edgecolor='r',\n",
    "            facecolor='none'\n",
    "        )\n",
    "        \n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(canvas_to_show, cmap='gray')\n",
    "    \n",
    "    \n",
    "    plt.title(\"Generated 100x100 Canvas (Test 1)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220539b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
