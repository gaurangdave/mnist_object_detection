{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364c7e70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05508ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 11:31:09.494749: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762543869.587370  807841 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762543869.614832  807841 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762543869.815851  807841 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762543869.815922  807841 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762543869.815924  807841 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762543869.815926  807841 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-07 11:31:09.839392: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96daf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d8211",
   "metadata": {},
   "source": [
    "## Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42f27dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"..\",\"data\")\n",
    "models_dir = Path(\"..\",\"models\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c142098",
   "metadata": {},
   "source": [
    "## Defining Bench Mark Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4773b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        print(f\"---- Epoch {epoch_num} ----\")\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        print(f\"Execution time for epoch {epoch_num} : {time.perf_counter() - start_time}\")\n",
    "    print(\"Total Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538acc3",
   "metadata": {},
   "source": [
    "* So single epoch took 2857.236867081 seconds so ~47 mins mamjority of that time went to data generation since we spent only 0.01s perbatch for \"training\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb18704",
   "metadata": {},
   "source": [
    "## Data Generation With Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5b91c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762543875.163217  807841 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6053 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:2e:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "ALL_MNIST_DATA_PIXELS_TF = tf.constant(x_train, dtype=tf.float32)\n",
    "ALL_MNIST_DATA_CLASSES_TF = tf.constant(y_train, dtype=tf.float32)\n",
    "\n",
    "# number of digits to overlay on canvas\n",
    "num_of_digits = tf.constant(3, dtype=tf.int32)\n",
    "\n",
    "# max digits to define the shape of prediction output\n",
    "MAX_DIGITS = tf.constant(5, dtype=tf.int32)\n",
    "\n",
    "\n",
    "# Sample Base Digits\n",
    "@tf.function\n",
    "def get_sample_indices(dataset, size=5):\n",
    "    dataset_len = tf.shape(dataset)[0] - 1\n",
    "    random_indices = tf.random.uniform(\n",
    "        shape=[size], minval=0, maxval=dataset_len, dtype=tf.int32)\n",
    "    return random_indices\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def sample_base_digits(num_of_digits):\n",
    "    \"\"\"\n",
    "    Sample a specified number of digit images and their class labels from the master MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        num_of_digits (int): Number of digit samples to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sample_pixels, sample_values)\n",
    "            sample_pixels (np.ndarray): Array of digit images with shape (num_of_digits, 28, 28, 1).\n",
    "            sample_values (np.ndarray): Array of class labels with shape (num_of_digits, 1).\n",
    "    \"\"\"\n",
    "    sample_indices = get_sample_indices(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, size=num_of_digits)\n",
    "    sample_pixels = tf.gather(ALL_MNIST_DATA_PIXELS_TF,\n",
    "                              indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_pixels = tf.reshape(sample_pixels, shape=(num_of_digits, 28, 28, 1))\n",
    "\n",
    "    sample_values = tf.gather(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_values = tf.reshape(sample_values, shape=(num_of_digits, 1))\n",
    "    return sample_pixels, sample_values\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "def augment_digits(digits):\n",
    "    \"\"\"\n",
    "    Apply random augmentations (translation, zoom, rotation) to a batch of digit images.\n",
    "\n",
    "    Args:\n",
    "        digits (np.ndarray): Array of digit images to augment.\n",
    "        debug (bool, optional): If True, displays before/after images for each digit. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Augmented digit images as a numpy array.\n",
    "    \"\"\"\n",
    "    # step 2: apply random augmentation\n",
    "    augmented_tensor_digits = augmentation(digits)\n",
    "    return augmented_tensor_digits\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_min_max(active_rows, active_cols):\n",
    "    # find x_min, x_max\n",
    "    # step 1 find indices for active x\n",
    "    non_zero_active_cols = tf.where(active_cols != 0)\n",
    "    # get the first and last active x as x_min and x_max\n",
    "    x_min = tf.cast(tf.reduce_min(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "    x_max = tf.cast(tf.reduce_max(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "\n",
    "    ##\n",
    "    non_zero_active_rows = tf.where(active_rows != 0)\n",
    "    y_min = tf.cast(tf.reduce_min(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "    y_max = tf.cast(tf.reduce_max(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_blank_canvas(shape=(100, 100, 1)):\n",
    "    \"\"\"\n",
    "    Create a blank canvas for placing digit images.\n",
    "\n",
    "    Args:\n",
    "        shape (tuple, optional): Shape of the canvas. Defaults to (100, 100, 1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Blank canvas array.\n",
    "    \"\"\"\n",
    "    canvas = tf.zeros(shape=(100, 100, 1), dtype=tf.float32)\n",
    "    return canvas\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_prediction_object():\n",
    "    \"\"\"\n",
    "    Create an empty prediction object for storing digit detection results.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Prediction array of shape (MAX_DIGITS, 15).\n",
    "    \"\"\"\n",
    "    prediction = tf.zeros(shape=(MAX_DIGITS, 15), dtype=tf.float32)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def calculate_tight_bbox(pixels, class_values, padding=1):\n",
    "    \"\"\"Creates bounding box for the digits in pixel tensor and returns a concatenated tensor with bounding box and class\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28,1) tensor of pixels\n",
    "        class_values (_type_): (m,1) tensor of class values\n",
    "    \"\"\"\n",
    "    # step 1: calculate active rows and cols\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the col\n",
    "    active_rows = tf.reduce_sum(pixels, axis=[2, 3])\n",
    "    # tf.print(\"----- active_rows shape : \", tf.shape(active_rows))\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the row\n",
    "    active_cols = tf.reduce_sum(pixels, axis=[1, 3])\n",
    "    # tf.print(\"----- active_cols shape : \", tf.shape(active_cols))\n",
    "\n",
    "    # step 2: find non zero coordinates\n",
    "    # create boolean mask for active rows\n",
    "    non_zero_row_mask = active_rows != 0\n",
    "\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_row_mask shape : \", tf.shape(non_zero_row_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_row_coordinates = tf.where(non_zero_row_mask)\n",
    "    # tf.print(\"----- non_zero_row_coordinates shape : \", tf.shape(non_zero_row_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_row_coordinates[:, 1]\n",
    "    segment_ids = non_zero_row_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the rows it gives us y-coordinates of the image\n",
    "    y_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    y_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "\n",
    "    # create boolean mask for active cols\n",
    "    non_zero_col_mask = active_cols != 0\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_col_mask shape : \", tf.shape(non_zero_col_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_col_coordinates = tf.where(non_zero_col_mask)\n",
    "    # tf.print(\"----- non_zero_col_coordinates shape : \", tf.shape(non_zero_col_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_col_coordinates[:, 1]\n",
    "    segment_ids = non_zero_col_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the cols it gives us x-coordinates of the image\n",
    "    x_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    x_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "\n",
    "    # step 3: add padding to pixels\n",
    "    # calculate padding condition for x_min\n",
    "    x_min_padding_cond = x_min > 0\n",
    "    padded_x_min = x_min - padding\n",
    "    x_min = tf.where(x_min_padding_cond, padded_x_min, x_min)\n",
    "\n",
    "    # calculate padding condition for x_max\n",
    "    x_max_padding_cond = x_max < 27\n",
    "    padded_x_max = x_max + padding\n",
    "    x_max = tf.where(x_max_padding_cond, padded_x_max, x_max)\n",
    "\n",
    "    # calculate padding condition for y_min\n",
    "    y_min_padding_cond = y_min > 0\n",
    "    padded_y_min = y_min - padding\n",
    "    y_min = tf.where(y_min_padding_cond, padded_y_min, y_min)\n",
    "\n",
    "    # calculate padding condition for y_max\n",
    "    y_max_padding_cond = y_max < 27\n",
    "    padded_y_max = y_max + padding\n",
    "    y_max = tf.where(y_max_padding_cond, padded_y_max, y_max)\n",
    "\n",
    "    # step 4: calculate x_center & y_center\n",
    "    x_center = tf.round((x_min + x_max) / 2)\n",
    "    y_center = tf.round((y_min + y_max) / 2)\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "\n",
    "    # step 5: calculate width and height\n",
    "    width = x_max - x_min + 1\n",
    "    height = y_max - y_min + 1\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "\n",
    "    # reshape all the values to match class_values\n",
    "    x_min = tf.reshape(x_min, shape=(-1, 1))\n",
    "    x_max = tf.reshape(x_max, shape=(-1, 1))\n",
    "    y_min = tf.reshape(y_min, shape=(-1, 1))\n",
    "    y_max = tf.reshape(y_max, shape=(-1, 1))\n",
    "    x_center = tf.reshape(x_center, shape=(-1, 1))\n",
    "    y_center = tf.reshape(y_center, shape=(-1, 1))\n",
    "    width = tf.reshape(width, shape=(-1, 1))\n",
    "    height = tf.reshape(height, shape=(-1, 1))\n",
    "\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- y_center shape : \", tf.shape(y_center))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- height shape : \", tf.shape(height))\n",
    "\n",
    "    # casting all values to same dtype\n",
    "    x_min = tf.cast(x_min, dtype=tf.int32)\n",
    "    x_max = tf.cast(x_max, dtype=tf.int32)\n",
    "    y_min = tf.cast(y_min, dtype=tf.int32)\n",
    "    y_max = tf.cast(y_max, dtype=tf.int32)\n",
    "    x_center = tf.cast(x_center, dtype=tf.int32)\n",
    "    y_center = tf.cast(y_center, dtype=tf.int32)\n",
    "    width = tf.cast(width, dtype=tf.int32)\n",
    "    height = tf.cast(height, dtype=tf.int32)\n",
    "    class_values = tf.cast(class_values, dtype=tf.int32)\n",
    "\n",
    "    bounding_box = tf.concat(\n",
    "        [x_min, x_max, y_min, y_max, x_center, y_center, width, height, class_values], axis=-1)\n",
    "    # tf.print(\"----- bounding_box shape : \", tf.shape(bounding_box))\n",
    "    return bounding_box\n",
    "\n",
    "\n",
    "# BBOX Indices\n",
    "BBOX_XMIN_IDX = 0\n",
    "BBOX_XMAX_IDX = 1\n",
    "BBOX_YMIN_IDX = 2\n",
    "BBOX_YMAX_IDX = 3\n",
    "BBOX_XCENTER_IDX = 4\n",
    "BBOX_YCENTER_IDX = 5  # (This might be the same as CLASS_IDX)\n",
    "BBOX_WIDTH_IDX = 6\n",
    "BBOX_HEIGHT_IDX = 7\n",
    "BBOX_CLASS_IDX = 8\n",
    "BBOX_CANVAS_TOP_IDX = 9\n",
    "BBOX_CANVAS_LEFT_IDX = 10\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_corners(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    y_min = tf.cast(bbox_info[..., BBOX_YMIN_IDX], dtype=tf.int32)\n",
    "    x_min = tf.cast(bbox_info[..., BBOX_XMIN_IDX], dtype=tf.int32)\n",
    "    y_max = tf.cast(bbox_info[..., BBOX_YMAX_IDX], dtype=tf.int32)\n",
    "    x_max = tf.cast(bbox_info[..., BBOX_XMAX_IDX], dtype=tf.int32)\n",
    "    return y_min, x_min, y_max, x_max\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_dimensions(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    height = tf.cast(bbox_info[..., BBOX_HEIGHT_IDX], dtype=tf.int32)\n",
    "    width = tf.cast(bbox_info[..., BBOX_WIDTH_IDX], dtype=tf.int32)\n",
    "    return height, width\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_center(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    y_center = tf.cast(bbox_info[..., BBOX_YCENTER_IDX], dtype=tf.int32)\n",
    "    x_center = tf.cast(bbox_info[..., BBOX_XCENTER_IDX], dtype=tf.int32)\n",
    "    return y_center, x_center\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_canvas_placement(bbox_info):\n",
    "    \"\"\"Extracts the final (top, left) coords for the canvas.\"\"\"\n",
    "    # Assuming you concatenated these at indices 9 and 10\n",
    "    canvas_top = tf.cast(bbox_info[..., BBOX_CANVAS_TOP_IDX], dtype=tf.int32)\n",
    "    canvas_left = tf.cast(bbox_info[..., BBOX_CANVAS_LEFT_IDX], dtype=tf.int32)\n",
    "    return canvas_top, canvas_left\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def augment_digits(pixels):\n",
    "    augmented_pixels = augmentation(pixels)\n",
    "    return augmented_pixels\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def generate_grid(grid_size):\n",
    "    coorinate_range = tf.range(grid_size, dtype=tf.float32)\n",
    "    grid_X, grid_Y = tf.meshgrid(coorinate_range, coorinate_range)\n",
    "    coordinate_grid = tf.stack(values=[grid_X, grid_Y], axis=2)\n",
    "    # normalized_grid = (coordinate_grid + 0.5) / grid_size\n",
    "    return coordinate_grid\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def map_bbox_to_grid_cells(bbox_grid_cells):\n",
    "    \"\"\"Helper function maps bbox x_min,y_min to top,left inside the cell\n",
    "\n",
    "    Args:\n",
    "        bbox_grid_cells (_type_): tensor of shape (13)\n",
    "\n",
    "    Returns:\n",
    "        _type_: tensor\n",
    "    \"\"\"\n",
    "    # x_min,x_max,y_min,y_max = bbox_grid_cells[0:4]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cells)\n",
    "    # grid_cell_x, grid_cell_y,grid_width,grid_height = bbox_grid_cells[9:]\n",
    "    # step 1: generate random top/left pair\n",
    "    grid_cell_x = bbox_grid_cells[9]\n",
    "    grid_cell_y = bbox_grid_cells[10]\n",
    "    grid_cell_width_limit = bbox_grid_cells[11]\n",
    "    grid_cell_height_limit = bbox_grid_cells[12]\n",
    "\n",
    "    max_left = grid_cell_width_limit - bbox_width\n",
    "    max_top = grid_cell_height_limit - bbox_height\n",
    "\n",
    "    left = tf.random.uniform(shape=[], minval=grid_cell_x,\n",
    "                             maxval=max_left+1, dtype=tf.int32)\n",
    "    top = tf.random.uniform(shape=[], minval=grid_cell_y,\n",
    "                            maxval=max_top+1, dtype=tf.int32)\n",
    "    return tf.stack([top, left], axis=-1)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_canvas_grid_cells(batch_size, grid_size):\n",
    "    \"\"\"Helper function that creates a grid of shape (grid_size,grid_size), scales it to 100x100 canvas and returns random grid cells and its dimensions\n",
    "\n",
    "    Args:\n",
    "        batch_size (_type_): _description_\n",
    "        grid_size (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    grid = generate_grid(grid_size=grid_size)\n",
    "    # reshape the grid so that we can select from the pool of 9 coordinates\n",
    "    grid = tf.reshape(grid, shape=(-1, 2))\n",
    "    # shuffle grid indices for random selection - this would create grid coordinates in random order\n",
    "    # which means first row can have coordinates for other rows as well.\n",
    "    shuffled_grid = tf.random.shuffle(value=grid)\n",
    "    # create random grid cells\n",
    "    random_grid_cells = shuffled_grid[:batch_size, :]\n",
    "    # tf.print(\"----- random_grid_cells shape : \", tf.shape(random_grid_cells))\n",
    "    grid_cell_size = tf.floor(100 / grid_size)\n",
    "    # scale grid cell coordinates\n",
    "    scalled_random_grid_cells = random_grid_cells * grid_cell_size\n",
    "    # tf.print(\"----- scalled_random_grid_cells shape : \", tf.shape(scalled_random_grid_cells))\n",
    "    # calculate the width and height limit of grid cells\n",
    "    grid_cell_dimensions = scalled_random_grid_cells + grid_cell_size\n",
    "    # tf.print(\"----- grid_cell_dimensions shape : \", tf.shape(grid_cell_dimensions))\n",
    "    # concatenate the info\n",
    "    final_grid_cells = tf.concat(\n",
    "        [scalled_random_grid_cells, grid_cell_dimensions], axis=-1)\n",
    "    final_grid_cells = tf.cast(final_grid_cells, dtype=tf.int32)\n",
    "    return final_grid_cells\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def map_bbox_to_patch_indices(elems):\n",
    "    \"\"\"Helper function to map bounding boxes to patches with coordinates\n",
    "\n",
    "    Args:\n",
    "        bbox_grid_cell_top_left (_type_): _description_\n",
    "    \"\"\"\n",
    "    single_image_data, bbox_grid_cell_top_left = elems\n",
    "    # tf.print(\"pixels shape : \", tf.shape(pixels))\n",
    "\n",
    "    # bbbox_grid_cell_top_left order x_min, x_max, y_min, y_max, x_center, y_center, width, height, class_values,top,left\n",
    "    # tf.print(\"bbox_grid_cell_top_left : \", bbox_grid_cell_top_left)\n",
    "\n",
    "    # step 1: create mesh grid indices based on width and height\n",
    "    # width_height = bbox_grid_cell_top_left[BBOX_WIDTH_IDX:BBOX_HEIGHT_IDX+1]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cell_top_left)\n",
    "    bbox_y_min, bbox_x_min, bbox_y_max, bbox_x_max = get_bbox_corners(\n",
    "        bbox_grid_cell_top_left)\n",
    "\n",
    "    patch_y, patch_x = tf.meshgrid(\n",
    "        tf.range(0, bbox_height), tf.range(0, bbox_width), indexing=\"ij\")\n",
    "    patch_grid = tf.stack([patch_y, patch_x], axis=-1)\n",
    "    # tf.print(\"----- patch_grid shape : \", tf.shape(patch_grid))\n",
    "\n",
    "    # create patch indices\n",
    "    y_min_x_min_slice = tf.gather(bbox_grid_cell_top_left, [2, 0])\n",
    "\n",
    "    # add dimensions to match patch_grid shape\n",
    "    y_min_x_min_slice = y_min_x_min_slice[tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    # add x_min, y_min to the patch grid\n",
    "    patch_indices = tf.add(y_min_x_min_slice, patch_grid)\n",
    "    # reshape patch_indices to make them flat\n",
    "    patch_indices = tf.reshape(patch_indices, shape=(-1, 2))\n",
    "    # cast to int32\n",
    "    patch_indices = tf.cast(patch_indices, dtype=tf.int32)\n",
    "\n",
    "    # read single_image_data data\n",
    "    # single_image_data is (28, 28, 1)\n",
    "    # begin must be 3D: [y, x, channel_start]\n",
    "    # size must be 3D: [h, w, num_channels]\n",
    "    patch_data = tf.slice(single_image_data,\n",
    "                          begin=[bbox_y_min, bbox_x_min, 0],\n",
    "                          size=[bbox_height, bbox_width, 1])\n",
    "\n",
    "    patch_data = tf.reshape(patch_data, shape=[-1])\n",
    "    # tf.print(\"patch_data : \", tf.shape(patch_data))\n",
    "\n",
    "    # create canvas indices\n",
    "    top_left_slice = tf.gather(bbox_grid_cell_top_left, [9, 10])\n",
    "    top_left_offset = top_left_slice[tf.newaxis, tf.newaxis, :]\n",
    "    canvas_indices = tf.add(top_left_offset, patch_grid)\n",
    "    # reshape patch_indices to make them flat\n",
    "    canvas_indices = tf.reshape(canvas_indices, shape=(-1, 2))\n",
    "    # cast to int32\n",
    "    canvas_indices = tf.cast(canvas_indices, dtype=tf.int32)\n",
    "\n",
    "    # tf.print(\"----- patch_indices shape : \", tf.shape(patch_indices))\n",
    "    return patch_data, canvas_indices\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def place_digit_on_canvas(pixels, class_values_with_bbox):\n",
    "    \"\"\"Function to extract the place the digits from pixels tensor on a 100x100 canvas\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28,1) - tensor of m 28x28 images\n",
    "        class_values_with_bbox (_type_): (m,9) - tensor of bounding box coordinates for m digits.\n",
    "    \"\"\"\n",
    "    pixels_dimensions = tf.shape(pixels)\n",
    "    batch_size = pixels_dimensions[0]\n",
    "\n",
    "    # step 1: Divide the 100x100 canvas with 3x3 cells and select random grid cells to place the digit in.\n",
    "    # generate grid size\n",
    "    grid_size = 3\n",
    "    final_grid_cells = get_canvas_grid_cells(batch_size, grid_size)\n",
    "    # tf.print(\"----- final_grid_cells shape : \", tf.shape(final_grid_cells))\n",
    "\n",
    "    # step 2: get the top/left pixels in each cell where we can place the bbox in the cell\n",
    "    bbox_grid_cells = tf.concat(\n",
    "        [class_values_with_bbox, final_grid_cells], axis=-1)\n",
    "\n",
    "    # tf.print(\"----- bbox_grid_cells.shape : \", tf.shape(bbox_grid_cells))\n",
    "    top_left = tf.map_fn(\n",
    "        map_bbox_to_grid_cells, bbox_grid_cells)\n",
    "    bbox_grid_cell_top_left = tf.concat(\n",
    "        [class_values_with_bbox, top_left], axis=-1)\n",
    "    # tf.print(\"----- bbox_grid_cell_top_left shape : \",tf.shape(bbox_grid_cell_top_left))\n",
    "\n",
    "    # step 3: Read image data from pixels using bbox\n",
    "    # step 3.1: create patch matching bounding box height and width\n",
    "    spec_patch_data = tf.RaggedTensorSpec(\n",
    "        shape=(None,), dtype=tf.float32, ragged_rank=0)\n",
    "    spec_canvas_indices = tf.RaggedTensorSpec(\n",
    "        shape=(None, 2), dtype=tf.int32, ragged_rank=0)\n",
    "\n",
    "    patch_data, canvas_indices = tf.map_fn(map_bbox_to_patch_indices, elems=(\n",
    "        pixels, bbox_grid_cell_top_left), fn_output_signature=(spec_patch_data, spec_canvas_indices))\n",
    "\n",
    "    all_updates = patch_data.flat_values\n",
    "    all_indices = canvas_indices.flat_values\n",
    "\n",
    "    # step 4: Update the canvas with the patch data.\n",
    "    canvas = tf.scatter_nd(\n",
    "        indices=all_indices,\n",
    "        updates=all_updates,\n",
    "        shape=[100, 100]\n",
    "    )\n",
    "\n",
    "    return canvas, bbox_grid_cell_top_left\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def translate_bbox_to_prediction(bbox_grid_cell_top_left):\n",
    "    \"\"\"creates a prediction object using the bbox grid and class value\n",
    "\n",
    "    Args:\n",
    "        prediction (_type_): tensor filled with zeroes of shape (MAX_OBJECTS, 15)\n",
    "        bbox_grid_cell_top_left (_type_): tensor of shape (num_digits, 11)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "        Prediction tensor value order \n",
    "        flag, x_center, y_center, width, height, one hot encoded class values (0 to 9)\n",
    "    \"\"\"\n",
    "    bbox_shape = tf.shape(bbox_grid_cell_top_left)\n",
    "    num_of_digits = bbox_shape[0]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cell_top_left)\n",
    "    bbox_class_val = bbox_grid_cell_top_left[..., BBOX_CLASS_IDX]\n",
    "    bbox_canvas_top = bbox_grid_cell_top_left[..., BBOX_CANVAS_TOP_IDX]\n",
    "    bbox_canvas_left = bbox_grid_cell_top_left[..., BBOX_CANVAS_LEFT_IDX]\n",
    "\n",
    "    # calculate the new canvas centers\n",
    "    canvas_x_center = (2 * bbox_canvas_left + bbox_width - 1)/2\n",
    "    canvas_y_center = (2 * bbox_canvas_top + bbox_height - 1)/2\n",
    "\n",
    "    # normalize the values\n",
    "    canvas_x_center = tf.cast(canvas_x_center / 100.0, dtype=tf.float32)\n",
    "    canvas_y_center = tf.cast(canvas_y_center / 100.0, dtype=tf.float32)\n",
    "\n",
    "    # one hot encoded class values\n",
    "    one_hot_encoded_class = tf.one_hot(indices=bbox_class_val, depth=10)\n",
    "\n",
    "    # flag for prediction\n",
    "    flag = tf.ones(shape=(num_of_digits, 1), dtype=tf.float32)\n",
    "\n",
    "    # reshape width & height\n",
    "    bbox_height = tf.reshape(bbox_height, shape=(-1, 1))\n",
    "    bbox_width = tf.reshape(bbox_width, shape=(-1, 1))\n",
    "\n",
    "    # cast to float32 and NORMALIZE\n",
    "    bbox_height = tf.cast(bbox_height, dtype=tf.float32) / 100.0\n",
    "    bbox_width = tf.cast(bbox_width, dtype=tf.float32) / 100.0\n",
    "\n",
    "    # reshape coordinates\n",
    "    canvas_x_center = tf.reshape(canvas_x_center, shape=(-1, 1))\n",
    "    canvas_y_center = tf.reshape(canvas_y_center, shape=(-1, 1))\n",
    "\n",
    "    # final updates tensor\n",
    "    updates = tf.concat([flag, canvas_x_center, canvas_y_center,\n",
    "                        bbox_width, bbox_height, one_hot_encoded_class], axis=-1)\n",
    "\n",
    "    # indices for scatter_nd\n",
    "    indices = tf.range(15, dtype=tf.int32)\n",
    "    indices = tf.repeat([indices], repeats=num_of_digits, axis=0)\n",
    "    indices = tf.reshape(indices, shape=(-1, 15, 1))\n",
    "    batch_indices = tf.range(num_of_digits, dtype=tf.int32)\n",
    "    batch_indices = batch_indices[:, tf.newaxis, tf.newaxis]\n",
    "    ones_tensor = tf.ones(shape=(num_of_digits, 15, 1), dtype=tf.int32)\n",
    "    stretched_batch_indices = tf.multiply(ones_tensor, batch_indices)\n",
    "\n",
    "    final_indices = tf.concat([stretched_batch_indices, indices], axis=-1)\n",
    "\n",
    "    prediction = tf.scatter_nd(\n",
    "        indices=final_indices, updates=updates, shape=(5, 15))\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def generate_training_example_tf(x, y, debug=True):\n",
    "    \"\"\"\n",
    "    Generate a training example by placing digits on a canvas and creating the corresponding prediction object.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Input digit image(s).\n",
    "        y (np.ndarray): Corresponding class label(s).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (canvas, prediction) where canvas is the composed image and prediction is the label array.\n",
    "    \"\"\"\n",
    "    pixels = tf.reshape(x, shape=(-1, 28, 28, 1))\n",
    "    class_values = tf.reshape(y, shape=(-1, 1))\n",
    "\n",
    "    # if debug:\n",
    "    # tf.print(\"----- pixels shape : \", tf.shape(pixels))\n",
    "    # tf.print(\"----- class_values shape : \", tf.shape(class_values))\n",
    "    # step 1: sample additional digits\n",
    "    if num_of_digits - 1 > 0:\n",
    "        additional_digits, additional_class_values = sample_base_digits(\n",
    "            num_of_digits - 1)\n",
    "        pixels = tf.concat([pixels, additional_digits], axis=0)\n",
    "        class_values = tf.concat(\n",
    "            [class_values, additional_class_values], axis=0)\n",
    "\n",
    "        # if debug:\n",
    "        # tf.print(\"----- pixels with additional_digits shape : \", tf.shape(pixels))\n",
    "        # tf.print(\"----- class_values with additional_class_values shape : \", tf.shape(class_values))\n",
    "\n",
    "    # step 2: augment digits\n",
    "    augmented_pixels = augment_digits(pixels)\n",
    "    cleaned_augmented_pixels = tf.nn.relu(augmented_pixels)\n",
    "\n",
    "    # step 3: calculate bounding box\n",
    "    class_values_with_bbox = calculate_tight_bbox(\n",
    "        cleaned_augmented_pixels, class_values)\n",
    "\n",
    "    # step 4: place digit on canvas\n",
    "    # Returns canvas with digits and bbox grid with new top left\n",
    "    canvas, bbox_grid_cell_top_left = place_digit_on_canvas(\n",
    "        augmented_pixels, class_values_with_bbox)\n",
    "\n",
    "    # step 5: translate bbox to prediction object\n",
    "    prediction = translate_bbox_to_prediction(bbox_grid_cell_top_left)\n",
    "\n",
    "    return canvas, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6ba9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "## temporary just selecting first 32 records to test quickly\n",
    "X_tensor = tf.convert_to_tensor(x_train[:32], dtype=tf.float32)\n",
    "y_tensor = tf.convert_to_tensor(y_train[:32], dtype=tf.float32)\n",
    "batch_size = 32\n",
    "\n",
    "# print(tf.shape(X_tensor))\n",
    "# print(tf.shape(y_tensor))\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "# Use the wrapper inside the map\n",
    "tf_processed_dataset = raw_dataset.map(generate_training_example_tf).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f5710",
   "metadata": {},
   "source": [
    "### Bench Marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b6f4af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 0 ----\n",
      "Execution time for epoch 0 : 0.5020597008988261\n",
      "Total Execution time: 0.5021998198935762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 11:31:17.412618: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "benchmark(tf_processed_dataset.prefetch(tf.data.AUTOTUNE), num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11fd3066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched_canvases shape: (32, 100, 100)\n",
      "predictions shape  tf.Tensor([32  5 15], shape=(3,), dtype=int32)\n",
      "Canvas shape: (100, 100)\n",
      "prediction shape : (5, 15)\n",
      "flag, x_center, y_center, width, height 100.0 69.5 67.0 28.0 25.0\n",
      "flag, x_center, y_center, width, height 100.0 65.5 1.0 21.0 18.0\n",
      "flag, x_center, y_center, width, height 100.0 38.5 34.0 25.0 20.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 11:31:17.968923: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "# Get one batch\n",
    "# Your dataset is batched, so .take(1) gets one full batch\n",
    "for batch in tf_processed_dataset.take(1):\n",
    "    # Your map function returns (canvas, bboxes, labels)\n",
    "    # So, 'batch' is a tuple of (batched_canvases, batched_bboxes, batched_labels)\n",
    "    batched_canvases,predictions = batch\n",
    "    print(f\"batched_canvases shape: {batched_canvases.shape}\")\n",
    "    print(f\"predictions shape \", tf.shape(predictions))\n",
    "    # Get the very first canvas from the batch (shape 100x100)\n",
    "    # We use .numpy() to convert it from a EagerTensor to a NumPy array for plotting\n",
    "    canvas_to_show = batched_canvases[0].numpy()\n",
    "    print(f\"Canvas shape: {canvas_to_show.shape}\")\n",
    "    \n",
    "    # Plot it\n",
    "    # --- Create a figure and axis ---\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "\n",
    "    \n",
    "    prediction = predictions[0]\n",
    "    print(f\"prediction shape : {prediction.shape}\")\n",
    "    ## get the 3 predictions\n",
    "    for i in range(3):\n",
    "        bbox = (prediction[i]).numpy() * 100\n",
    "        \n",
    "        # flag, x_center, y_center, width, height,\n",
    "        flag = bbox[0]\n",
    "        x_center = bbox[1]\n",
    "        y_center = bbox[2]\n",
    "        width = bbox[3]\n",
    "        height = bbox[4]\n",
    "        \n",
    "        x_min = x_center - (width / 2)\n",
    "        y_min = y_center - (width / 2)\n",
    "        \n",
    "        print(\"flag, x_center, y_center, width, height\",flag, x_min, y_min, width, height,)\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min),\n",
    "            width,\n",
    "            height,\n",
    "            linewidth=2,\n",
    "            edgecolor='r',\n",
    "            facecolor='none'\n",
    "        )\n",
    "        \n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(canvas_to_show, cmap='gray')\n",
    "    \n",
    "    \n",
    "    plt.title(\"Generated 100x100 Canvas (Test 1)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0220539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched_canvases shape: (32, 100, 100)\n",
      "predictions shape  tf.Tensor([32  5 15], shape=(3,), dtype=int32)\n",
      "predictions [1.    0.155 0.195 0.28  0.22  0.    0.    0.    0.    0.    1.    0.\n",
      " 0.    0.    0.   ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 11:31:59.027207: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for batch in tf_processed_dataset.take(1):\n",
    "    # Your map function returns (canvas, bboxes, labels)\n",
    "    # So, 'batch' is a tuple of (batched_canvases, batched_bboxes, batched_labels)\n",
    "    batched_canvases,predictions = batch\n",
    "    print(f\"batched_canvases shape: {batched_canvases.shape}\")\n",
    "    print(f\"predictions shape \", tf.shape(predictions))\n",
    "    print(f\"predictions {predictions[0,0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909bad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
