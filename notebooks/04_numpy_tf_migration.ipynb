{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364c7e70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05508ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 10:34:32.019643: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761327272.038704   34505 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761327272.043919   34505 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1761327272.066972   34505 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761327272.067012   34505 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761327272.067014   34505 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761327272.067016   34505 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-24 10:34:32.076173: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import fetch_openml\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from matplotlib import patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96daf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d8211",
   "metadata": {},
   "source": [
    "## Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42f27dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"..\",\"data\")\n",
    "models_dir = Path(\"..\",\"models\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c142098",
   "metadata": {},
   "source": [
    "## Defining Bench Mark Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4773b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        print(f\"---- Epoch {epoch_num} ----\")\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        print(f\"Execution time for epoch {epoch_num} : {time.perf_counter() - start_time}\")\n",
    "    print(\"Total Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538acc3",
   "metadata": {},
   "source": [
    "* So single epoch took 2857.236867081 seconds so ~47 mins mamjority of that time went to data generation since we spent only 0.01s perbatch for \"training\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb18704",
   "metadata": {},
   "source": [
    "## Data Generation With Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e5b91c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MNIST_DATA_PIXELS_TF = tf.constant(x_train, dtype=tf.float32)\n",
    "ALL_MNIST_DATA_CLASSES_TF = tf.constant(y_train, dtype=tf.float32)\n",
    "\n",
    "# number of digits to overlay on canvas\n",
    "num_of_digits = tf.constant(3, dtype=tf.int32)\n",
    "\n",
    "# max digits to define the shape of prediction output\n",
    "MAX_DIGITS = tf.constant(5, dtype=tf.int32)\n",
    "\n",
    "\n",
    "# Sample Base Digits\n",
    "@tf.function\n",
    "def get_sample_indices(dataset, size=5):\n",
    "    dataset_len = tf.shape(dataset)[0] - 1\n",
    "    random_indices = tf.random.uniform(\n",
    "        shape=[size], minval=0, maxval=dataset_len, dtype=tf.int32)\n",
    "    return random_indices\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def sample_base_digits(num_of_digits):\n",
    "    \"\"\"\n",
    "    Sample a specified number of digit images and their class labels from the master MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        num_of_digits (int): Number of digit samples to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sample_pixels, sample_values)\n",
    "            sample_pixels (np.ndarray): Array of digit images with shape (num_of_digits, 28, 28, 1).\n",
    "            sample_values (np.ndarray): Array of class labels with shape (num_of_digits, 1).\n",
    "    \"\"\"\n",
    "    sample_indices = get_sample_indices(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, size=num_of_digits)\n",
    "    sample_pixels = tf.gather(ALL_MNIST_DATA_PIXELS_TF,\n",
    "                              indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_pixels = tf.reshape(sample_pixels, shape=(num_of_digits, 28, 28))\n",
    "\n",
    "    sample_values = tf.gather(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_values = tf.reshape(sample_values, shape=(num_of_digits, 1))\n",
    "    return sample_pixels, sample_values\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "def augment_digits(digits, debug=False):\n",
    "    \"\"\"\n",
    "    Apply random augmentations (translation, zoom, rotation) to a batch of digit images.\n",
    "\n",
    "    Args:\n",
    "        digits (np.ndarray): Array of digit images to augment.\n",
    "        debug (bool, optional): If True, displays before/after images for each digit. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Augmented digit images as a numpy array.\n",
    "    \"\"\"\n",
    "    # step 2: apply random augmentation\n",
    "    augmented_tensor_digits = augmentation(digits)\n",
    "    return augmented_tensor_digits\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_min_max(active_rows, active_cols):\n",
    "    # find x_min, x_max\n",
    "    # step 1 find indices for active x\n",
    "    non_zero_active_cols = tf.where(active_cols != 0)\n",
    "    # get the first and last active x as x_min and x_max\n",
    "    x_min = tf.cast(tf.reduce_min(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "    x_max = tf.cast(tf.reduce_max(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "\n",
    "    ##\n",
    "    non_zero_active_rows = tf.where(active_rows != 0)\n",
    "    y_min = tf.cast(tf.reduce_min(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "    y_max = tf.cast(tf.reduce_max(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_blank_canvas(shape=(100, 100, 1)):\n",
    "    \"\"\"\n",
    "    Create a blank canvas for placing digit images.\n",
    "\n",
    "    Args:\n",
    "        shape (tuple, optional): Shape of the canvas. Defaults to (100, 100, 1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Blank canvas array.\n",
    "    \"\"\"\n",
    "    canvas = tf.zeros(shape=(100, 100, 1), dtype=tf.float32)\n",
    "    return canvas\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_prediction_object():\n",
    "    \"\"\"\n",
    "    Create an empty prediction object for storing digit detection results.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Prediction array of shape (MAX_DIGITS, 15).\n",
    "    \"\"\"\n",
    "    prediction = tf.zeros(shape=(MAX_DIGITS, 15), dtype=tf.float32)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def calculate_tight_bbox(pixels, class_values, padding=1):\n",
    "    \"\"\"Creates bounding box for the digits in pixel tensor and returns a concatenated tensor with bounding box and class\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28) tensor of pixels\n",
    "        class_values (_type_): (m,1) tensor of class values\n",
    "    \"\"\"\n",
    "    # step 1: calculate active rows and cols\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the col\n",
    "    active_rows = tf.reduce_sum(pixels, axis=2)\n",
    "    # tf.print(\"----- active_rows shape : \", tf.shape(active_rows))\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the row\n",
    "    active_cols = tf.reduce_sum(pixels, axis=1)\n",
    "    # tf.print(\"----- active_cols shape : \", tf.shape(active_cols))\n",
    "\n",
    "    # step 2: find non zero coordinates\n",
    "    # create boolean mask for active rows\n",
    "    non_zero_row_mask = active_rows > 0\n",
    "\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_row_mask shape : \", tf.shape(non_zero_row_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_row_coordinates = tf.where(non_zero_row_mask)\n",
    "    # tf.print(\"----- non_zero_row_coordinates shape : \", tf.shape(non_zero_row_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_row_coordinates[:, 1]\n",
    "    segment_ids = non_zero_row_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the rows it gives us y-coordinates of the image\n",
    "    y_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    y_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "\n",
    "    # create boolean mask for active cols\n",
    "    non_zero_col_mask = active_cols > 0\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_col_mask shape : \", tf.shape(non_zero_col_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_col_coordinates = tf.where(non_zero_col_mask)\n",
    "    # tf.print(\"----- non_zero_col_coordinates shape : \", tf.shape(non_zero_col_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_col_coordinates[:, 1]\n",
    "    segment_ids = non_zero_col_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the rows it gives us y-coordinates of the image\n",
    "    x_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    x_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "\n",
    "    # step 3: add padding to pixels\n",
    "    # calculate padding condition for x_min\n",
    "    x_min_padding_cond = x_min > 0\n",
    "    padded_x_min = x_min - padding\n",
    "    x_min = tf.where(x_min_padding_cond, padded_x_min, x_min)\n",
    "\n",
    "    # calculate padding condition for x_max\n",
    "    x_max_padding_cond = x_max < 27\n",
    "    padded_x_max = x_max + padding\n",
    "    x_max = tf.where(x_max_padding_cond, padded_x_max, x_max)\n",
    "\n",
    "    # calculate padding condition for y_min\n",
    "    y_min_padding_cond = y_min > 0\n",
    "    padded_y_min = y_min - padding\n",
    "    y_min = tf.where(y_min_padding_cond, padded_y_min, y_min)\n",
    "\n",
    "    # calculate padding condition for y_max\n",
    "    y_max_padding_cond = y_max < 27\n",
    "    padded_y_max = y_max + padding\n",
    "    y_max = tf.where(y_max_padding_cond, padded_y_max, y_max)\n",
    "\n",
    "    # step 4: calculate x_center & y_center\n",
    "    x_center = tf.round((x_min + x_max) / 2)\n",
    "    y_center = tf.round((y_min + y_max) / 2)\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "\n",
    "    # step 5: calculate width and height\n",
    "    width = x_max - x_min + 1\n",
    "    height = y_max - y_min + 1\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "\n",
    "    # reshape all the values to match class_values\n",
    "    x_min = tf.reshape(x_min, shape=(-1, 1))\n",
    "    x_max = tf.reshape(x_max, shape=(-1, 1))\n",
    "    y_min = tf.reshape(y_min, shape=(-1, 1))\n",
    "    y_max = tf.reshape(y_max, shape=(-1, 1))\n",
    "    x_center = tf.reshape(x_center, shape=(-1, 1))\n",
    "    y_center = tf.reshape(y_center, shape=(-1, 1))\n",
    "    width = tf.reshape(width, shape=(-1, 1))\n",
    "    height = tf.reshape(height, shape=(-1, 1))\n",
    "\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- y_center shape : \", tf.shape(y_center))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- height shape : \", tf.shape(height))\n",
    "\n",
    "    # casting all values to same dtype\n",
    "    x_min = tf.cast(x_min, dtype=tf.int32)\n",
    "    x_max = tf.cast(x_max, dtype=tf.int32)\n",
    "    y_min = tf.cast(y_min, dtype=tf.int32)\n",
    "    y_max = tf.cast(y_max, dtype=tf.int32)\n",
    "    x_center = tf.cast(x_center, dtype=tf.int32)\n",
    "    y_center = tf.cast(y_center, dtype=tf.int32)\n",
    "    width = tf.cast(width, dtype=tf.int32)\n",
    "    height = tf.cast(height, dtype=tf.int32)\n",
    "    class_values = tf.cast(class_values, dtype=tf.int32)\n",
    "\n",
    "    bounding_box = tf.concat(\n",
    "        [x_min, x_max, y_min, y_max, x_center, y_center, width, height, class_values], axis=-1)\n",
    "    # tf.print(\"----- bounding_box shape : \", tf.shape(bounding_box))\n",
    "    return bounding_box\n",
    "\n",
    "\n",
    "# BBOX Indices\n",
    "BBOX_XMIN_IDX = 0\n",
    "BBOX_XMAX_IDX = 1\n",
    "BBOX_YMIN_IDX = 2\n",
    "BBOX_YMAX_IDX = 3\n",
    "BBOX_XCENTER_IDX = 4\n",
    "BBOX_YCENTER_IDX = 5  # (This might be the same as CLASS_IDX)\n",
    "BBOX_WIDTH_IDX = 6\n",
    "BBOX_HEIGHT_IDX = 7\n",
    "BBOX_CLASS_IDX = 8\n",
    "BBOX_CANVAS_TOP_IDX = 9\n",
    "BBOX_CANVAS_LEFT_IDX = 10\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_corners(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    y_min = tf.cast(bbox_info[..., BBOX_YMIN_IDX], dtype=tf.int32)\n",
    "    x_min = tf.cast(bbox_info[..., BBOX_XMIN_IDX], dtype=tf.int32)\n",
    "    y_max = tf.cast(bbox_info[..., BBOX_YMAX_IDX], dtype=tf.int32)\n",
    "    x_max = tf.cast(bbox_info[..., BBOX_XMAX_IDX], dtype=tf.int32)\n",
    "    return y_min, x_min, y_max, x_max\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_dimensions(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    height = tf.cast(bbox_info[..., BBOX_HEIGHT_IDX], dtype=tf.int32)\n",
    "    width = tf.cast(bbox_info[..., BBOX_WIDTH_IDX], dtype=tf.int32)\n",
    "    return height, width\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_center(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    y_center = tf.cast(bbox_info[..., BBOX_YCENTER_IDX], dtype=tf.int32)\n",
    "    x_center = tf.cast(bbox_info[..., BBOX_XCENTER_IDX], dtype=tf.int32)\n",
    "    return y_center, x_center\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_canvas_placement(bbox_info):\n",
    "    \"\"\"Extracts the final (top, left) coords for the canvas.\"\"\"\n",
    "    # Assuming you concatenated these at indices 9 and 10\n",
    "    canvas_top = tf.cast(bbox_info[..., BBOX_CANVAS_TOP_IDX], dtype=tf.int32)\n",
    "    canvas_left = tf.cast(bbox_info[..., BBOX_CANVAS_LEFT_IDX], dtype=tf.int32)\n",
    "    return canvas_top, canvas_left\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def augment_digits(pixels):\n",
    "    augmented_pixels = augmentation(pixels)\n",
    "    return augmented_pixels\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def generate_grid(grid_size):\n",
    "    coorinate_range = tf.range(grid_size, dtype=tf.float32)\n",
    "    grid_X, grid_Y = tf.meshgrid(coorinate_range, coorinate_range)\n",
    "    coordinate_grid = tf.stack(values=[grid_X, grid_Y], axis=2)\n",
    "    # normalized_grid = (coordinate_grid + 0.5) / grid_size\n",
    "    return coordinate_grid\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def map_bbox_to_grid_cells(bbox_grid_cells):\n",
    "    \"\"\"Helper function maps bbox x_min,y_min to top,left inside the cell\n",
    "\n",
    "    Args:\n",
    "        bbox_grid_cells (_type_): tensor of shape (13)\n",
    "\n",
    "    Returns:\n",
    "        _type_: tensor\n",
    "    \"\"\"\n",
    "    # x_min,x_max,y_min,y_max = bbox_grid_cells[0:4]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cells)\n",
    "    # grid_cell_x, grid_cell_y,grid_width,grid_height = bbox_grid_cells[9:]\n",
    "    # step 1: generate random top/left pair\n",
    "    grid_cell_x = bbox_grid_cells[9]\n",
    "    grid_cell_y = bbox_grid_cells[10]\n",
    "    grid_cell_width_limit = bbox_grid_cells[11]\n",
    "    grid_cell_height_limit = bbox_grid_cells[12]\n",
    "\n",
    "    max_left = grid_cell_width_limit - bbox_width\n",
    "    max_top = grid_cell_height_limit - bbox_height\n",
    "\n",
    "    left = tf.random.uniform(shape=[], minval=grid_cell_x,\n",
    "                             maxval=max_left, dtype=tf.int32)\n",
    "    top = tf.random.uniform(shape=[], minval=grid_cell_y,\n",
    "                            maxval=max_top, dtype=tf.int32)\n",
    "\n",
    "    return tf.stack([top, left], axis=-1)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_canvas_grid_cells(batch_size, grid_size):\n",
    "    \"\"\"Helper function that creates a grid of shape (grid_size,grid_size), scales it to 100x100 canvas and returns random grid cells and its dimensions\n",
    "\n",
    "    Args:\n",
    "        batch_size (_type_): _description_\n",
    "        grid_size (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    grid = generate_grid(grid_size=grid_size)\n",
    "    # reshape the grid so that we can select from the pool of 9 coordinates\n",
    "    grid = tf.reshape(grid, shape=(-1, 2))\n",
    "    # shuffle grid indices for random selection - this would create grid coordinates in random order\n",
    "    # which means first row can have coordinates for other rows as well.\n",
    "    shuffled_grid = tf.random.shuffle(value=grid)\n",
    "    # create random grid cells\n",
    "    random_grid_cells = shuffled_grid[:batch_size, :]\n",
    "    # tf.print(\"----- random_grid_cells shape : \", tf.shape(random_grid_cells))\n",
    "    grid_cell_size = tf.floor(100 / grid_size)\n",
    "    # scale grid cell coordinates\n",
    "    scalled_random_grid_cells = random_grid_cells * grid_cell_size\n",
    "    # tf.print(\"----- scalled_random_grid_cells shape : \", tf.shape(scalled_random_grid_cells))\n",
    "    # calculate the width and height limit of grid cells\n",
    "    grid_cell_dimensions = scalled_random_grid_cells + grid_cell_size\n",
    "    # tf.print(\"----- grid_cell_dimensions shape : \", tf.shape(grid_cell_dimensions))\n",
    "    # concatenate the info\n",
    "    final_grid_cells = tf.concat(\n",
    "        [scalled_random_grid_cells, grid_cell_dimensions], axis=-1)\n",
    "    final_grid_cells = tf.cast(final_grid_cells, dtype=tf.int32)\n",
    "    return final_grid_cells\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def map_bbox_to_patch_indices(elems):\n",
    "    \"\"\"Helper function to map bounding boxes to patches with coordinates\n",
    "\n",
    "    Args:\n",
    "        bbox_grid_cell_top_left (_type_): _description_\n",
    "    \"\"\"\n",
    "    single_image_data, bbox_grid_cell_top_left = elems\n",
    "    # tf.print(\"pixels shape : \", tf.shape(pixels))\n",
    "\n",
    "    # bbbox_grid_cell_top_left order x_min, x_max, y_min, y_max, x_center, y_center, width, height, class_values,top,left\n",
    "    # tf.print(\"bbox_grid_cell_top_left : \", bbox_grid_cell_top_left)\n",
    "\n",
    "    # step 1: create mesh grid indices based on width and height\n",
    "    # width_height = bbox_grid_cell_top_left[BBOX_WIDTH_IDX:BBOX_HEIGHT_IDX+1]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cell_top_left)\n",
    "    bbox_y_min, bbox_x_min, bbox_y_max, bbox_x_max = get_bbox_corners(\n",
    "        bbox_grid_cell_top_left)\n",
    "\n",
    "    patch_y, patch_x = tf.meshgrid(\n",
    "        tf.range(0, bbox_height), tf.range(0, bbox_width), indexing=\"ij\")\n",
    "    patch_grid = tf.stack([patch_y, patch_x], axis=-1)\n",
    "    # tf.print(\"----- patch_grid shape : \", tf.shape(patch_grid))\n",
    "\n",
    "    # create patch indices\n",
    "    y_min_x_min_slice = tf.gather(bbox_grid_cell_top_left, [2, 0])\n",
    "\n",
    "\n",
    "    # add dimensions to match patch_grid shape\n",
    "    y_min_x_min_slice = y_min_x_min_slice[tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    # add x_min, y_min to the patch grid\n",
    "    patch_indices = tf.add(y_min_x_min_slice, patch_grid)\n",
    "    # reshape patch_indices to make them flat\n",
    "    patch_indices = tf.reshape(patch_indices, shape=(-1, 2))\n",
    "    # cast to int32\n",
    "    patch_indices = tf.cast(patch_indices, dtype=tf.int32)\n",
    "\n",
    "    # read single_image_data data\n",
    "    patch_data = tf.slice(single_image_data, begin=[\n",
    "                          bbox_y_min, bbox_x_min], size=[bbox_height, bbox_width])\n",
    "\n",
    "    patch_data = tf.reshape(patch_data, shape=[-1])\n",
    "    # tf.print(\"patch_data : \", tf.shape(patch_data))\n",
    "\n",
    "    # create canvas indices\n",
    "    top_left_slice = tf.gather(bbox_grid_cell_top_left, [9, 10])\n",
    "    top_left_offset = top_left_slice[tf.newaxis, tf.newaxis, :]\n",
    "    canvas_indices = tf.add(top_left_offset, patch_grid)\n",
    "    # reshape patch_indices to make them flat\n",
    "    canvas_indices = tf.reshape(canvas_indices, shape=(-1, 2))\n",
    "    # cast to int32\n",
    "    canvas_indices = tf.cast(canvas_indices, dtype=tf.int32)\n",
    "\n",
    "    # tf.print(\"----- patch_indices shape : \", tf.shape(patch_indices))\n",
    "    return patch_data, canvas_indices\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def place_digit_on_canvas(pixels, class_values_with_bbox):\n",
    "    \"\"\"Function to extract the place the digits from pixels tensor on a 100x100 canvas\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28) - tensor of m 28x28 images\n",
    "        class_values_with_bbox (_type_): (m,9) - tensor of bounding box coordinates for m digits.\n",
    "    \"\"\"\n",
    "    pixels_dimensions = tf.shape(pixels)\n",
    "    batch_size = pixels_dimensions[0]\n",
    "\n",
    "    # step 1: Divide the 100x100 canvas with 3x3 cells and select random grid cells to place the digit in.\n",
    "    # generate grid size\n",
    "    grid_size = 3\n",
    "    final_grid_cells = get_canvas_grid_cells(batch_size, grid_size)\n",
    "    # tf.print(\"----- final_grid_cells shape : \", tf.shape(final_grid_cells))\n",
    "\n",
    "    # step 2: get the top/left pixels in each cell where we can place the bbox in the cell\n",
    "    bbox_grid_cells = tf.concat(\n",
    "        [class_values_with_bbox, final_grid_cells], axis=-1)\n",
    "\n",
    "    # tf.print(\"----- bbox_grid_cells.shape : \", tf.shape(bbox_grid_cells))\n",
    "    top_left = tf.map_fn(\n",
    "        map_bbox_to_grid_cells, bbox_grid_cells)\n",
    "    bbox_grid_cell_top_left = tf.concat(\n",
    "        [class_values_with_bbox, top_left], axis=-1)\n",
    "    # tf.print(\"----- bbox_grid_cell_top_left shape : \",tf.shape(bbox_grid_cell_top_left))\n",
    "\n",
    "    # step 3: Read image data from pixels using bbox\n",
    "\n",
    "    # create coordinates for gather_nd\n",
    "    # we need to read the read the values within bounding box from the pixels tensor to place it on the canvas.\n",
    "    # in order to do that we need to create coordinates that range between min/max values of the bounding box.\n",
    "\n",
    "    # step 3.1: create patch matching bounding box height and width\n",
    "    spec_patch_data = tf.RaggedTensorSpec(\n",
    "        shape=(None,), dtype=tf.float32, ragged_rank=0)\n",
    "    spec_canvas_indices = tf.RaggedTensorSpec(\n",
    "        shape=(None, 2), dtype=tf.int32, ragged_rank=0)\n",
    "\n",
    "    patch_data, canvas_indices = tf.map_fn(map_bbox_to_patch_indices, elems=(\n",
    "        pixels, bbox_grid_cell_top_left), fn_output_signature=(spec_patch_data, spec_canvas_indices))\n",
    "\n",
    "    all_updates = patch_data.flat_values\n",
    "    all_indices = canvas_indices.flat_values\n",
    "    \n",
    "    canvas = tf.scatter_nd(\n",
    "        indices=all_indices,\n",
    "        updates=all_updates,\n",
    "        shape=[100, 100]\n",
    "    )\n",
    "\n",
    "    ## TODO: Update the class values with bbox with values relative to canvas\n",
    "    return canvas, class_values_with_bbox\n",
    "\n",
    "\n",
    "def generate_training_example_tf(x, y, debug=True):\n",
    "    \"\"\"\n",
    "    Generate a training example by placing digits on a canvas and creating the corresponding prediction object.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Input digit image(s).\n",
    "        y (np.ndarray): Corresponding class label(s).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (canvas, prediction) where canvas is the composed image and prediction is the label array.\n",
    "    \"\"\"\n",
    "    pixels = tf.reshape(x, shape=(-1, 28, 28))\n",
    "    class_values = tf.reshape(y, shape=(-1, 1))\n",
    "\n",
    "    # if debug:\n",
    "    # tf.print(\"----- pixels shape : \", tf.shape(pixels))\n",
    "    # tf.print(\"----- class_values shape : \", tf.shape(class_values))\n",
    "    # step 1: sample additional digits\n",
    "    if num_of_digits - 1 > 0:\n",
    "        additional_digits, additional_class_values = sample_base_digits(\n",
    "            num_of_digits - 1)\n",
    "        pixels = tf.concat([pixels, additional_digits], axis=0)\n",
    "        class_values = tf.concat(\n",
    "            [class_values, additional_class_values], axis=0)\n",
    "\n",
    "        # if debug:\n",
    "        # tf.print(\"----- pixels with additional_digits shape : \", tf.shape(pixels))\n",
    "        # tf.print(\"----- class_values with additional_class_values shape : \", tf.shape(class_values))\n",
    "\n",
    "    # step 2: augment digits\n",
    "    augmented_pixels = augment_digits(pixels)\n",
    "    # if debug:\n",
    "    # tf.print(\"----- augmented_pixels shape : \", tf.shape(augmented_pixels))\n",
    "\n",
    "    # step 3: calculate bounding box\n",
    "    class_values_with_bbox = calculate_tight_bbox(\n",
    "        augmented_pixels, class_values)\n",
    "\n",
    "    # # step 4: create blank canvas and prediction\n",
    "    canvas = create_blank_canvas()\n",
    "    prediction = create_prediction_object()\n",
    "\n",
    "    # # step 5: place digit on canvas\n",
    "    canvas, class_bbox = place_digit_on_canvas(\n",
    "        pixels, class_values_with_bbox)\n",
    "\n",
    "    # # step 6: translate bbox to prediction object\n",
    "    # prediction = translate_bbox_to_prediction(\n",
    "    #     class_bbox, prediction, debug=debug)\n",
    "\n",
    "    # # print(f\"Final canvas shape {canvas.shape}, final prediction shape {prediction.shape}\")\n",
    "    # tf.print(\"----- Processed Sample -----\")\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d6ba9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "## temporary just selecting first 32 records to test quickly\n",
    "X_tensor = tf.convert_to_tensor(x_train[:32], dtype=tf.float32)\n",
    "y_tensor = tf.convert_to_tensor(y_train[:32], dtype=tf.float32)\n",
    "batch_size = 32\n",
    "\n",
    "# print(tf.shape(X_tensor))\n",
    "# print(tf.shape(y_tensor))\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "# Use the wrapper inside the map\n",
    "tf_processed_dataset = raw_dataset.map(generate_training_example_tf).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f5710",
   "metadata": {},
   "source": [
    "### Bench Marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b6f4af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 0 ----\n",
      "Execution time for epoch 0 : 0.44215892400825396\n",
      "Total Execution time: 0.4423185620107688\n"
     ]
    }
   ],
   "source": [
    "benchmark(tf_processed_dataset.prefetch(tf.data.AUTOTUNE), num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11fd3066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas shape: (100, 100)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "# Get one batch\n",
    "# Your dataset is batched, so .take(1) gets one full batch\n",
    "for batch in tf_processed_dataset.take(1):\n",
    "    # Your map function returns (canvas, bboxes, labels)\n",
    "    # So, 'batch' is a tuple of (batched_canvases, batched_bboxes, batched_labels)\n",
    "    batched_canvases = batch\n",
    "    \n",
    "    # Get the very first canvas from the batch (shape 100x100)\n",
    "    # We use .numpy() to convert it from a EagerTensor to a NumPy array for plotting\n",
    "    canvas_to_show = batched_canvases[0].numpy()\n",
    "    \n",
    "    print(f\"Canvas shape: {canvas_to_show.shape}\")\n",
    "    \n",
    "    # Plot it\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(canvas_to_show, cmap='gray')\n",
    "    plt.title(\"Generated 100x100 Canvas (Test 1)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220539b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
