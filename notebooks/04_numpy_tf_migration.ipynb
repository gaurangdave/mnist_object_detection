{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364c7e70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05508ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import fetch_openml\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from matplotlib import patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f96daf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d8211",
   "metadata": {},
   "source": [
    "## Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e42f27dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"..\",\"data\")\n",
    "models_dir = Path(\"..\",\"models\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c142098",
   "metadata": {},
   "source": [
    "## Defining Bench Mark Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca4773b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        print(f\"---- Epoch {epoch_num} ----\")\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        print(f\"Execution time for epoch {epoch_num} : {time.perf_counter() - start_time}\")\n",
    "    print(\"Total Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538acc3",
   "metadata": {},
   "source": [
    "* So single epoch took 2857.236867081 seconds so ~47 mins mamjority of that time went to data generation since we spent only 0.01s perbatch for \"training\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb18704",
   "metadata": {},
   "source": [
    "## Data Generation With Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5b91c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MNIST_DATA_PIXELS_TF = tf.constant(x_train, dtype=tf.float32)\n",
    "ALL_MNIST_DATA_CLASSES_TF = tf.constant(y_train, dtype=tf.float32)\n",
    "\n",
    "# number of digits to overlay on canvas\n",
    "num_of_digits = tf.constant(3, dtype=tf.int32)\n",
    "\n",
    "# max digits to define the shape of prediction output\n",
    "MAX_DIGITS = tf.constant(5, dtype=tf.int32)\n",
    "\n",
    "\n",
    "# Sample Base Digits\n",
    "@tf.function\n",
    "def get_sample_indices(dataset, size=5):\n",
    "    dataset_len = tf.shape(dataset)[0] - 1\n",
    "    random_indices = tf.random.uniform(\n",
    "        shape=[size], minval=0, maxval=dataset_len, dtype=tf.int32)\n",
    "    return random_indices\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def sample_base_digits(num_of_digits):\n",
    "    \"\"\"\n",
    "    Sample a specified number of digit images and their class labels from the master MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        num_of_digits (int): Number of digit samples to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (sample_pixels, sample_values)\n",
    "            sample_pixels (np.ndarray): Array of digit images with shape (num_of_digits, 28, 28, 1).\n",
    "            sample_values (np.ndarray): Array of class labels with shape (num_of_digits, 1).\n",
    "    \"\"\"\n",
    "    sample_indices = get_sample_indices(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, size=num_of_digits)\n",
    "    sample_pixels = tf.gather(ALL_MNIST_DATA_PIXELS_TF,\n",
    "                              indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_pixels = tf.reshape(sample_pixels, shape=(num_of_digits, 28, 28,1))\n",
    "\n",
    "    sample_values = tf.gather(\n",
    "        ALL_MNIST_DATA_CLASSES_TF, indices=sample_indices, axis=0, batch_dims=1)\n",
    "    sample_values = tf.reshape(sample_values, shape=(num_of_digits, 1))\n",
    "    return sample_pixels, sample_values\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "def augment_digits(digits):\n",
    "    \"\"\"\n",
    "    Apply random augmentations (translation, zoom, rotation) to a batch of digit images.\n",
    "\n",
    "    Args:\n",
    "        digits (np.ndarray): Array of digit images to augment.\n",
    "        debug (bool, optional): If True, displays before/after images for each digit. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Augmented digit images as a numpy array.\n",
    "    \"\"\"\n",
    "    # step 2: apply random augmentation\n",
    "    augmented_tensor_digits = augmentation(digits)\n",
    "    return augmented_tensor_digits\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_min_max(active_rows, active_cols):\n",
    "    # find x_min, x_max\n",
    "    # step 1 find indices for active x\n",
    "    non_zero_active_cols = tf.where(active_cols != 0)\n",
    "    # get the first and last active x as x_min and x_max\n",
    "    x_min = tf.cast(tf.reduce_min(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "    x_max = tf.cast(tf.reduce_max(non_zero_active_cols[:, 1]), dtype=tf.int32)\n",
    "\n",
    "    ##\n",
    "    non_zero_active_rows = tf.where(active_rows != 0)\n",
    "    y_min = tf.cast(tf.reduce_min(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "    y_max = tf.cast(tf.reduce_max(non_zero_active_rows[:, 0]), dtype=tf.int32)\n",
    "\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_blank_canvas(shape=(100, 100, 1)):\n",
    "    \"\"\"\n",
    "    Create a blank canvas for placing digit images.\n",
    "\n",
    "    Args:\n",
    "        shape (tuple, optional): Shape of the canvas. Defaults to (100, 100, 1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Blank canvas array.\n",
    "    \"\"\"\n",
    "    canvas = tf.zeros(shape=(100, 100, 1), dtype=tf.float32)\n",
    "    return canvas\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def create_prediction_object():\n",
    "    \"\"\"\n",
    "    Create an empty prediction object for storing digit detection results.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Prediction array of shape (MAX_DIGITS, 15).\n",
    "    \"\"\"\n",
    "    prediction = tf.zeros(shape=(MAX_DIGITS, 15), dtype=tf.float32)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def calculate_tight_bbox(pixels, class_values, padding=1):\n",
    "    \"\"\"Creates bounding box for the digits in pixel tensor and returns a concatenated tensor with bounding box and class\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28,1) tensor of pixels\n",
    "        class_values (_type_): (m,1) tensor of class values\n",
    "    \"\"\"\n",
    "    # step 1: calculate active rows and cols\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the col\n",
    "    active_rows = tf.reduce_sum(pixels, axis=[2, 3])\n",
    "    # tf.print(\"----- active_rows shape : \", tf.shape(active_rows))\n",
    "    # active rows will have shape of (m,28) where each 28 pixels represent sum of 28 pixels in the row\n",
    "    active_cols = tf.reduce_sum(pixels, axis=[1, 3])\n",
    "    # tf.print(\"----- active_cols shape : \", tf.shape(active_cols))\n",
    "\n",
    "    # step 2: find non zero coordinates\n",
    "    # create boolean mask for active rows\n",
    "    non_zero_row_mask = active_rows != 0\n",
    "\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_row_mask shape : \", tf.shape(non_zero_row_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_row_coordinates = tf.where(non_zero_row_mask)\n",
    "    # tf.print(\"----- non_zero_row_coordinates shape : \", tf.shape(non_zero_row_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_row_coordinates[:, 1]\n",
    "    segment_ids = non_zero_row_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the rows it gives us y-coordinates of the image\n",
    "    y_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    y_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "\n",
    "    # create boolean mask for active cols\n",
    "    non_zero_col_mask = active_cols != 0\n",
    "    # TIL - tf.print by default converts boolean to integer values 1, 0\n",
    "    # tf.print(\"----- non_zero_col_mask shape : \", tf.shape(non_zero_col_mask))\n",
    "    # find coordinates using the boolean mask\n",
    "    non_zero_col_coordinates = tf.where(non_zero_col_mask)\n",
    "    # tf.print(\"----- non_zero_col_coordinates shape : \", tf.shape(non_zero_col_coordinates))\n",
    "    # find min and max row coordinates using segment_min, segment_max\n",
    "    segment_data = non_zero_col_coordinates[:, 1]\n",
    "    segment_ids = non_zero_col_coordinates[:, 0]\n",
    "    # FYI - since we are parsing thru the cols it gives us x-coordinates of the image\n",
    "    x_min = tf.math.segment_min(data=segment_data, segment_ids=segment_ids)\n",
    "    x_max = tf.math.segment_max(data=segment_data, segment_ids=segment_ids)\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "\n",
    "    # step 3: add padding to pixels\n",
    "    # calculate padding condition for x_min\n",
    "    x_min_padding_cond = x_min > 0\n",
    "    padded_x_min = x_min - padding\n",
    "    x_min = tf.where(x_min_padding_cond, padded_x_min, x_min)\n",
    "\n",
    "    # calculate padding condition for x_max\n",
    "    x_max_padding_cond = x_max < 27\n",
    "    padded_x_max = x_max + padding\n",
    "    x_max = tf.where(x_max_padding_cond, padded_x_max, x_max)\n",
    "\n",
    "    # calculate padding condition for y_min\n",
    "    y_min_padding_cond = y_min > 0\n",
    "    padded_y_min = y_min - padding\n",
    "    y_min = tf.where(y_min_padding_cond, padded_y_min, y_min)\n",
    "\n",
    "    # calculate padding condition for y_max\n",
    "    y_max_padding_cond = y_max < 27\n",
    "    padded_y_max = y_max + padding\n",
    "    y_max = tf.where(y_max_padding_cond, padded_y_max, y_max)\n",
    "\n",
    "    # step 4: calculate x_center & y_center\n",
    "    x_center = tf.round((x_min + x_max) / 2)\n",
    "    y_center = tf.round((y_min + y_max) / 2)\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "\n",
    "    # step 5: calculate width and height\n",
    "    width = x_max - x_min + 1\n",
    "    height = y_max - y_min + 1\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "\n",
    "    # reshape all the values to match class_values\n",
    "    x_min = tf.reshape(x_min, shape=(-1, 1))\n",
    "    x_max = tf.reshape(x_max, shape=(-1, 1))\n",
    "    y_min = tf.reshape(y_min, shape=(-1, 1))\n",
    "    y_max = tf.reshape(y_max, shape=(-1, 1))\n",
    "    x_center = tf.reshape(x_center, shape=(-1, 1))\n",
    "    y_center = tf.reshape(y_center, shape=(-1, 1))\n",
    "    width = tf.reshape(width, shape=(-1, 1))\n",
    "    height = tf.reshape(height, shape=(-1, 1))\n",
    "\n",
    "    # tf.print(\"----- x_min shape : \", tf.shape(x_min))\n",
    "    # tf.print(\"----- x_max shape : \", tf.shape(x_max))\n",
    "    # tf.print(\"----- y_min shape : \", tf.shape(y_min))\n",
    "    # tf.print(\"----- y_max shape : \", tf.shape(y_max))\n",
    "    # tf.print(\"----- x_center shape : \", tf.shape(x_center))\n",
    "    # tf.print(\"----- y_center shape : \", tf.shape(y_center))\n",
    "    # tf.print(\"----- width shape : \", tf.shape(width))\n",
    "    # tf.print(\"----- height shape : \", tf.shape(height))\n",
    "\n",
    "    # casting all values to same dtype\n",
    "    x_min = tf.cast(x_min, dtype=tf.int32)\n",
    "    x_max = tf.cast(x_max, dtype=tf.int32)\n",
    "    y_min = tf.cast(y_min, dtype=tf.int32)\n",
    "    y_max = tf.cast(y_max, dtype=tf.int32)\n",
    "    x_center = tf.cast(x_center, dtype=tf.int32)\n",
    "    y_center = tf.cast(y_center, dtype=tf.int32)\n",
    "    width = tf.cast(width, dtype=tf.int32)\n",
    "    height = tf.cast(height, dtype=tf.int32)\n",
    "    class_values = tf.cast(class_values, dtype=tf.int32)\n",
    "\n",
    "    bounding_box = tf.concat(\n",
    "        [x_min, x_max, y_min, y_max, x_center, y_center, width, height, class_values], axis=-1)\n",
    "    # tf.print(\"----- bounding_box shape : \", tf.shape(bounding_box))\n",
    "    return bounding_box\n",
    "\n",
    "\n",
    "# BBOX Indices\n",
    "BBOX_XMIN_IDX = 0\n",
    "BBOX_XMAX_IDX = 1\n",
    "BBOX_YMIN_IDX = 2\n",
    "BBOX_YMAX_IDX = 3\n",
    "BBOX_XCENTER_IDX = 4\n",
    "BBOX_YCENTER_IDX = 5  # (This might be the same as CLASS_IDX)\n",
    "BBOX_WIDTH_IDX = 6\n",
    "BBOX_HEIGHT_IDX = 7\n",
    "BBOX_CLASS_IDX = 8\n",
    "BBOX_CANVAS_TOP_IDX = 9\n",
    "BBOX_CANVAS_LEFT_IDX = 10\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_corners(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    y_min = tf.cast(bbox_info[..., BBOX_YMIN_IDX], dtype=tf.int32)\n",
    "    x_min = tf.cast(bbox_info[..., BBOX_XMIN_IDX], dtype=tf.int32)\n",
    "    y_max = tf.cast(bbox_info[..., BBOX_YMAX_IDX], dtype=tf.int32)\n",
    "    x_max = tf.cast(bbox_info[..., BBOX_XMAX_IDX], dtype=tf.int32)\n",
    "    return y_min, x_min, y_max, x_max\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_dimensions(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    height = tf.cast(bbox_info[..., BBOX_HEIGHT_IDX], dtype=tf.int32)\n",
    "    width = tf.cast(bbox_info[..., BBOX_WIDTH_IDX], dtype=tf.int32)\n",
    "    return height, width\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_bbox_center(bbox_info):\n",
    "    \"\"\"Extracts bounding box dimensions from the info tensor.\"\"\"\n",
    "    y_center = tf.cast(bbox_info[..., BBOX_YCENTER_IDX], dtype=tf.int32)\n",
    "    x_center = tf.cast(bbox_info[..., BBOX_XCENTER_IDX], dtype=tf.int32)\n",
    "    return y_center, x_center\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_canvas_placement(bbox_info):\n",
    "    \"\"\"Extracts the final (top, left) coords for the canvas.\"\"\"\n",
    "    # Assuming you concatenated these at indices 9 and 10\n",
    "    canvas_top = tf.cast(bbox_info[..., BBOX_CANVAS_TOP_IDX], dtype=tf.int32)\n",
    "    canvas_left = tf.cast(bbox_info[..., BBOX_CANVAS_LEFT_IDX], dtype=tf.int32)\n",
    "    return canvas_top, canvas_left\n",
    "\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomTranslation(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=0.2, width_factor=0.2, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "\n",
    "    tf.keras.layers.RandomRotation(\n",
    "        factor=0.1, fill_value=0.0, fill_mode=\"constant\", seed=42),\n",
    "])\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def augment_digits(pixels):\n",
    "    augmented_pixels = augmentation(pixels)\n",
    "    return augmented_pixels\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def generate_grid(grid_size):\n",
    "    coorinate_range = tf.range(grid_size, dtype=tf.float32)\n",
    "    grid_X, grid_Y = tf.meshgrid(coorinate_range, coorinate_range)\n",
    "    coordinate_grid = tf.stack(values=[grid_X, grid_Y], axis=2)\n",
    "    # normalized_grid = (coordinate_grid + 0.5) / grid_size\n",
    "    return coordinate_grid\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def map_bbox_to_grid_cells(bbox_grid_cells):\n",
    "    \"\"\"Helper function maps bbox x_min,y_min to top,left inside the cell\n",
    "\n",
    "    Args:\n",
    "        bbox_grid_cells (_type_): tensor of shape (13)\n",
    "\n",
    "    Returns:\n",
    "        _type_: tensor\n",
    "    \"\"\"\n",
    "    # x_min,x_max,y_min,y_max = bbox_grid_cells[0:4]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cells)\n",
    "    # grid_cell_x, grid_cell_y,grid_width,grid_height = bbox_grid_cells[9:]\n",
    "    # step 1: generate random top/left pair\n",
    "    grid_cell_x = bbox_grid_cells[9]\n",
    "    grid_cell_y = bbox_grid_cells[10]\n",
    "    grid_cell_width_limit = bbox_grid_cells[11]\n",
    "    grid_cell_height_limit = bbox_grid_cells[12]\n",
    "\n",
    "    max_left = grid_cell_width_limit - bbox_width\n",
    "    max_top = grid_cell_height_limit - bbox_height\n",
    "\n",
    "    left = tf.random.uniform(shape=[], minval=grid_cell_x,\n",
    "                             maxval=max_left+1, dtype=tf.int32)\n",
    "    top = tf.random.uniform(shape=[], minval=grid_cell_y,\n",
    "                            maxval=max_top+1, dtype=tf.int32)\n",
    "    return tf.stack([top, left], axis=-1)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_canvas_grid_cells(batch_size, grid_size):\n",
    "    \"\"\"Helper function that creates a grid of shape (grid_size,grid_size), scales it to 100x100 canvas and returns random grid cells and its dimensions\n",
    "\n",
    "    Args:\n",
    "        batch_size (_type_): _description_\n",
    "        grid_size (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    grid = generate_grid(grid_size=grid_size)\n",
    "    # reshape the grid so that we can select from the pool of 9 coordinates\n",
    "    grid = tf.reshape(grid, shape=(-1, 2))\n",
    "    # shuffle grid indices for random selection - this would create grid coordinates in random order\n",
    "    # which means first row can have coordinates for other rows as well.\n",
    "    shuffled_grid = tf.random.shuffle(value=grid)\n",
    "    # create random grid cells\n",
    "    random_grid_cells = shuffled_grid[:batch_size, :]\n",
    "    # tf.print(\"----- random_grid_cells shape : \", tf.shape(random_grid_cells))\n",
    "    grid_cell_size = tf.floor(100 / grid_size)\n",
    "    # scale grid cell coordinates\n",
    "    scalled_random_grid_cells = random_grid_cells * grid_cell_size\n",
    "    # tf.print(\"----- scalled_random_grid_cells shape : \", tf.shape(scalled_random_grid_cells))\n",
    "    # calculate the width and height limit of grid cells\n",
    "    grid_cell_dimensions = scalled_random_grid_cells + grid_cell_size\n",
    "    # tf.print(\"----- grid_cell_dimensions shape : \", tf.shape(grid_cell_dimensions))\n",
    "    # concatenate the info\n",
    "    final_grid_cells = tf.concat(\n",
    "        [scalled_random_grid_cells, grid_cell_dimensions], axis=-1)\n",
    "    final_grid_cells = tf.cast(final_grid_cells, dtype=tf.int32)\n",
    "    return final_grid_cells\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def map_bbox_to_patch_indices(elems):\n",
    "    \"\"\"Helper function to map bounding boxes to patches with coordinates\n",
    "\n",
    "    Args:\n",
    "        bbox_grid_cell_top_left (_type_): _description_\n",
    "    \"\"\"\n",
    "    single_image_data, bbox_grid_cell_top_left = elems\n",
    "    # tf.print(\"pixels shape : \", tf.shape(pixels))\n",
    "\n",
    "    # bbbox_grid_cell_top_left order x_min, x_max, y_min, y_max, x_center, y_center, width, height, class_values,top,left\n",
    "    # tf.print(\"bbox_grid_cell_top_left : \", bbox_grid_cell_top_left)\n",
    "\n",
    "    # step 1: create mesh grid indices based on width and height\n",
    "    # width_height = bbox_grid_cell_top_left[BBOX_WIDTH_IDX:BBOX_HEIGHT_IDX+1]\n",
    "    bbox_height, bbox_width = get_bbox_dimensions(bbox_grid_cell_top_left)\n",
    "    bbox_y_min, bbox_x_min, bbox_y_max, bbox_x_max = get_bbox_corners(\n",
    "        bbox_grid_cell_top_left)\n",
    "\n",
    "    patch_y, patch_x = tf.meshgrid(\n",
    "        tf.range(0, bbox_height), tf.range(0, bbox_width), indexing=\"ij\")\n",
    "    patch_grid = tf.stack([patch_y, patch_x], axis=-1)\n",
    "    # tf.print(\"----- patch_grid shape : \", tf.shape(patch_grid))\n",
    "\n",
    "    # create patch indices\n",
    "    y_min_x_min_slice = tf.gather(bbox_grid_cell_top_left, [2, 0])\n",
    "\n",
    "\n",
    "    # add dimensions to match patch_grid shape\n",
    "    y_min_x_min_slice = y_min_x_min_slice[tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    # add x_min, y_min to the patch grid\n",
    "    patch_indices = tf.add(y_min_x_min_slice, patch_grid)\n",
    "    # reshape patch_indices to make them flat\n",
    "    patch_indices = tf.reshape(patch_indices, shape=(-1, 2))\n",
    "    # cast to int32\n",
    "    patch_indices = tf.cast(patch_indices, dtype=tf.int32)\n",
    "\n",
    "    # read single_image_data data\n",
    "    # single_image_data is (28, 28, 1)\n",
    "    # begin must be 3D: [y, x, channel_start]\n",
    "    # size must be 3D: [h, w, num_channels]\n",
    "    patch_data = tf.slice(single_image_data, \n",
    "                          begin=[bbox_y_min, bbox_x_min, 0], \n",
    "                          size=[bbox_height, bbox_width, 1])\n",
    "\n",
    "    patch_data = tf.reshape(patch_data, shape=[-1])\n",
    "    # tf.print(\"patch_data : \", tf.shape(patch_data))\n",
    "\n",
    "    # create canvas indices\n",
    "    top_left_slice = tf.gather(bbox_grid_cell_top_left, [9, 10])\n",
    "    top_left_offset = top_left_slice[tf.newaxis, tf.newaxis, :]\n",
    "    canvas_indices = tf.add(top_left_offset, patch_grid)\n",
    "    # reshape patch_indices to make them flat\n",
    "    canvas_indices = tf.reshape(canvas_indices, shape=(-1, 2))\n",
    "    # cast to int32\n",
    "    canvas_indices = tf.cast(canvas_indices, dtype=tf.int32)\n",
    "\n",
    "    # tf.print(\"----- patch_indices shape : \", tf.shape(patch_indices))\n",
    "    return patch_data, canvas_indices\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def place_digit_on_canvas(pixels, class_values_with_bbox):\n",
    "    \"\"\"Function to extract the place the digits from pixels tensor on a 100x100 canvas\n",
    "\n",
    "    Args:\n",
    "        pixels (_type_): (m,28,28,1) - tensor of m 28x28 images\n",
    "        class_values_with_bbox (_type_): (m,9) - tensor of bounding box coordinates for m digits.\n",
    "    \"\"\"\n",
    "    pixels_dimensions = tf.shape(pixels)\n",
    "    batch_size = pixels_dimensions[0]\n",
    "\n",
    "    # step 1: Divide the 100x100 canvas with 3x3 cells and select random grid cells to place the digit in.\n",
    "    # generate grid size\n",
    "    grid_size = 3\n",
    "    final_grid_cells = get_canvas_grid_cells(batch_size, grid_size)\n",
    "    # tf.print(\"----- final_grid_cells shape : \", tf.shape(final_grid_cells))\n",
    "\n",
    "    # step 2: get the top/left pixels in each cell where we can place the bbox in the cell\n",
    "    bbox_grid_cells = tf.concat(\n",
    "        [class_values_with_bbox, final_grid_cells], axis=-1)\n",
    "\n",
    "    # tf.print(\"----- bbox_grid_cells.shape : \", tf.shape(bbox_grid_cells))\n",
    "    top_left = tf.map_fn(\n",
    "        map_bbox_to_grid_cells, bbox_grid_cells)\n",
    "    bbox_grid_cell_top_left = tf.concat(\n",
    "        [class_values_with_bbox, top_left], axis=-1)\n",
    "    # tf.print(\"----- bbox_grid_cell_top_left shape : \",tf.shape(bbox_grid_cell_top_left))\n",
    "\n",
    "    # step 3: Read image data from pixels using bbox\n",
    "\n",
    "    # create coordinates for gather_nd\n",
    "    # we need to read the read the values within bounding box from the pixels tensor to place it on the canvas.\n",
    "    # in order to do that we need to create coordinates that range between min/max values of the bounding box.\n",
    "\n",
    "    # step 3.1: create patch matching bounding box height and width\n",
    "    spec_patch_data = tf.RaggedTensorSpec(\n",
    "        shape=(None,), dtype=tf.float32, ragged_rank=0)\n",
    "    spec_canvas_indices = tf.RaggedTensorSpec(\n",
    "        shape=(None, 2), dtype=tf.int32, ragged_rank=0)\n",
    "\n",
    "    patch_data, canvas_indices = tf.map_fn(map_bbox_to_patch_indices, elems=(\n",
    "        pixels, bbox_grid_cell_top_left), fn_output_signature=(spec_patch_data, spec_canvas_indices))\n",
    "\n",
    "    all_updates = patch_data.flat_values\n",
    "    all_indices = canvas_indices.flat_values\n",
    "    \n",
    "    canvas = tf.scatter_nd(\n",
    "        indices=all_indices,\n",
    "        updates=all_updates,\n",
    "        shape=[100, 100]\n",
    "    )\n",
    "\n",
    "    ## TODO: Update the class values with bbox with values relative to canvas\n",
    "    return canvas, class_values_with_bbox\n",
    "\n",
    "\n",
    "def generate_training_example_tf(x, y, debug=True):\n",
    "    \"\"\"\n",
    "    Generate a training example by placing digits on a canvas and creating the corresponding prediction object.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Input digit image(s).\n",
    "        y (np.ndarray): Corresponding class label(s).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (canvas, prediction) where canvas is the composed image and prediction is the label array.\n",
    "    \"\"\"\n",
    "    pixels = tf.reshape(x, shape=(-1, 28, 28, 1))\n",
    "    class_values = tf.reshape(y, shape=(-1, 1))\n",
    "\n",
    "    # if debug:\n",
    "    # tf.print(\"----- pixels shape : \", tf.shape(pixels))\n",
    "    # tf.print(\"----- class_values shape : \", tf.shape(class_values))\n",
    "    # step 1: sample additional digits\n",
    "    if num_of_digits - 1 > 0:\n",
    "        additional_digits, additional_class_values = sample_base_digits(\n",
    "            num_of_digits - 1)\n",
    "        pixels = tf.concat([pixels, additional_digits], axis=0)\n",
    "        class_values = tf.concat(\n",
    "            [class_values, additional_class_values], axis=0)\n",
    "\n",
    "        # if debug:\n",
    "        # tf.print(\"----- pixels with additional_digits shape : \", tf.shape(pixels))\n",
    "        # tf.print(\"----- class_values with additional_class_values shape : \", tf.shape(class_values))\n",
    "\n",
    "    # step 2: augment digits\n",
    "    augmented_pixels = augment_digits(pixels)\n",
    "    cleaned_augmented_pixels = tf.nn.relu(augmented_pixels)\n",
    "\n",
    "    # step 3: calculate bounding box\n",
    "    class_values_with_bbox = calculate_tight_bbox(\n",
    "        cleaned_augmented_pixels, class_values)\n",
    "\n",
    "    # # step 5: place digit on canvas\n",
    "    canvas, class_bbox = place_digit_on_canvas(\n",
    "        augmented_pixels, class_values_with_bbox)\n",
    "\n",
    "    # # step 6: translate bbox to prediction object\n",
    "    # prediction = translate_bbox_to_prediction(\n",
    "    #     class_bbox, prediction, debug=debug)\n",
    "\n",
    "    # # print(f\"Final canvas shape {canvas.shape}, final prediction shape {prediction.shape}\")\n",
    "    # tf.print(\"----- Processed Sample -----\")\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6ba9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "## temporary just selecting first 32 records to test quickly\n",
    "X_tensor = tf.convert_to_tensor(x_train[:32], dtype=tf.float32)\n",
    "y_tensor = tf.convert_to_tensor(y_train[:32], dtype=tf.float32)\n",
    "batch_size = 32\n",
    "\n",
    "# print(tf.shape(X_tensor))\n",
    "# print(tf.shape(y_tensor))\n",
    "\n",
    "raw_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "# Use the wrapper inside the map\n",
    "tf_processed_dataset = raw_dataset.map(generate_training_example_tf).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f5710",
   "metadata": {},
   "source": [
    "### Bench Marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b6f4af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 0 ----\n",
      "Execution time for epoch 0 : 0.37324034003540874\n",
      "Total Execution time: 0.3733791970880702\n"
     ]
    }
   ],
   "source": [
    "benchmark(tf_processed_dataset.prefetch(tf.data.AUTOTUNE), num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11fd3066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas shape: (100, 100)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "# Get one batch\n",
    "# Your dataset is batched, so .take(1) gets one full batch\n",
    "for batch in tf_processed_dataset.take(1):\n",
    "    # Your map function returns (canvas, bboxes, labels)\n",
    "    # So, 'batch' is a tuple of (batched_canvases, batched_bboxes, batched_labels)\n",
    "    batched_canvases = batch\n",
    "    \n",
    "    # Get the very first canvas from the batch (shape 100x100)\n",
    "    # We use .numpy() to convert it from a EagerTensor to a NumPy array for plotting\n",
    "    canvas_to_show = batched_canvases[0].numpy()\n",
    "    \n",
    "    print(f\"Canvas shape: {canvas_to_show.shape}\")\n",
    "    # single_image = tf.reshape(single_image,shape=(28,28))\n",
    "    \n",
    "    # Plot it\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(canvas_to_show, cmap='gray')\n",
    "    plt.title(\"Generated 100x100 Canvas (Test 1)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220539b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
